{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in e:\\project_viralnews\\venv\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in e:\\project_viralnews\\venv\\lib\\site-packages (from sklearn) (0.23.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in e:\\project_viralnews\\venv\\lib\\site-packages (from scikit-learn->sklearn) (1.18.5)\n",
      "Requirement already satisfied: joblib>=0.11 in e:\\project_viralnews\\venv\\lib\\site-packages (from scikit-learn->sklearn) (0.15.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in e:\\project_viralnews\\venv\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in e:\\project_viralnews\\venv\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import dataset\n",
    "2. Vectorize the training samples using count vectorizer\n",
    "3. shuffle indexes and partition dataset into train and test\n",
    "4. Training parameters:\n",
    "    title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39644, 31565, 18490)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../uci_data/OnlineNewsPopularity_extended.csv\")\n",
    "# data['label_by_mean'] = 0\n",
    "# data['label_by_median'] = 0\n",
    "# mean = data.shares.mean()\n",
    "# median = data.shares.median()\n",
    "# data.loc[data.shares<mean,'label_by_mean'] = 1\n",
    "# data.loc[data.shares<median,'label_by_median'] = 1\n",
    "len(data), data.loc[data['label_by_mean']==1,'url'].count(),data.loc[data['label_by_median']==1,'url'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39592, 31527, 18471)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "len(data), data.loc[data['label_by_mean']==1,'url'].count(),data.loc[data['label_by_median']==1,'url'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39592, 27303)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = data['title']\n",
    "X = vectorizer.fit_transform(X)\n",
    "print(X.shape)\n",
    "y = data['label_by_mean']\n",
    "# y = [1,1,1,0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=12345, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a classifier using SVM on count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(random_state=12345)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LinearSVC(random_state=12345)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy, precision, recall and f1 for the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Information about [Precision, Recall and F1 score](https://scikit-learn.org/stable/modules/model_evaluation.html#precision-recall-and-f-measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Non Viral       0.23      0.17      0.19      3226\n",
      "       Viral       0.80      0.85      0.83     12611\n",
      "\n",
      "    accuracy                           0.71     15837\n",
      "   macro avg       0.51      0.51      0.51     15837\n",
      "weighted avg       0.68      0.71      0.70     15837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred,target_names=['Non Viral', 'Viral']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Non Viral       0.55      0.57      0.56      8478\n",
      "       Viral       0.48      0.46      0.47      7359\n",
      "\n",
      "    accuracy                           0.52     15837\n",
      "   macro avg       0.52      0.52      0.52     15837\n",
      "weighted avg       0.52      0.52      0.52     15837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = data['title']\n",
    "X = vectorizer.fit_transform(X)\n",
    "y = data['label_by_median']\n",
    "# y = [1,1,1,0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=12345, shuffle=True)\n",
    "\n",
    "classifier = LinearSVC(random_state=12345)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred,target_names=['Non Viral', 'Viral']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

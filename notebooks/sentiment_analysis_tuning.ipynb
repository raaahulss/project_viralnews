{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "data_path = '../../dataset/'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('{}full_ibc'.format(data_path)))\n",
    "import copy\n",
    "import pickle\n",
    "import numpy\n",
    "import json\n",
    "import random\n",
    "from random import randint\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "import nltk\n",
    "from nltk.lm import Vocabulary\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "print(stopwords.words('english'))\n",
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier as DCT\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import fasttext\n",
    "\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ibc_data():\n",
    "    [lib, con, neutral] = pickle.load(open('{}full_ibc/ibcData.pkl'.format(data_path), 'rb'))\n",
    "\n",
    "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    ibc_lib = [([token for token in tokenizer.tokenize(tree.get_words().lower()) if token not in stopwords.words('english')], \"LIBERAL\")\n",
    "               for tree in lib]\n",
    "    ibc_con = [([token for token in tokenizer.tokenize(tree.get_words().lower()) if token not in stopwords.words('english')], \"CONSERVATIVE\")\n",
    "               for tree in con]\n",
    "    ibc_full_data = ibc_lib + ibc_con\n",
    "\n",
    "    ibc_lib_size = len(ibc_lib)\n",
    "    ibc_lib_train_size = int(ibc_lib_size*0.8)\n",
    "    ibc_lib_val_size = int(ibc_lib_size*0.1)\n",
    "    ibc_lib_test_size = ibc_lib_size - ibc_lib_train_size - ibc_lib_val_size\n",
    "    ibc_lib_train_data, ibc_lib_val_data, ibc_lib_test_data = torch.utils.data.random_split(ibc_lib, [ibc_lib_train_size, ibc_lib_val_size, ibc_lib_test_size])\n",
    "    \n",
    "    ibc_con_size = len(ibc_con)\n",
    "    ibc_con_train_size = int(ibc_con_size*0.8)\n",
    "    ibc_con_val_size = int(ibc_con_size*0.1)\n",
    "    ibc_con_test_size = ibc_con_size - ibc_con_train_size - ibc_con_val_size\n",
    "    ibc_con_train_data, ibc_con_val_data, ibc_con_test_data = torch.utils.data.random_split(ibc_con, [ibc_con_train_size, ibc_con_val_size, ibc_con_test_size])\n",
    "\n",
    "    ibc_train_data = ibc_lib_train_data + ibc_con_train_data\n",
    "    ibc_val_data = ibc_lib_val_data + ibc_con_val_data\n",
    "    ibc_test_data = ibc_lib_test_data + ibc_con_test_data\n",
    "    ibc_labels = {\"LIBERAL\": 0, \"CONSERVATIVE\": 1}\n",
    "    \n",
    "    print('training data size:', len(ibc_train_data))\n",
    "    print('validation data size:', len(ibc_val_data))\n",
    "    print('test data size:', len(ibc_test_data))\n",
    "    \n",
    "    return ibc_train_data, ibc_val_data, ibc_test_data\n",
    "\n",
    "def generate_data_loader(train_data, val_data, test_data, make_feature, make_target, labels={\"LIBERAL\": 0, \"CONSERVATIVE\": 1}, batch_size=1, cutoff=1):\n",
    "    train_corpus = []\n",
    "    for sentence, _ in train_data:\n",
    "        train_corpus += sentence\n",
    "    vocab_nltk = Vocabulary(train_corpus)\n",
    "    \n",
    "    vocab = {'<unknown>': 0}\n",
    "    for word, count in vocab_nltk.counts.items():\n",
    "        if count >= cutoff:\n",
    "            vocab[word] = len(vocab)\n",
    "            \n",
    "    train_data_loader = torch.utils.data.DataLoader([(make_feature(sentence, vocab), make_target(label, labels)) for sentence, label in train_data],\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    shuffle=True)\n",
    "    val_data_loader = torch.utils.data.DataLoader([(make_feature(sentence, vocab), make_target(label, labels)) for sentence, label in val_data],\n",
    "                                                  batch_size=batch_size)\n",
    "    test_data_loader = torch.utils.data.DataLoader([(make_feature(sentence, vocab), make_target(label, labels)) for sentence, label in test_data],\n",
    "                                                   batch_size=batch_size)\n",
    "    return vocab, train_data_loader, val_data_loader, test_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size: 2980\n",
      "validation data size: 372\n",
      "test data size: 374\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "ibc_train_data, ibc_val_data, ibc_test_data = generate_ibc_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Ensemble method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bow_vec_lr(sentence, vocab):\n",
    "    vec = torch.zeros(len(vocab), device=device)\n",
    "    for word in sentence:\n",
    "        if word in vocab:\n",
    "            vec[vocab[word]] += 1\n",
    "        else:\n",
    "            vec[0] += 1\n",
    "    return vec.view(-1)\n",
    "\n",
    "def make_label_lr(label, label_to_id):\n",
    "    return torch.tensor(label_to_id[label]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoWClassifier(nn.Module):\n",
    "    def __init__(self, vocab, output_size):\n",
    "        super(BoWClassifier, self).__init__()\n",
    "        self.vocab = vocab\n",
    "        self.input_size = len(vocab)\n",
    "        self.output_size = output_size\n",
    "        self.linear = nn.Linear(self.input_size, self.output_size).to(device)\n",
    "        \n",
    "    def forward(self, bow_vec):\n",
    "        return F.log_softmax(self.linear(bow_vec), dim=-1)\n",
    "    \n",
    "def lr_train(model, train_data, val_data, num_epochs=50):\n",
    "    loss_function = nn.NLLLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for bow_vec, target in train_data:\n",
    "            model.zero_grad()\n",
    "\n",
    "            probs = model(bow_vec)\n",
    "            loss = loss_function(probs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print('{}: {}'.format(epoch+1, lr_eval(model, val_data)))\n",
    "    \n",
    "def lr_eval(model, data):\n",
    "    model.eval()\n",
    "    num_predictions = 0\n",
    "    num_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for bow_vec, target in data:\n",
    "            probs = model(bow_vec)\n",
    "            for i in range(len(probs)):\n",
    "                num_predictions += 1\n",
    "                if (torch.argmax(probs[i]) == target[i]):\n",
    "                    num_correct += 1\n",
    "    model.train()\n",
    "    return num_correct/num_predictions*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibc_vocab, ibc_train_data_loader, ibc_val_data_loader, ibc_test_data_loader = generate_data_loader(ibc_train_data,\n",
    "                                                                                                   ibc_val_data,\n",
    "                                                                                                   ibc_test_data,\n",
    "                                                                                                   make_bow_vec_lr,\n",
    "                                                                                                   make_label_lr,\n",
    "                                                                                                   {\"LIBERAL\": 0, \"CONSERVATIVE\": 1},\n",
    "                                                                                                   batch_size=16\n",
    "                                                                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.63636363636363\n",
      "10: 68.54838709677419\n",
      "20: 68.81720430107528\n",
      "30: 68.54838709677419\n",
      "40: 68.54838709677419\n",
      "50: 68.01075268817203\n",
      "60: 68.27956989247312\n",
      "70: 66.93548387096774\n",
      "80: 66.12903225806451\n",
      "90: 65.59139784946237\n",
      "100: 66.12903225806451\n",
      "63.63636363636363\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "lr_model = BoWClassifier(ibc_vocab, 2)\n",
    "\n",
    "print(lr_eval(model, ibc_test_data_loader))\n",
    "lr_train(lr_model, ibc_train_data_loader, ibc_val_data_loader, num_epochs=100)\n",
    "print(lr_eval(model, ibc_test_data_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bow_vec_dt(sentence, vocab):\n",
    "    vec = [0] * len(vocab)\n",
    "    for word in sentence:\n",
    "        if word in vocab.keys():\n",
    "            vec[vocab[word]] += 1\n",
    "    return vec\n",
    "\n",
    "def make_target_dt(label, labels):\n",
    "    return labels[label]\n",
    "\n",
    "def generate_data_dt(train_data, val_data, test_data, labels={\"LIBERAL\": 0, \"CONSERVATIVE\": 1}, cutoff=1):\n",
    "    train_corpus = []\n",
    "    for sentence, _ in train_data:\n",
    "        train_corpus += sentence\n",
    "    vocab_nltk = Vocabulary(train_corpus)\n",
    "    \n",
    "    vocab = {'<unknown>': 0}\n",
    "    for word, count in vocab_nltk.counts.items():\n",
    "        if count >= cutoff:\n",
    "            vocab[word] = len(vocab)\n",
    "    \n",
    "    train_data = [(make_bow_vec_dt(sentence, vocab), make_target_dt(target, labels)) for sentence, target in train_data]\n",
    "    test_data = [(make_bow_vec_dt(sentence, vocab), make_target_dt(target, labels)) for sentence, target in test_data]\n",
    "\n",
    "    print('train data size:', len(train_data))\n",
    "    print('test data size:', len(test_data))\n",
    "    \n",
    "    return vocab, train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt_train(model, train_data):\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for sentence, label in train_data:\n",
    "        x.append(sentence)\n",
    "        y.append(label)\n",
    "\n",
    "    model.fit(x, y)\n",
    "    \n",
    "def dt_eval(model, test_data):\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for sentence, label in test_data:\n",
    "        x.append(sentence)\n",
    "        y.append(label)\n",
    "        \n",
    "    predictions = model.predict(x)\n",
    "    \n",
    "    correct_prediction = 0\n",
    "    idx = 0\n",
    "    while idx < len(x):\n",
    "        if predictions[idx] == y[idx]:\n",
    "            correct_prediction += 1\n",
    "        idx += 1\n",
    "        \n",
    "    return correct_prediction / idx * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: 2980\n",
      "test data size: 374\n"
     ]
    }
   ],
   "source": [
    "ibc_vocab_dt, ibc_train_data_dt, ibc_test_data_dt = generate_data_dt(ibc_train_data, ibc_val_data, ibc_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(0)\n",
    "dt = DCT()\n",
    "dt_train(dt, ibc_train_data_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.48663101604278\n"
     ]
    }
   ],
   "source": [
    "print(dt_eval(dt, ibc_test_data_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bow_vec_knn(sentence, vocab):\n",
    "    vec = [0] * len(vocab)\n",
    "    for word in sentence:\n",
    "        if word in vocab.keys():\n",
    "            vec[vocab[word]] += 1\n",
    "    return vec\n",
    "\n",
    "def make_target_knn(label, labels):\n",
    "    return labels[label]\n",
    "\n",
    "def generate_data_knn(train_data, val_data, test_data, labels={\"LIBERAL\": 0, \"CONSERVATIVE\": 1}, cutoff=1):\n",
    "    train_corpus = []\n",
    "    for sentence, _ in train_data:\n",
    "        train_corpus += sentence\n",
    "    vocab_nltk = Vocabulary(train_corpus)\n",
    "    \n",
    "    vocab = {'<unknown>': 0}\n",
    "    for word, count in vocab_nltk.counts.items():\n",
    "        if count >= cutoff:\n",
    "            vocab[word] = len(vocab)\n",
    "\n",
    "    train_data = [(make_bow_vec_dt(sentence, vocab), make_target_dt(target, labels)) for sentence, target in train_data]\n",
    "    test_data = [(make_bow_vec_dt(sentence, vocab), make_target_dt(target, labels)) for sentence, target in test_data]\n",
    "\n",
    "    print('train data size:', len(train_data))\n",
    "    print('test data size:', len(test_data))\n",
    "    \n",
    "    return vocab, train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_train(model, train_data):\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for sentence, label in train_data:\n",
    "        x.append(sentence)\n",
    "        y.append(label)\n",
    "\n",
    "    model.fit(x, y)\n",
    "    \n",
    "def knn_eval(model, test_data):\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for sentence, label in test_data:\n",
    "        x.append(sentence)\n",
    "        y.append(label)\n",
    "        \n",
    "    predictions = model.predict(x)\n",
    "    \n",
    "    correct_prediction = 0\n",
    "    idx = 0\n",
    "    while idx < len(x):\n",
    "        if predictions[idx] == y[idx]:\n",
    "            correct_prediction += 1\n",
    "        idx += 1\n",
    "        \n",
    "    return correct_prediction / idx * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: 2980\n",
      "test data size: 374\n"
     ]
    }
   ],
   "source": [
    "ibc_vocab_knn, ibc_train_data_knn, ibc_test_data_knn = generate_data_knn(ibc_train_data, ibc_val_data, ibc_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(0)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_train(knn, ibc_train_data_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.20855614973262\n"
     ]
    }
   ],
   "source": [
    "print(knn_eval(knn, ibc_test_data_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Ensemble method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_eval(lr_model_ensemble, dt_model_ensemble, knn_model_ensemble, test_data):\n",
    "    num_predictions = 0\n",
    "    num_correct = 0\n",
    "    lr_model_ensemble.eval()\n",
    "    for sentence, target in test_data:\n",
    "        with torch.no_grad():\n",
    "            lr_predictions = torch.argmax(torch.Tensor.cpu(lr_model_ensemble(sentence)), dim=-1)\n",
    "        dt_predictions = dt_model_ensemble.predict(torch.Tensor.cpu(sentence))\n",
    "        knn_predictions = knn_model_ensemble.predict(torch.Tensor.cpu(sentence))\n",
    "\n",
    "        ensemble_predictions = lr_predictions + dt_predictions + knn_predictions\n",
    "        for i in range(len(ensemble_predictions)):\n",
    "            num_predictions += 1\n",
    "            if ensemble_predictions[i] >= 2 and target[i] == 1:\n",
    "                num_correct += 1\n",
    "            elif ensemble_predictions[i] <= 1 and target[i] == 0:\n",
    "                num_correct += 1\n",
    "    \n",
    "    lr_model_ensemble.train()\n",
    "    return num_correct / num_predictions * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.962566844919785\n"
     ]
    }
   ],
   "source": [
    "print(ensemble_eval(lr_model, dt, knn, ibc_test_data_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_rnn(sentence, word_to_id):\n",
    "    return torch.tensor([word_to_id[word] for word in sentence if word in word_to_id]).to(device)\n",
    "\n",
    "def make_target_rnn(label, label_to_id):\n",
    "    return torch.LongTensor([label_to_id[label]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab, output_size, hidden_size):\n",
    "        torch.manual_seed(0)\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.vocab = vocab\n",
    "        self.input_size = len(vocab)\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # dropout\n",
    "#         self.dropout = nn.Dropout()\n",
    "#         self.dropout = LockedDropout()\n",
    "        self.embedding = nn.Embedding(self.input_size, self.hidden_size).to(device)\n",
    "        self.rnn = nn.RNN(self.hidden_size, self.hidden_size).to(device)\n",
    "        self.cat = nn.Linear(self.hidden_size, self.output_size).to(device)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embedding = self.embedding(sentence).unsqueeze(1)\n",
    "#         embedding = self.dropout(embedding)\n",
    "        output, hidden = self.rnn(embedding)\n",
    "        output = output\n",
    "#         output = self.dropout(output)\n",
    "        return F.log_softmax(self.cat(output.squeeze()[-1]), dim=-1).view(1, -1)\n",
    "\n",
    "class RNN_LSTM(nn.Module):\n",
    "    def __init__(self, vocab, output_size, hidden_size):\n",
    "        torch.manual_seed(0)\n",
    "        super(RNN_LSTM, self).__init__()\n",
    "\n",
    "        self.vocab = vocab\n",
    "        self.input_size = len(vocab)\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # dropout\n",
    "#         self.dropout = nn.Dropout()\n",
    "#         self.dropout = LockedDropout()\n",
    "        self.embedding = nn.Embedding(self.input_size, self.hidden_size).to(device)\n",
    "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size).to(device)\n",
    "        self.cat = nn.Linear(self.hidden_size, self.output_size).to(device)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embedding = self.embedding(sentence).unsqueeze(1)\n",
    "#         embedding = self.dropout(embedding)\n",
    "        output, hidden = self.lstm(embedding)\n",
    "        output = output\n",
    "#         output = self.dropout(output)\n",
    "        return F.log_softmax(self.cat(output.squeeze()[-1]), dim=-1).view(1, -1)\n",
    "\n",
    "class RNN_BiLSTM(nn.Module):\n",
    "    def __init__(self, vocab, output_size, hidden_size):\n",
    "        torch.manual_seed(0)\n",
    "        super(RNN_BiLSTM, self).__init__()\n",
    "\n",
    "        self.vocab = vocab\n",
    "        self.input_size = len(vocab)\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # dropout\n",
    "#         self.dropout = nn.Dropout()\n",
    "#         self.dropout = LockedDropout()\n",
    "        self.embedding = nn.Embedding(self.input_size, self.hidden_size).to(device)\n",
    "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size, bidirectional=True).to(device)\n",
    "        self.cat = nn.Linear(self.hidden_size * 2, self.output_size).to(device)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embedding = self.embedding(sentence).unsqueeze(1)\n",
    "#         embedding = self.dropout(embedding)\n",
    "        output, hidden = self.lstm(embedding)\n",
    "        output = output\n",
    "#         output = self.dropout(output)\n",
    "#         return F.log_softmax(self.cat(output.squeeze()[-1]), dim=-1).view(1, -1)\n",
    "        return F.log_softmax(self.cat(hidden[0].view(-1)), dim=-1).view(1, -1)\n",
    "\n",
    "def rnn_train(model, train_data, valid_data, test_data, loss_function, optimizer, num_epochs=50):\n",
    "    print('Before training:', rnn_eval(model, test_data, loss_function))\n",
    "    best_valid_accuracy = 0\n",
    "    patience = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        iters = 0\n",
    "        total_loss = 0\n",
    "        \n",
    "        for bow_vec, target in train_data:\n",
    "            model.zero_grad()\n",
    "\n",
    "            probs = model(bow_vec[0])\n",
    "            loss = loss_function(probs, target[0])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            iters += 1\n",
    "\n",
    "        # begin validation\n",
    "        valid_loss, valid_accuracy = rnn_eval(model, valid_data, loss_function)\n",
    "        if valid_accuracy > best_valid_accuracy:\n",
    "            patience = 0\n",
    "            best_valid_accuracy = valid_accuracy\n",
    "            torch.save(model, 'rnn_best_valid.model')\n",
    "            print('[{}] Saved best model'.format(epoch + 1))\n",
    "\n",
    "        print('[{}] training loss: {}, validation loss: {}, validation accuracy: {}'.format(epoch + 1, total_loss / iters, valid_loss, valid_accuracy))\n",
    "    \n",
    "    print('After training:', rnn_eval(model, test_data, loss_function))\n",
    "        \n",
    "\n",
    "def rnn_eval(model, data, loss_function):\n",
    "    model.eval()\n",
    "    num_predictions = 0\n",
    "    num_correct = 0\n",
    "    total_loss = 0\n",
    "    for sentence, target in data:\n",
    "        with torch.no_grad():\n",
    "            probs = model(sentence[0])\n",
    "            loss = loss_function(probs, target[0])\n",
    "        total_loss += loss.item()\n",
    "        num_predictions += 1\n",
    "        if (torch.argmax(probs) == target[0]):\n",
    "            num_correct += 1\n",
    "    model.train()\n",
    "    return total_loss/num_predictions, num_correct/num_predictions*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibc_vocab_rnn, ibc_train_data_rnn, ibc_val_data_rnn, ibc_test_data_rnn = generate_data_loader(ibc_train_data,\n",
    "                                                                               ibc_val_data,\n",
    "                                                                               ibc_test_data,\n",
    "                                                                               make_feature_rnn,\n",
    "                                                                               make_target_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training: (0.7164431756192987, 50.534759358288774)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Saved best model\n",
      "[1] training loss: 0.7032935611753656, validation loss: 0.6936856418527583, validation accuracy: 56.451612903225815\n",
      "[2] training loss: 0.6771213473189597, validation loss: 0.6951153573169503, validation accuracy: 55.91397849462365\n",
      "[3] training loss: 0.6647767246769579, validation loss: 0.6992007501984155, validation accuracy: 55.376344086021504\n",
      "[4] training loss: 0.6527841143360074, validation loss: 0.7050893772193181, validation accuracy: 55.91397849462365\n",
      "[5] training loss: 0.6420569313052517, validation loss: 0.7126990039983103, validation accuracy: 52.956989247311824\n",
      "[6] training loss: 0.6299102134652586, validation loss: 0.7218775775644087, validation accuracy: 54.03225806451613\n",
      "[7] training loss: 0.6173382380164709, validation loss: 0.7357503862310482, validation accuracy: 52.956989247311824\n",
      "[8] training loss: 0.6029040044886154, validation loss: 0.7535924705606635, validation accuracy: 51.61290322580645\n",
      "[9] training loss: 0.5848770040293668, validation loss: 0.7756210122938438, validation accuracy: 52.41935483870967\n",
      "[10] training loss: 0.5652801672584259, validation loss: 0.8050676790937301, validation accuracy: 49.46236559139785\n",
      "[11] training loss: 0.5439444339315364, validation loss: 0.8343006371650644, validation accuracy: 50.53763440860215\n",
      "[12] training loss: 0.5183148087221104, validation loss: 0.8574713057567996, validation accuracy: 49.73118279569893\n",
      "[13] training loss: 0.49063702789729075, validation loss: 0.9217847724274922, validation accuracy: 49.193548387096776\n",
      "[14] training loss: 0.45826934184504037, validation loss: 0.9579989432647664, validation accuracy: 47.8494623655914\n",
      "[15] training loss: 0.4234436972679308, validation loss: 1.0174521162945738, validation accuracy: 47.8494623655914\n",
      "[16] training loss: 0.3769061496243781, validation loss: 1.105422379909664, validation accuracy: 45.96774193548387\n",
      "[17] training loss: 0.3276209863290291, validation loss: 1.2218952127682265, validation accuracy: 47.8494623655914\n",
      "[18] training loss: 0.2748960765966233, validation loss: 1.3473996759582592, validation accuracy: 46.774193548387096\n",
      "[19] training loss: 0.2167074035578126, validation loss: 1.4871582032371593, validation accuracy: 49.73118279569893\n",
      "[20] training loss: 0.16040457891637847, validation loss: 1.64612427610223, validation accuracy: 49.193548387096776\n",
      "[21] training loss: 0.12372334802010715, validation loss: 1.7895789760094818, validation accuracy: 48.38709677419355\n",
      "[22] training loss: 0.08730604060544264, validation loss: 2.0147433676706847, validation accuracy: 46.50537634408602\n",
      "[23] training loss: 0.06215419534768834, validation loss: 2.07204113996798, validation accuracy: 47.043010752688176\n",
      "[24] training loss: 0.04951780077395023, validation loss: 2.169898930896995, validation accuracy: 49.46236559139785\n",
      "[25] training loss: 0.04462502018717311, validation loss: 2.294155024232403, validation accuracy: 47.31182795698925\n",
      "[26] training loss: 0.040953027301986744, validation loss: 2.2964645833257706, validation accuracy: 47.58064516129033\n",
      "[27] training loss: 0.03467077766388855, validation loss: 2.3394305906308595, validation accuracy: 48.38709677419355\n",
      "[28] training loss: 0.03280836453773831, validation loss: 2.4082687135825873, validation accuracy: 46.774193548387096\n",
      "[29] training loss: 0.026795811161098863, validation loss: 2.482352817010495, validation accuracy: 48.11827956989247\n",
      "[30] training loss: 0.029891852624464355, validation loss: 2.4901171230500743, validation accuracy: 46.50537634408602\n",
      "[31] training loss: 0.02464682015796636, validation loss: 2.5371443823941293, validation accuracy: 46.774193548387096\n",
      "[32] training loss: 0.025228739344833682, validation loss: 2.584357628899236, validation accuracy: 47.043010752688176\n",
      "[33] training loss: 0.022866030507439735, validation loss: 2.5600778313093286, validation accuracy: 47.31182795698925\n",
      "[34] training loss: 0.021486289829215747, validation loss: 2.640069746602607, validation accuracy: 47.043010752688176\n",
      "[35] training loss: 0.02236187786063892, validation loss: 2.655312642455101, validation accuracy: 46.236559139784944\n",
      "[36] training loss: 0.019252412151170257, validation loss: 2.7085203893723024, validation accuracy: 47.043010752688176\n",
      "[37] training loss: 0.018555406045993702, validation loss: 2.6749785999937723, validation accuracy: 47.58064516129033\n",
      "[38] training loss: 0.017828237750386233, validation loss: 2.698934286352127, validation accuracy: 48.11827956989247\n",
      "[39] training loss: 0.017038869417753795, validation loss: 2.7474261025587716, validation accuracy: 47.043010752688176\n",
      "[40] training loss: 0.01657254799900439, validation loss: 2.722425895592859, validation accuracy: 49.73118279569893\n",
      "[41] training loss: 0.016329957314785697, validation loss: 2.756849978719988, validation accuracy: 48.38709677419355\n",
      "[42] training loss: 0.01541068814944901, validation loss: 2.815327146841634, validation accuracy: 47.8494623655914\n",
      "[43] training loss: 0.016202056177910543, validation loss: 2.8184457682473685, validation accuracy: 46.50537634408602\n",
      "[44] training loss: 0.014658516535422945, validation loss: 2.8319404621117856, validation accuracy: 48.655913978494624\n",
      "[45] training loss: 0.014725606053467564, validation loss: 2.864006669691173, validation accuracy: 47.58064516129033\n",
      "[46] training loss: 0.013675408165326855, validation loss: 2.842701183932443, validation accuracy: 47.58064516129033\n",
      "[47] training loss: 0.01297454890988817, validation loss: 2.8752322426886967, validation accuracy: 47.31182795698925\n",
      "[48] training loss: 0.01265793877760036, validation loss: 2.9125784649163164, validation accuracy: 47.31182795698925\n",
      "[49] training loss: 0.013277810451968405, validation loss: 2.9407265085366463, validation accuracy: 46.774193548387096\n",
      "[50] training loss: 0.012624462918947208, validation loss: 2.9442059329600743, validation accuracy: 47.043010752688176\n",
      "After training: (2.447482792929532, 56.417112299465245)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "rnn_model = RNN(ibc_vocab_rnn, 2, 150)\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(rnn_model.parameters(), lr=0.001)\n",
    "num_epochs = 50\n",
    "\n",
    "rnn_train(rnn_model, ibc_train_data_rnn, ibc_val_data_rnn, ibc_test_data_rnn, loss_function, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training: (0.7101112781042721, 41.17647058823529)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type RNN_LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Saved best model\n",
      "[1] training loss: 0.6964924912024665, validation loss: 0.6947921786897926, validation accuracy: 53.494623655913976\n",
      "[2] training loss: 0.6887304395037209, validation loss: 0.6924741173623711, validation accuracy: 53.494623655913976\n",
      "[3] Saved best model\n",
      "[3] training loss: 0.6848773994801829, validation loss: 0.6908633350044169, validation accuracy: 54.83870967741935\n",
      "[4] Saved best model\n",
      "[4] training loss: 0.6812694555360999, validation loss: 0.6895922466471631, validation accuracy: 55.107526881720425\n",
      "[5] Saved best model\n",
      "[5] training loss: 0.6775854246228333, validation loss: 0.6886045311086921, validation accuracy: 56.72043010752689\n",
      "[6] Saved best model\n",
      "[6] training loss: 0.6740302998947617, validation loss: 0.6881247667535659, validation accuracy: 56.98924731182796\n",
      "[7] training loss: 0.6702533440301882, validation loss: 0.6880480337046808, validation accuracy: 55.107526881720425\n",
      "[8] training loss: 0.666270576017415, validation loss: 0.6883465436998234, validation accuracy: 55.107526881720425\n",
      "[9] training loss: 0.6621135068519803, validation loss: 0.6891575164051467, validation accuracy: 54.3010752688172\n",
      "[10] training loss: 0.6577265491421591, validation loss: 0.6905649064048645, validation accuracy: 54.03225806451613\n",
      "[11] training loss: 0.6531671245226124, validation loss: 0.6924326580057862, validation accuracy: 54.83870967741935\n",
      "[12] training loss: 0.6486237329624643, validation loss: 0.694623367760771, validation accuracy: 53.2258064516129\n",
      "[13] training loss: 0.6435783333826385, validation loss: 0.6977819717058571, validation accuracy: 53.2258064516129\n",
      "[14] training loss: 0.6387987277751801, validation loss: 0.7002403551852832, validation accuracy: 52.956989247311824\n",
      "[15] training loss: 0.6336431745014734, validation loss: 0.7035867074324239, validation accuracy: 53.76344086021505\n",
      "[16] training loss: 0.6281228733442774, validation loss: 0.7071854202978073, validation accuracy: 52.956989247311824\n",
      "[17] training loss: 0.6224739166414177, validation loss: 0.7106504675040963, validation accuracy: 53.494623655913976\n",
      "[18] training loss: 0.6161191294057258, validation loss: 0.7145268359491902, validation accuracy: 53.2258064516129\n",
      "[19] training loss: 0.6094309833725827, validation loss: 0.7184642895415265, validation accuracy: 52.68817204301075\n",
      "[20] training loss: 0.6023000344734064, validation loss: 0.7229333890061225, validation accuracy: 53.76344086021505\n",
      "[21] training loss: 0.5945407588909937, validation loss: 0.7268746889406635, validation accuracy: 53.2258064516129\n",
      "[22] training loss: 0.5858334195893883, validation loss: 0.7311641222206495, validation accuracy: 52.956989247311824\n",
      "[23] training loss: 0.5769940744310418, validation loss: 0.7355517726591838, validation accuracy: 51.344086021505376\n",
      "[24] training loss: 0.5669268010946729, validation loss: 0.7405423751922064, validation accuracy: 51.075268817204304\n",
      "[25] training loss: 0.5556947185789178, validation loss: 0.7468301389486559, validation accuracy: 52.956989247311824\n",
      "[26] training loss: 0.5444535634561674, validation loss: 0.7508424010968977, validation accuracy: 52.956989247311824\n",
      "[27] training loss: 0.5316883691605305, validation loss: 0.7552271091168926, validation accuracy: 54.03225806451613\n",
      "[28] training loss: 0.5180283156717383, validation loss: 0.7612187463429666, validation accuracy: 55.64516129032258\n",
      "[29] training loss: 0.503506990647156, validation loss: 0.7688700337243336, validation accuracy: 52.956989247311824\n",
      "[30] training loss: 0.48794397100706227, validation loss: 0.7761691485842069, validation accuracy: 55.376344086021504\n",
      "[31] training loss: 0.4721485422961664, validation loss: 0.7803370453497415, validation accuracy: 55.107526881720425\n",
      "[32] training loss: 0.45508406536291107, validation loss: 0.7888768438690452, validation accuracy: 55.107526881720425\n",
      "[33] training loss: 0.4372937150649576, validation loss: 0.791411379492411, validation accuracy: 55.107526881720425\n",
      "[34] training loss: 0.4188098126709861, validation loss: 0.798997678263213, validation accuracy: 55.91397849462365\n",
      "[35] training loss: 0.40004088662614756, validation loss: 0.8067520496345335, validation accuracy: 56.98924731182796\n",
      "[36] training loss: 0.3795129581785842, validation loss: 0.8166359254429417, validation accuracy: 56.98924731182796\n",
      "[37] training loss: 0.3592798408445896, validation loss: 0.8256195427909974, validation accuracy: 54.83870967741935\n",
      "[38] training loss: 0.3377026347305951, validation loss: 0.8360060528721861, validation accuracy: 56.451612903225815\n",
      "[39] training loss: 0.31498543860128264, validation loss: 0.8469874988640508, validation accuracy: 56.451612903225815\n",
      "[40] training loss: 0.2920173749627683, validation loss: 0.8685086405565662, validation accuracy: 56.18279569892473\n",
      "[41] training loss: 0.27054990381002425, validation loss: 0.8714439576511742, validation accuracy: 56.98924731182796\n",
      "[42] training loss: 0.2459092808649844, validation loss: 0.894911057686293, validation accuracy: 55.64516129032258\n",
      "[43] training loss: 0.22492899197660038, validation loss: 0.9198029496336496, validation accuracy: 56.18279569892473\n",
      "[44] Saved best model\n",
      "[44] training loss: 0.20125930285293783, validation loss: 0.9183519146134776, validation accuracy: 58.333333333333336\n",
      "[45] Saved best model\n",
      "[45] training loss: 0.1803983124510554, validation loss: 0.9420135094113248, validation accuracy: 58.87096774193549\n",
      "[46] training loss: 0.15928804879420555, validation loss: 0.965326253685259, validation accuracy: 58.602150537634415\n",
      "[47] Saved best model\n",
      "[47] training loss: 0.13887796279968032, validation loss: 0.9912230881151333, validation accuracy: 59.13978494623656\n",
      "[48] Saved best model\n",
      "[48] training loss: 0.12140380886177089, validation loss: 1.0148813891955601, validation accuracy: 59.946236559139784\n",
      "[49] training loss: 0.1057448200531454, validation loss: 1.0394924666772607, validation accuracy: 58.602150537634415\n",
      "[50] training loss: 0.09144281150910678, validation loss: 1.085219611243535, validation accuracy: 58.602150537634415\n",
      "After training: (0.9857183691652064, 57.75401069518716)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "rnn_lstm_model = RNN_LSTM(ibc_vocab_rnn, 2, 150)\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(rnn_lstm_model.parameters(), lr=0.001)\n",
    "num_epochs = 50\n",
    "\n",
    "rnn_train(rnn_lstm_model, ibc_train_data_rnn, ibc_val_data_rnn, ibc_test_data_rnn, loss_function, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training: (0.693911278630323, 50.534759358288774)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type RNN_BiLSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Saved best model\n",
      "[1] training loss: 0.6928777187362614, validation loss: 0.6922219839467797, validation accuracy: 50.53763440860215\n",
      "[2] Saved best model\n",
      "[2] training loss: 0.6859231516818872, validation loss: 0.6914576848828664, validation accuracy: 52.41935483870967\n",
      "[3] training loss: 0.6807285616861893, validation loss: 0.6915054769926173, validation accuracy: 51.075268817204304\n",
      "[4] training loss: 0.6762065653832967, validation loss: 0.6915156550465091, validation accuracy: 51.344086021505376\n",
      "[5] training loss: 0.6709951802288125, validation loss: 0.6921580973812329, validation accuracy: 52.41935483870967\n",
      "[6] Saved best model\n",
      "[6] training loss: 0.6661480002055232, validation loss: 0.6929216340825122, validation accuracy: 53.2258064516129\n",
      "[7] training loss: 0.6605155876618903, validation loss: 0.6942488842753953, validation accuracy: 52.68817204301075\n",
      "[8] training loss: 0.654732222135035, validation loss: 0.6958320694424773, validation accuracy: 52.41935483870967\n",
      "[9] Saved best model\n",
      "[9] training loss: 0.6485906563149203, validation loss: 0.6979681955229852, validation accuracy: 54.03225806451613\n",
      "[10] training loss: 0.6419831449453463, validation loss: 0.700775693340968, validation accuracy: 53.494623655913976\n",
      "[11] training loss: 0.6351319991602193, validation loss: 0.7041636488290244, validation accuracy: 53.494623655913976\n",
      "[12] training loss: 0.6280105379903876, validation loss: 0.7076854291622356, validation accuracy: 53.76344086021505\n",
      "[13] training loss: 0.6205355177689719, validation loss: 0.7122647972196661, validation accuracy: 52.956989247311824\n",
      "[14] training loss: 0.6131076516221033, validation loss: 0.7167816996093719, validation accuracy: 53.494623655913976\n",
      "[15] training loss: 0.6051982397501101, validation loss: 0.7217216796131545, validation accuracy: 54.03225806451613\n",
      "[16] training loss: 0.5971196239526639, validation loss: 0.7270766782664484, validation accuracy: 53.2258064516129\n",
      "[17] training loss: 0.5885654164240665, validation loss: 0.7329884581668402, validation accuracy: 54.03225806451613\n",
      "[18] training loss: 0.5800755468290925, validation loss: 0.7384478488276082, validation accuracy: 53.2258064516129\n",
      "[19] Saved best model\n",
      "[19] training loss: 0.5709337620027113, validation loss: 0.7448363602962546, validation accuracy: 54.3010752688172\n",
      "[20] training loss: 0.5612528129312016, validation loss: 0.7510300470135545, validation accuracy: 54.3010752688172\n",
      "[21] training loss: 0.551312485807294, validation loss: 0.7572033160155819, validation accuracy: 53.2258064516129\n",
      "[22] training loss: 0.5406429207264977, validation loss: 0.7632629619811171, validation accuracy: 53.2258064516129\n",
      "[23] training loss: 0.5291522449495009, validation loss: 0.7705666970020981, validation accuracy: 53.76344086021505\n",
      "[24] training loss: 0.5171758593228839, validation loss: 0.7776488708232039, validation accuracy: 52.956989247311824\n",
      "[25] training loss: 0.5044725458593976, validation loss: 0.7831674013887683, validation accuracy: 53.2258064516129\n",
      "[26] training loss: 0.4912848705513365, validation loss: 0.7892767207757119, validation accuracy: 52.956989247311824\n",
      "[27] training loss: 0.47725693839508415, validation loss: 0.7955292594689195, validation accuracy: 53.2258064516129\n",
      "[28] training loss: 0.4623374361219822, validation loss: 0.803076025539188, validation accuracy: 52.956989247311824\n",
      "[29] training loss: 0.44653690482346003, validation loss: 0.8102658029685739, validation accuracy: 52.956989247311824\n",
      "[30] training loss: 0.43044103168001113, validation loss: 0.819270324723054, validation accuracy: 53.494623655913976\n",
      "[31] training loss: 0.4133239419768321, validation loss: 0.8275473943801337, validation accuracy: 52.68817204301075\n",
      "[32] training loss: 0.39593685003335044, validation loss: 0.8376255987151977, validation accuracy: 52.68817204301075\n",
      "[33] training loss: 0.3780332748821918, validation loss: 0.8439306839499422, validation accuracy: 52.41935483870967\n",
      "[34] training loss: 0.35976011835088667, validation loss: 0.8504480717162932, validation accuracy: 51.88172043010753\n",
      "[35] training loss: 0.34107552528781376, validation loss: 0.8588323315144867, validation accuracy: 53.2258064516129\n",
      "[36] training loss: 0.32284119288193297, validation loss: 0.8690579894890067, validation accuracy: 52.1505376344086\n",
      "[37] training loss: 0.3039447801525161, validation loss: 0.8793148317484445, validation accuracy: 53.2258064516129\n",
      "[38] training loss: 0.28570765488899796, validation loss: 0.8948126158086203, validation accuracy: 53.2258064516129\n",
      "[39] training loss: 0.26731616617649195, validation loss: 0.9078696322056555, validation accuracy: 53.494623655913976\n",
      "[40] training loss: 0.24933723926344173, validation loss: 0.9230653364011037, validation accuracy: 53.2258064516129\n",
      "[41] training loss: 0.23172999062394137, validation loss: 0.9371293820040201, validation accuracy: 53.2258064516129\n",
      "[42] training loss: 0.21473135385137276, validation loss: 0.9501744745078907, validation accuracy: 52.68817204301075\n",
      "[43] training loss: 0.19888537750148133, validation loss: 0.9690229817423769, validation accuracy: 53.494623655913976\n",
      "[44] training loss: 0.18274995650621068, validation loss: 0.9877348769736546, validation accuracy: 52.956989247311824\n",
      "[45] training loss: 0.16800791372188786, validation loss: 1.004860093596802, validation accuracy: 52.68817204301075\n",
      "[46] training loss: 0.15389482549972983, validation loss: 1.0259468950411326, validation accuracy: 52.68817204301075\n",
      "[47] training loss: 0.1412043966202928, validation loss: 1.047243970376189, validation accuracy: 54.03225806451613\n",
      "[48] training loss: 0.12931705353244038, validation loss: 1.06556699657312, validation accuracy: 53.494623655913976\n",
      "[49] training loss: 0.11784548895471048, validation loss: 1.0811182142746063, validation accuracy: 53.494623655913976\n",
      "[50] training loss: 0.10749959149616677, validation loss: 1.0994279446300639, validation accuracy: 53.76344086021505\n",
      "After training: (0.8932636083766101, 61.49732620320856)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "rnn_bilstm_model = RNN_BiLSTM(ibc_vocab_rnn, 2, 150)\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(rnn_bilstm_model.parameters(), lr=0.001)\n",
    "num_epochs = 50\n",
    "\n",
    "rnn_train(rnn_bilstm_model, ibc_train_data_rnn, ibc_val_data_rnn, ibc_test_data_rnn, loss_function, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Random insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonym(word):\n",
    "    replacements = []\n",
    "    for syn in wn.synsets(word):\n",
    "        syn_word = syn.name().split('.')[0]\n",
    "        if syn_word != word and re.match('\\w', word):\n",
    "            replacements.append(syn_word)\n",
    "            \n",
    "    if len(replacements) > 0:\n",
    "        return replacements[randint(0, len(replacements) - 1)]\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "def random_insertion(sentence, alpha=0.1):\n",
    "    new_sentence = sentence.copy()\n",
    "    for i in range(int(len(sentence) * 0.1)):\n",
    "        syn = get_synonym(sentence[randint(0, len(sentence) - 1)])\n",
    "        if syn:\n",
    "            new_sentence.insert(randint(0, len(new_sentence)), syn)\n",
    "        \n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "\n",
    "ibc_train_data_ri = []\n",
    "for sentence, label in ibc_train_data:\n",
    "    ibc_train_data_ri.append((random_insertion(sentence), label))\n",
    "    \n",
    "ibc_train_data_ri += ibc_train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibc_vocab_lr_ri, ibc_train_data_loader_lr_ri, ibc_val_data_loader_lr_ri, ibc_test_data_loader_lr_ri = generate_data_loader(ibc_train_data_ri,\n",
    "                                                                                                   ibc_val_data,\n",
    "                                                                                                   ibc_test_data,\n",
    "                                                                                                   make_bow_vec_lr,\n",
    "                                                                                                   make_label_lr,\n",
    "                                                                                                   {\"LIBERAL\": 0, \"CONSERVATIVE\": 1},\n",
    "                                                                                                   batch_size=16,\n",
    "                                                                                                   cutoff=1\n",
    "                                                                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.20855614973262\n",
      "10: 66.66666666666666\n",
      "20: 68.27956989247312\n",
      "30: 67.74193548387096\n",
      "40: 66.93548387096774\n",
      "50: 66.93548387096774\n",
      "60: 66.66666666666666\n",
      "70: 66.66666666666666\n",
      "80: 66.66666666666666\n",
      "90: 66.66666666666666\n",
      "100: 66.66666666666666\n",
      "64.70588235294117\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "lr_model_ri = BoWClassifier(ibc_vocab_lr_ri, 2)\n",
    "\n",
    "print(lr_eval(lr_model_ri, ibc_test_data_loader_lr_ri))\n",
    "lr_train(lr_model_ri, ibc_train_data_loader_lr_ri, ibc_val_data_loader_lr_ri, num_epochs=100)\n",
    "print(lr_eval(lr_model_ri, ibc_test_data_loader_lr_ri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: 5960\n",
      "test data size: 374\n"
     ]
    }
   ],
   "source": [
    "ibc_vocab_dt_ri, ibc_train_data_dt_ri, ibc_test_data_dt_ri = generate_data_dt(ibc_train_data_ri, ibc_val_data, ibc_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(0)\n",
    "dt_ri = DCT()\n",
    "dt_train(dt_ri, ibc_train_data_dt_ri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.68449197860963\n"
     ]
    }
   ],
   "source": [
    "print(dt_eval(dt_ri, ibc_test_data_dt_ri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: 5960\n",
      "test data size: 374\n"
     ]
    }
   ],
   "source": [
    "ibc_vocab_knn_ri, ibc_train_data_knn_ri, ibc_test_data_knn_ri = generate_data_knn(ibc_train_data_ri, ibc_val_data, ibc_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(0)\n",
    "knn_ri = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_train(knn_ri, ibc_train_data_knn_ri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.20855614973262\n"
     ]
    }
   ],
   "source": [
    "print(knn_eval(knn_ri, ibc_test_data_knn_ri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.4 Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.6951871657754\n"
     ]
    }
   ],
   "source": [
    "print(ensemble_eval(lr_model_ri, dt_ri, knn_ri, ibc_test_data_loader_lr_ri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.5 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibc_vocab_rnn_ri, ibc_train_data_rnn_ri, ibc_val_data_rnn_ri, ibc_test_data_rnn_ri = generate_data_loader(ibc_train_data_ri,\n",
    "                                                                               ibc_val_data,\n",
    "                                                                               ibc_test_data,\n",
    "                                                                               make_feature_rnn,\n",
    "                                                                               make_target_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training: (0.7060735285441506, 52.406417112299465)\n",
      "[1] Saved best model\n",
      "[1] training loss: 0.6902853396814942, validation loss: 0.7117355913724951, validation accuracy: 49.73118279569893\n",
      "[2] Saved best model\n",
      "[2] training loss: 0.6632371385925568, validation loss: 0.7181852195532091, validation accuracy: 52.1505376344086\n",
      "[3] training loss: 0.6438462856181916, validation loss: 0.7364493775111373, validation accuracy: 52.1505376344086\n",
      "[4] Saved best model\n",
      "[4] training loss: 0.6199658582049529, validation loss: 0.7546904977931771, validation accuracy: 54.83870967741935\n",
      "[5] training loss: 0.5914451123008992, validation loss: 0.796822426299895, validation accuracy: 50.0\n",
      "[6] training loss: 0.5567024489177154, validation loss: 0.8488623361273478, validation accuracy: 51.88172043010753\n",
      "[7] training loss: 0.5176616286121358, validation loss: 0.900085186045016, validation accuracy: 51.61290322580645\n",
      "[8] training loss: 0.4670624262334516, validation loss: 0.9688530219818956, validation accuracy: 50.53763440860215\n",
      "[9] training loss: 0.40358826717324303, validation loss: 1.03009549031655, validation accuracy: 52.956989247311824\n",
      "[10] training loss: 0.3293883807132108, validation loss: 1.0949908139244202, validation accuracy: 51.61290322580645\n",
      "[11] training loss: 0.24889288150624142, validation loss: 1.2402333206226748, validation accuracy: 54.03225806451613\n",
      "[12] training loss: 0.16911818645394489, validation loss: 1.4025908399333236, validation accuracy: 52.68817204301075\n",
      "[13] training loss: 0.10701468270397026, validation loss: 1.6118383930735691, validation accuracy: 50.0\n",
      "[14] training loss: 0.06575852693027298, validation loss: 1.7062499357727907, validation accuracy: 52.41935483870967\n",
      "[15] training loss: 0.0485025025704163, validation loss: 1.8758203561908455, validation accuracy: 54.3010752688172\n",
      "[16] training loss: 0.03891827559611141, validation loss: 1.9416259018483983, validation accuracy: 51.344086021505376\n",
      "[17] training loss: 0.02759590863481464, validation loss: 1.9719143522683011, validation accuracy: 51.61290322580645\n",
      "[18] training loss: 0.027999149927956945, validation loss: 2.0325877053603048, validation accuracy: 53.76344086021505\n",
      "[19] training loss: 0.025743746162460956, validation loss: 2.1006058373598644, validation accuracy: 52.956989247311824\n",
      "[20] training loss: 0.018084836641214037, validation loss: 2.119415833825065, validation accuracy: 53.494623655913976\n",
      "[21] training loss: 0.02131537532546376, validation loss: 2.116459587889333, validation accuracy: 53.2258064516129\n",
      "[22] training loss: 0.016008484828592146, validation loss: 2.181008303197481, validation accuracy: 50.806451612903224\n",
      "[23] training loss: 0.014787509267362171, validation loss: 2.1924240441732508, validation accuracy: 54.03225806451613\n",
      "[24] training loss: 0.014810365598473773, validation loss: 2.174370030882538, validation accuracy: 52.68817204301075\n",
      "[25] training loss: 0.011474729589367873, validation loss: 2.2625232974207528, validation accuracy: 51.88172043010753\n",
      "[26] training loss: 0.012636650273663886, validation loss: 2.3313314473276496, validation accuracy: 51.61290322580645\n",
      "[27] training loss: 0.013981173342506358, validation loss: 2.324631191149194, validation accuracy: 51.88172043010753\n",
      "[28] training loss: 0.011473229942505792, validation loss: 2.295540816721416, validation accuracy: 52.956989247311824\n",
      "[29] training loss: 0.01110214298503511, validation loss: 2.3104534658693496, validation accuracy: 53.494623655913976\n",
      "[30] training loss: 0.011458925032775675, validation loss: 2.323105261290586, validation accuracy: 52.41935483870967\n",
      "[31] training loss: 0.009294443802545535, validation loss: 2.36132060528122, validation accuracy: 54.03225806451613\n",
      "[32] training loss: 0.01031458387338875, validation loss: 2.364076616062272, validation accuracy: 52.41935483870967\n",
      "[33] training loss: 0.010294569488739807, validation loss: 2.4080866474297737, validation accuracy: 53.2258064516129\n",
      "[34] training loss: 0.010746598153706365, validation loss: 2.399682259767927, validation accuracy: 52.68817204301075\n",
      "[35] training loss: 0.009463561531281311, validation loss: 2.4192919097440218, validation accuracy: 52.68817204301075\n",
      "[36] training loss: 0.00783726623494353, validation loss: 2.4393011618365525, validation accuracy: 52.68817204301075\n",
      "[37] training loss: 0.008545403512532279, validation loss: 2.4729753471510385, validation accuracy: 52.956989247311824\n",
      "[38] training loss: 0.009192037827416554, validation loss: 2.4606291513128946, validation accuracy: 52.68817204301075\n",
      "[39] training loss: 0.008085311059183722, validation loss: 2.455922329457857, validation accuracy: 52.956989247311824\n",
      "[40] training loss: 0.008580544050907928, validation loss: 2.4898077841968305, validation accuracy: 52.68817204301075\n",
      "[41] training loss: 0.008787075250140773, validation loss: 2.50712090834815, validation accuracy: 52.41935483870967\n",
      "[42] training loss: 0.008054715604990121, validation loss: 2.5476985382296706, validation accuracy: 52.68817204301075\n",
      "[43] training loss: 0.008149063697197293, validation loss: 2.512803568474708, validation accuracy: 53.2258064516129\n",
      "[44] training loss: 0.007469293775174442, validation loss: 2.554445817345573, validation accuracy: 52.41935483870967\n",
      "[45] training loss: 0.007308060655857893, validation loss: 2.576770639467624, validation accuracy: 52.956989247311824\n",
      "[46] training loss: 0.007065985546816115, validation loss: 2.545826814027243, validation accuracy: 53.494623655913976\n",
      "[47] training loss: 0.007385044729949644, validation loss: 2.5510640196422094, validation accuracy: 52.41935483870967\n",
      "[48] training loss: 0.007342716066429279, validation loss: 2.5658036630640746, validation accuracy: 53.2258064516129\n",
      "[49] training loss: 0.007330308364541739, validation loss: 2.5949732984105744, validation accuracy: 54.56989247311827\n",
      "[50] training loss: 0.006978827399895495, validation loss: 2.608503467293196, validation accuracy: 52.1505376344086\n",
      "After training: (2.686581368832027, 52.67379679144385)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "rnn_model_ri = RNN(ibc_vocab_rnn_ri, 2, 150)\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(rnn_model_ri.parameters(), lr=0.001)\n",
    "num_epochs = 50\n",
    "\n",
    "rnn_train(rnn_model_ri, ibc_train_data_rnn_ri, ibc_val_data_rnn_ri, ibc_test_data_rnn_ri, loss_function, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Random replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonym(word):\n",
    "    replacements = []\n",
    "    for syn in wn.synsets(word):\n",
    "        syn_word = syn.name().split('.')[0]\n",
    "        if syn_word != word and re.match('\\w', word):\n",
    "            replacements.append(syn_word)\n",
    "            \n",
    "    if len(replacements) > 0:\n",
    "        return replacements[randint(0, len(replacements) - 1)]\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "def random_replacement(sentence, alpha=0.1):\n",
    "    new_sentence = sentence.copy()\n",
    "    for i in range(int(len(sentence) * 0.1)):\n",
    "        word_id = randint(0, len(sentence) - 1)\n",
    "        syn = get_synonym(sentence[word_id])\n",
    "        if syn:\n",
    "            new_sentence[word_id] = syn\n",
    "        \n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "ibc_train_data_rr = []\n",
    "for sentence, label in ibc_train_data:\n",
    "    ibc_train_data_rr.append((random_replacement(sentence), label))\n",
    "    \n",
    "ibc_train_data_rr += ibc_train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibc_vocab_lr_rr, ibc_train_data_loader_lr_rr, ibc_val_data_loader_lr_rr, ibc_test_data_loader_lr_rr = generate_data_loader(ibc_train_data_rr,\n",
    "                                                                                                   ibc_val_data,\n",
    "                                                                                                   ibc_test_data,\n",
    "                                                                                                   make_bow_vec_lr,\n",
    "                                                                                                   make_label_lr,\n",
    "                                                                                                   {\"LIBERAL\": 0, \"CONSERVATIVE\": 1},\n",
    "                                                                                                   batch_size=16,\n",
    "                                                                                                   cutoff=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.534759358288774\n",
      "10: 68.81720430107528\n",
      "20: 69.08602150537635\n",
      "30: 68.54838709677419\n",
      "40: 67.20430107526882\n",
      "50: 66.66666666666666\n",
      "60: 66.39784946236558\n",
      "70: 65.86021505376344\n",
      "80: 65.86021505376344\n",
      "90: 65.86021505376344\n",
      "100: 65.59139784946237\n",
      "63.36898395721925\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "lr_model_rr = BoWClassifier(ibc_vocab_lr_rr, 2)\n",
    "\n",
    "print(lr_eval(lr_model_rr, ibc_test_data_loader_lr_rr))\n",
    "lr_train(lr_model_rr, ibc_train_data_loader_lr_rr, ibc_val_data_loader_lr_rr, num_epochs=100)\n",
    "print(lr_eval(lr_model_rr, ibc_test_data_loader_lr_rr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: 5960\n",
      "test data size: 374\n"
     ]
    }
   ],
   "source": [
    "ibc_vocab_dt_rr, ibc_train_data_dt_rr, ibc_test_data_dt_rr = generate_data_dt(ibc_train_data_rr, ibc_val_data, ibc_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(0)\n",
    "dt_rr = DCT()\n",
    "dt_train(dt_rr, ibc_train_data_dt_rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.417112299465245\n"
     ]
    }
   ],
   "source": [
    "print(dt_eval(dt_rr, ibc_test_data_dt_rr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: 5960\n",
      "test data size: 374\n"
     ]
    }
   ],
   "source": [
    "ibc_vocab_knn_rr, ibc_train_data_knn_rr, ibc_test_data_knn_rr = generate_data_knn(ibc_train_data_rr, ibc_val_data, ibc_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(0)\n",
    "knn_rr = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_train(knn_rr, ibc_train_data_knn_rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.87165775401069\n"
     ]
    }
   ],
   "source": [
    "print(knn_eval(knn_rr, ibc_test_data_knn_rr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.4 Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.16042780748663\n"
     ]
    }
   ],
   "source": [
    "print(ensemble_eval(lr_model_rr, dt_rr, knn_rr, ibc_test_data_loader_lr_rr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.5 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibc_vocab_rnn_rr, ibc_train_data_rnn_rr, ibc_val_data_rnn_rr, ibc_test_data_rnn_rr = generate_data_loader(ibc_train_data_rr,\n",
    "                                                                               ibc_val_data,\n",
    "                                                                               ibc_test_data,\n",
    "                                                                               make_feature_rnn,\n",
    "                                                                               make_target_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training: (0.7368121365493632, 45.18716577540107)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Saved best model\n",
      "[1] training loss: 0.6841355575161092, validation loss: 0.7051241746352565, validation accuracy: 48.655913978494624\n",
      "[2] Saved best model\n",
      "[2] training loss: 0.6543531695718333, validation loss: 0.7300154360071305, validation accuracy: 49.46236559139785\n",
      "[3] Saved best model\n",
      "[3] training loss: 0.6297749183696989, validation loss: 0.7488500791531737, validation accuracy: 50.53763440860215\n",
      "[4] training loss: 0.6023878786212846, validation loss: 0.7900659422720632, validation accuracy: 50.26881720430107\n",
      "[5] Saved best model\n",
      "[5] training loss: 0.5720405528634387, validation loss: 0.8039869560349372, validation accuracy: 53.76344086021505\n",
      "[6] training loss: 0.5350105627146143, validation loss: 0.8631122128296924, validation accuracy: 51.075268817204304\n",
      "[7] training loss: 0.4849059949335236, validation loss: 0.9142731271924511, validation accuracy: 52.41935483870967\n",
      "[8] training loss: 0.42364200362373117, validation loss: 0.9631817279964365, validation accuracy: 52.68817204301075\n",
      "[9] training loss: 0.3474853645735139, validation loss: 1.1066185280039746, validation accuracy: 49.73118279569893\n",
      "[10] Saved best model\n",
      "[10] training loss: 0.2668785063437367, validation loss: 1.2389060275689248, validation accuracy: 54.03225806451613\n",
      "[11] training loss: 0.18893016701276671, validation loss: 1.4497253261907126, validation accuracy: 50.53763440860215\n",
      "[12] training loss: 0.12148721331617976, validation loss: 1.6215377096687593, validation accuracy: 50.806451612903224\n",
      "[13] training loss: 0.07117782723933658, validation loss: 1.8035616150466345, validation accuracy: 51.61290322580645\n",
      "[14] training loss: 0.049132681077958755, validation loss: 1.8707898242339012, validation accuracy: 52.956989247311824\n",
      "[15] training loss: 0.037121030685785636, validation loss: 2.0014617686630576, validation accuracy: 53.2258064516129\n",
      "[16] training loss: 0.026932345980765836, validation loss: 2.1027901221507337, validation accuracy: 52.1505376344086\n",
      "[17] training loss: 0.025976417878730184, validation loss: 2.132673613326524, validation accuracy: 51.61290322580645\n",
      "[18] training loss: 0.02328176865941726, validation loss: 2.2042484339526904, validation accuracy: 52.68817204301075\n",
      "[19] training loss: 0.021437473155108074, validation loss: 2.2440813052397903, validation accuracy: 51.61290322580645\n",
      "[20] Saved best model\n",
      "[20] training loss: 0.019207749080737965, validation loss: 2.2198010497195746, validation accuracy: 54.56989247311827\n",
      "[21] training loss: 0.01582605554753502, validation loss: 2.367134287512751, validation accuracy: 52.41935483870967\n",
      "[22] training loss: 0.013687992565983895, validation loss: 2.426689614051132, validation accuracy: 53.2258064516129\n",
      "[23] training loss: 0.01312902345253317, validation loss: 2.436961524028291, validation accuracy: 51.075268817204304\n",
      "[24] training loss: 0.014404540403977336, validation loss: 2.4189676142507985, validation accuracy: 53.2258064516129\n",
      "[25] training loss: 0.01373330883731778, validation loss: 2.4000250816505444, validation accuracy: 52.956989247311824\n",
      "[26] training loss: 0.01201395610434897, validation loss: 2.4966600835323334, validation accuracy: 52.68817204301075\n",
      "[27] training loss: 0.011328105568485772, validation loss: 2.4521368000936765, validation accuracy: 52.68817204301075\n",
      "[28] training loss: 0.011312166656423735, validation loss: 2.47392252680435, validation accuracy: 52.1505376344086\n",
      "[29] training loss: 0.010762899303996322, validation loss: 2.498256823789048, validation accuracy: 52.68817204301075\n",
      "[30] training loss: 0.010444585798970805, validation loss: 2.5628406019300543, validation accuracy: 52.41935483870967\n",
      "[31] training loss: 0.010389544704816485, validation loss: 2.602362465233572, validation accuracy: 52.1505376344086\n",
      "[32] training loss: 0.009389692159907129, validation loss: 2.6039161738208545, validation accuracy: 53.2258064516129\n",
      "[33] training loss: 0.00917315671107913, validation loss: 2.5990988377441644, validation accuracy: 53.2258064516129\n",
      "[34] training loss: 0.009454899466277769, validation loss: 2.624301685040356, validation accuracy: 51.61290322580645\n",
      "[35] Saved best model\n",
      "[35] training loss: 0.008815235449563736, validation loss: 2.6646661725576206, validation accuracy: 54.83870967741935\n",
      "[36] training loss: 0.009229944891377583, validation loss: 2.628578799225951, validation accuracy: 52.41935483870967\n",
      "[37] training loss: 0.0093475990447422, validation loss: 2.6661837395801338, validation accuracy: 52.1505376344086\n",
      "[38] training loss: 0.009084479730801294, validation loss: 2.692650185877918, validation accuracy: 52.68817204301075\n",
      "[39] training loss: 0.008570744567269447, validation loss: 2.6973748997014058, validation accuracy: 52.41935483870967\n",
      "[40] training loss: 0.008459431963078927, validation loss: 2.7188997983291583, validation accuracy: 52.1505376344086\n",
      "[41] training loss: 0.008349305861348274, validation loss: 2.777718760073185, validation accuracy: 52.68817204301075\n",
      "[42] training loss: 0.008005611463481149, validation loss: 2.760227452282624, validation accuracy: 52.68817204301075\n",
      "[43] training loss: 0.008025396490257058, validation loss: 2.7642538363254197, validation accuracy: 51.61290322580645\n",
      "[44] training loss: 0.007550216866219604, validation loss: 2.793277183848043, validation accuracy: 52.956989247311824\n",
      "[45] training loss: 0.008189954403662842, validation loss: 2.774263495078651, validation accuracy: 52.1505376344086\n",
      "[46] training loss: 0.0072158820277092445, validation loss: 2.8047457476777415, validation accuracy: 52.1505376344086\n",
      "[47] training loss: 0.007876823812523144, validation loss: 2.8120257670199997, validation accuracy: 52.41935483870967\n",
      "[48] training loss: 0.007300148639302926, validation loss: 2.77867350286694, validation accuracy: 53.76344086021505\n",
      "[49] training loss: 0.0077723308547631206, validation loss: 2.78773299853007, validation accuracy: 52.956989247311824\n",
      "[50] training loss: 0.007557333995831893, validation loss: 2.827387587998503, validation accuracy: 52.41935483870967\n",
      "After training: (2.72027967208847, 56.68449197860963)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "rnn_model_rr = RNN(ibc_vocab_rnn_rr, 2, 150)\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(rnn_model_rr.parameters(), lr=0.001)\n",
    "\n",
    "rnn_train(rnn_model_rr, ibc_train_data_rnn_rr, ibc_val_data_rnn_rr, ibc_test_data_rnn_rr, loss_function, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Random deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_deletion(sentence, alpha=0.1):\n",
    "    new_sentence = sentence.copy()\n",
    "    for i in range(int(len(sentence) * 0.1)):\n",
    "        new_sentence.pop(randint(0, len(new_sentence) - 1))\n",
    "        \n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "ibc_train_data_rd = []\n",
    "for sentence, label in ibc_train_data:\n",
    "    ibc_train_data_rd.append((random_deletion(sentence), label))\n",
    "    \n",
    "ibc_train_data_rd += ibc_train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibc_vocab_lr_rd, ibc_train_data_loader_lr_rd, ibc_val_data_loader_lr_rd, ibc_test_data_loader_lr_rd = generate_data_loader(ibc_train_data_rd,\n",
    "                                                                                                   ibc_val_data,\n",
    "                                                                                                   ibc_test_data,\n",
    "                                                                                                   make_bow_vec_lr,\n",
    "                                                                                                   make_label_lr,\n",
    "                                                                                                   {\"LIBERAL\": 0, \"CONSERVATIVE\": 1},\n",
    "                                                                                                   batch_size=16,\n",
    "                                                                                                   cutoff=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.513368983957214\n",
      "10: 69.6236559139785\n",
      "20: 68.27956989247312\n",
      "30: 67.20430107526882\n",
      "40: 66.93548387096774\n",
      "50: 67.47311827956989\n",
      "60: 66.39784946236558\n",
      "70: 66.39784946236558\n",
      "80: 66.39784946236558\n",
      "90: 66.12903225806451\n",
      "100: 65.86021505376344\n",
      "64.1711229946524\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "lr_model_rd = BoWClassifier(ibc_vocab_lr_rd, 2)\n",
    "\n",
    "print(lr_eval(lr_model_rd, ibc_test_data_loader_lr_rd))\n",
    "lr_train(lr_model_rd, ibc_train_data_loader_lr_rd, ibc_val_data_loader_lr_rd, num_epochs=100)\n",
    "print(lr_eval(lr_model_rd, ibc_test_data_loader_lr_rd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: 5960\n",
      "test data size: 374\n"
     ]
    }
   ],
   "source": [
    "ibc_vocab_dt_rd, ibc_train_data_dt_rd, ibc_test_data_dt_rd = generate_data_dt(ibc_train_data_rd, ibc_val_data, ibc_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(0)\n",
    "dt_rd = DCT()\n",
    "dt_train(dt_rd, ibc_train_data_dt_rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.16042780748663\n"
     ]
    }
   ],
   "source": [
    "print(dt_eval(dt_rd, ibc_test_data_dt_rd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: 5960\n",
      "test data size: 374\n"
     ]
    }
   ],
   "source": [
    "ibc_vocab_knn_rd, ibc_train_data_knn_rd, ibc_test_data_knn_rd = generate_data_knn(ibc_train_data_rd, ibc_val_data, ibc_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(0)\n",
    "knn_rd = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_train(knn_rd, ibc_train_data_knn_rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.81283422459893\n"
     ]
    }
   ],
   "source": [
    "print(knn_eval(knn_rd, ibc_test_data_knn_rd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.4 Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.299465240641716\n"
     ]
    }
   ],
   "source": [
    "print(ensemble_eval(lr_model_rd, dt_rd, knn_rd, ibc_test_data_loader_lr_rd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.5 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibc_vocab_rnn_rd, ibc_train_data_rnn_rd, ibc_val_data_rnn_rd, ibc_test_data_rnn_rd = generate_data_loader(ibc_train_data_rd,\n",
    "                                                                               ibc_val_data,\n",
    "                                                                               ibc_test_data,\n",
    "                                                                               make_feature_rnn,\n",
    "                                                                               make_target_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training: (0.7303125680608545, 48.1283422459893)\n",
      "[1] Saved best model\n",
      "[1] training loss: 0.6877565339957707, validation loss: 0.7009653349717458, validation accuracy: 51.344086021505376\n",
      "[2] Saved best model\n",
      "[2] training loss: 0.6598749999681975, validation loss: 0.7108162533371679, validation accuracy: 52.68817204301075\n",
      "[3] training loss: 0.6398006651200504, validation loss: 0.7293691949177814, validation accuracy: 51.88172043010753\n",
      "[4] training loss: 0.6170618657872781, validation loss: 0.7604174076389241, validation accuracy: 49.46236559139785\n",
      "[5] Saved best model\n",
      "[5] training loss: 0.5923387955849203, validation loss: 0.7666598052106878, validation accuracy: 54.56989247311827\n",
      "[6] training loss: 0.5589565623351591, validation loss: 0.7865079056511644, validation accuracy: 52.956989247311824\n",
      "[7] training loss: 0.5175635399209373, validation loss: 0.812721926118097, validation accuracy: 53.2258064516129\n",
      "[8] training loss: 0.4631195663505753, validation loss: 0.8884834837048284, validation accuracy: 54.03225806451613\n",
      "[9] Saved best model\n",
      "[9] training loss: 0.40418097269815084, validation loss: 0.9310286294228287, validation accuracy: 56.18279569892473\n",
      "[10] training loss: 0.32739378736673186, validation loss: 1.053446848546305, validation accuracy: 55.64516129032258\n",
      "[11] training loss: 0.25224446507808346, validation loss: 1.1941559011096596, validation accuracy: 55.376344086021504\n",
      "[12] training loss: 0.17769359483964892, validation loss: 1.2821334125373953, validation accuracy: 55.91397849462365\n",
      "[13] Saved best model\n",
      "[13] training loss: 0.10816738895771888, validation loss: 1.4444169749816258, validation accuracy: 56.72043010752689\n",
      "[14] training loss: 0.07597556724744355, validation loss: 1.7050898417189557, validation accuracy: 54.83870967741935\n",
      "[15] training loss: 0.04985469267422321, validation loss: 1.809205761680039, validation accuracy: 55.107526881720425\n",
      "[16] training loss: 0.037902820412844616, validation loss: 1.7753495710992044, validation accuracy: 55.376344086021504\n",
      "[17] training loss: 0.029896121827147952, validation loss: 1.886097700365128, validation accuracy: 56.18279569892473\n",
      "[18] Saved best model\n",
      "[18] training loss: 0.02137086339444922, validation loss: 1.9819897524611925, validation accuracy: 56.98924731182796\n",
      "[19] training loss: 0.01859680964742731, validation loss: 2.023367553308446, validation accuracy: 56.72043010752689\n",
      "[20] training loss: 0.024748931035099415, validation loss: 2.0100747706588877, validation accuracy: 53.76344086021505\n",
      "[21] training loss: 0.0158648871935454, validation loss: 2.0785425066627483, validation accuracy: 55.107526881720425\n",
      "[22] training loss: 0.0168768309006755, validation loss: 2.0868363207386387, validation accuracy: 55.91397849462365\n",
      "[23] training loss: 0.014051044717331061, validation loss: 2.137745730098217, validation accuracy: 55.64516129032258\n",
      "[24] training loss: 0.014882340057184232, validation loss: 2.1847334180868443, validation accuracy: 56.98924731182796\n",
      "[25] training loss: 0.013499172461912935, validation loss: 2.1128633176126788, validation accuracy: 55.91397849462365\n",
      "[26] training loss: 0.011884255847274858, validation loss: 2.1764319116069424, validation accuracy: 55.376344086021504\n",
      "[27] Saved best model\n",
      "[27] training loss: 0.012288646299967029, validation loss: 2.2237747470217366, validation accuracy: 57.52688172043011\n",
      "[28] training loss: 0.011663276352138327, validation loss: 2.2132089225355016, validation accuracy: 57.52688172043011\n",
      "[29] Saved best model\n",
      "[29] training loss: 0.010086150737416824, validation loss: 2.2642536143301637, validation accuracy: 58.602150537634415\n",
      "[30] training loss: 0.011388677568643686, validation loss: 2.2614122644387264, validation accuracy: 55.91397849462365\n",
      "[31] training loss: 0.011083970658931156, validation loss: 2.2429357169055812, validation accuracy: 57.52688172043011\n",
      "[32] training loss: 0.00847866647195496, validation loss: 2.313019794401943, validation accuracy: 57.52688172043011\n",
      "[33] training loss: 0.009517790997188363, validation loss: 2.3467274244113634, validation accuracy: 56.72043010752689\n",
      "[34] training loss: 0.009478747664682017, validation loss: 2.3065104795399534, validation accuracy: 56.72043010752689\n",
      "[35] training loss: 0.008460862704571461, validation loss: 2.351575243537144, validation accuracy: 57.795698924731184\n",
      "[36] training loss: 0.010041819872872141, validation loss: 2.360666013292728, validation accuracy: 57.795698924731184\n",
      "[37] Saved best model\n",
      "[37] training loss: 0.0086536872856969, validation loss: 2.367581951281717, validation accuracy: 58.87096774193549\n",
      "[38] training loss: 0.008292574915509896, validation loss: 2.411211915073856, validation accuracy: 56.451612903225815\n",
      "[39] training loss: 0.009076284032140003, validation loss: 2.4229488424876684, validation accuracy: 58.333333333333336\n",
      "[40] training loss: 0.008048457427312864, validation loss: 2.4449611006564993, validation accuracy: 56.451612903225815\n",
      "[41] training loss: 0.008450095890552406, validation loss: 2.4153673217822145, validation accuracy: 57.25806451612904\n",
      "[42] training loss: 0.007862426590599469, validation loss: 2.3967782972400546, validation accuracy: 56.98924731182796\n",
      "[43] training loss: 0.008504840046567404, validation loss: 2.454618505893215, validation accuracy: 57.25806451612904\n",
      "[44] training loss: 0.00762471426653382, validation loss: 2.4593991279121368, validation accuracy: 56.98924731182796\n",
      "[45] Saved best model\n",
      "[45] training loss: 0.007544751655335394, validation loss: 2.5278395704364263, validation accuracy: 59.13978494623656\n",
      "[46] training loss: 0.007294937423211616, validation loss: 2.509318793332705, validation accuracy: 56.18279569892473\n",
      "[47] training loss: 0.007823398689295621, validation loss: 2.5208586999165115, validation accuracy: 57.52688172043011\n",
      "[48] training loss: 0.007336474250026997, validation loss: 2.4994006934024955, validation accuracy: 59.13978494623656\n",
      "[49] training loss: 0.006954562534021851, validation loss: 2.536658224639713, validation accuracy: 57.795698924731184\n",
      "[50] training loss: 0.007488353370420085, validation loss: 2.5364254214750823, validation accuracy: 57.52688172043011\n",
      "After training: (2.6703713104367894, 54.54545454545454)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "rnn_model_rd = RNN(ibc_vocab_rnn_rd, 2, 150)\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(rnn_model_rd.parameters(), lr=0.001)\n",
    "\n",
    "rnn_train(rnn_model_rd, ibc_train_data_rnn_rd, ibc_val_data_rnn_rd, ibc_test_data_rnn_rd, loss_function, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ibc_data_fasttext():\n",
    "    [lib, con, neutral] = pickle.load(open('{}full_ibc/ibcData.pkl'.format(data_path), 'rb'))\n",
    "\n",
    "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    ibc_lib = [(tree.get_words().lower(), \"LIBERAL\") for tree in lib]\n",
    "    ibc_con = [(tree.get_words().lower(), \"CONSERVATIVE\") for tree in con]\n",
    "    ibc_full_data = ibc_lib + ibc_con\n",
    "\n",
    "    ibc_lib_size = len(ibc_lib)\n",
    "    ibc_lib_train_size = int(ibc_lib_size*0.8)\n",
    "    ibc_lib_val_size = int(ibc_lib_size*0.1)\n",
    "    ibc_lib_test_size = ibc_lib_size - ibc_lib_train_size - ibc_lib_val_size\n",
    "    ibc_lib_train_data, ibc_lib_val_data, ibc_lib_test_data = torch.utils.data.random_split(ibc_lib, [ibc_lib_train_size, ibc_lib_val_size, ibc_lib_test_size])\n",
    "    \n",
    "    ibc_con_size = len(ibc_con)\n",
    "    ibc_con_train_size = int(ibc_con_size*0.8)\n",
    "    ibc_con_val_size = int(ibc_con_size*0.1)\n",
    "    ibc_con_test_size = ibc_con_size - ibc_con_train_size - ibc_con_val_size\n",
    "    ibc_con_train_data, ibc_con_val_data, ibc_con_test_data = torch.utils.data.random_split(ibc_con, [ibc_con_train_size, ibc_con_val_size, ibc_con_test_size])\n",
    "\n",
    "    ibc_train_data = ibc_lib_train_data + ibc_con_train_data\n",
    "    ibc_val_data = ibc_lib_val_data + ibc_con_val_data\n",
    "    ibc_test_data = ibc_lib_test_data + ibc_con_test_data\n",
    "    ibc_labels = {\"LIBERAL\": 0, \"CONSERVATIVE\": 1}\n",
    "    \n",
    "    print('training data size:', len(ibc_train_data))\n",
    "    print('validation data size:', len(ibc_val_data))\n",
    "    print('test data size:', len(ibc_test_data))\n",
    "\n",
    "    with open('raw_ibc_fasttext.train', 'w') as f:\n",
    "        for sentence, label in ibc_train_data:\n",
    "            f.write('__label__{} {}\\n'.format(label, sentence))\n",
    "            if label == \"CONSERVATIVE\":\n",
    "                f.write('__label__{} {}\\n'.format(label, sentence))\n",
    "            \n",
    "    with open('raw_ibc_fasttext.val', 'w') as f:\n",
    "        for sentence, label in ibc_val_data:\n",
    "            f.write('__label__{} {}\\n'.format(label, sentence))\n",
    "\n",
    "    with open('raw_ibc_fasttext.test', 'w') as f:\n",
    "        for sentence, label in ibc_test_data:\n",
    "            f.write('__label__{} {}\\n'.format(label, sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size: 2980\n",
      "validation data size: 372\n",
      "test data size: 374\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "generate_ibc_data_fasttext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ibc_fasttext.train', 'w') as f:\n",
    "    for sentence, label in ibc_train_data:\n",
    "        f.write('__label__{} {}\\n'.format(label, ' '.join(sentence)))\n",
    "        if label == \"CONSERVATIVE\":\n",
    "                f.write('__label__{} {}\\n'.format(label, sentence))\n",
    "        \n",
    "with open('ibc_fasttext.val', 'w') as f:\n",
    "    for sentence, label in ibc_val_data:\n",
    "        f.write('__label__{} {}\\n'.format(label, ' '.join(sentence)))\n",
    "\n",
    "with open('ibc_fasttext.test', 'w') as f:\n",
    "    for sentence, label in ibc_test_data:\n",
    "        f.write('__label__{} {}\\n'.format(label, ' '.join(sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__label__LIBERAL': {'precision': 0.6455026455026455,\n",
       "  'recall': 0.6009852216748769,\n",
       "  'f1score': 0.6224489795918368},\n",
       " '__label__CONSERVATIVE': {'precision': 0.5621621621621622,\n",
       "  'recall': 0.6081871345029239,\n",
       "  'f1score': 0.5842696629213483}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model = fasttext.train_supervised(input=\"ibc_fasttext.train\", epoch=10, lr=0.1)\n",
    "fasttext_model.test(\"ibc_fasttext.test\")\n",
    "fasttext_model.test_label(\"ibc_fasttext.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__label__LIBERAL': {'precision': 0.6774193548387096,\n",
       "  'recall': 0.41379310344827586,\n",
       "  'f1score': 0.5137614678899083},\n",
       " '__label__CONSERVATIVE': {'precision': 0.524,\n",
       "  'recall': 0.7660818713450293,\n",
       "  'f1score': 0.6223277909738717}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model = fasttext.train_supervised(input=\"raw_ibc_fasttext.train\", epoch=15, lr=0.1)\n",
    "fasttext_model.test(\"raw_ibc_fasttext.test\")\n",
    "fasttext_model.test_label(\"raw_ibc_fasttext.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = []\n",
    "y_axis = []\n",
    "for epoch in range(5, 51, 5):\n",
    "    x_axis.append(epoch)\n",
    "for lr in range(1, 11):\n",
    "    y_axis.append(lr / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_raw = []\n",
    "\n",
    "for y in y_axis:\n",
    "    tmp_result_raw = []\n",
    "    for x in x_axis:\n",
    "        curr_result = 0\n",
    "        curr_result += fasttext.train_supervised(input=\"raw_ibc_fasttext.train\", epoch=x, lr=y).test(\"raw_ibc_fasttext.test\")[1]\n",
    "        curr_result += fasttext.train_supervised(input=\"raw_ibc_fasttext.train\", epoch=x, lr=y).test(\"raw_ibc_fasttext.test\")[1]\n",
    "        curr_result += fasttext.train_supervised(input=\"raw_ibc_fasttext.train\", epoch=x, lr=y).test(\"raw_ibc_fasttext.test\")[1]\n",
    "        tmp_result_raw.append(curr_result / 3)\n",
    "    result_raw.append(tmp_result_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for y in y_axis:\n",
    "    tmp_result = []\n",
    "    for x in x_axis:\n",
    "        curr_result = 0\n",
    "        curr_result += fasttext.train_supervised(input=\"ibc_fasttext.train\", epoch=x, lr=y).test(\"ibc_fasttext.test\")[1]\n",
    "        curr_result += fasttext.train_supervised(input=\"ibc_fasttext.train\", epoch=x, lr=y).test(\"ibc_fasttext.test\")[1]\n",
    "        curr_result += fasttext.train_supervised(input=\"ibc_fasttext.train\", epoch=x, lr=y).test(\"ibc_fasttext.test\")[1]\n",
    "        tmp_result.append(curr_result / 3)\n",
    "    result.append(tmp_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5133689839572192, 0.5445632798573975, 0.6007130124777184, 0.6060606060606061, 0.6167557932263815, 0.6345811051693405, 0.5998217468805705, 0.6158645276292335, 0.6158645276292335, 0.5935828877005348]\n",
      "[0.5294117647058824, 0.5926916221033868, 0.6372549019607843, 0.6203208556149733, 0.6007130124777184, 0.6087344028520499, 0.6060606060606061, 0.6007130124777184, 0.6024955436720142, 0.5998217468805703]\n",
      "[0.5436720142602495, 0.6087344028520499, 0.6221033868092691, 0.6131907308377896, 0.6078431372549019, 0.6033868092691622, 0.6042780748663101, 0.5989304812834225, 0.5971479500891266, 0.5926916221033869]\n",
      "[0.5436720142602495, 0.6274509803921569, 0.6194295900178254, 0.6087344028520499, 0.6042780748663101, 0.6060606060606061, 0.6060606060606061, 0.5989304812834224, 0.6024955436720143, 0.5998217468805704]\n",
      "[0.5588235294117646, 0.6292335115864528, 0.6176470588235294, 0.6078431372549019, 0.5998217468805703, 0.6033868092691622, 0.5962566844919787, 0.5944741532976826, 0.6016042780748663, 0.5962566844919787]\n",
      "[0.5588235294117646, 0.6283422459893048, 0.6131907308377896, 0.6060606060606061, 0.6042780748663101, 0.6007130124777184, 0.6024955436720142, 0.5971479500891266, 0.5935828877005348, 0.6060606060606061]\n",
      "[0.5454545454545454, 0.6336898395721925, 0.6158645276292335, 0.606951871657754, 0.605169340463458, 0.6016042780748663, 0.5926916221033868, 0.5873440285204992, 0.5971479500891266, 0.6016042780748663]\n",
      "[0.5570409982174688, 0.6301247771836006, 0.5998217468805703, 0.605169340463458, 0.5953654188948306, 0.5989304812834225, 0.5998217468805704, 0.5944741532976827, 0.5953654188948306, 0.5998217468805704]\n",
      "[0.5677361853832442, 0.6319073083778965, 0.6033868092691622, 0.606951871657754, 0.5962566844919787, 0.605169340463458, 0.6051693404634582, 0.6033868092691622, 0.5998217468805704, 0.5998217468805703]\n",
      "[0.5650623885918004, 0.6203208556149732, 0.6078431372549019, 0.606951871657754, 0.6087344028520499, 0.6060606060606061, 0.5971479500891266, 0.5962566844919786, 0.6033868092691622, 0.5918003565062389]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = seaborn.heatmap(result_raw, xticklabels=x_axis, yticklabels=y_axis, vmin=0.5, vmax=0.65)\n",
    "ax.set_title('Fasttext train on raw data')\n",
    "ax.set_xlabel('Number of epochs')\n",
    "ax.set_ylabel('Learning rate')\n",
    "for row in result_raw:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6203208556149733, 0.6283422459893048, 0.6417112299465241, 0.6176470588235294, 0.5846702317290552, 0.6024955436720142, 0.5953654188948306, 0.5953654188948306, 0.5873440285204992, 0.5855614973262032]\n",
      "[0.5721925133689839, 0.6345811051693405, 0.6016042780748663, 0.5900178253119429, 0.5793226381461675, 0.5766488413547237, 0.5793226381461675, 0.5766488413547237, 0.5784313725490197, 0.5757575757575757]\n",
      "[0.5971479500891266, 0.6185383244206774, 0.5918003565062389, 0.5882352941176471, 0.5819964349376114, 0.5793226381461675, 0.5837789661319074, 0.5775401069518717, 0.5793226381461675, 0.5766488413547237]\n",
      "[0.6060606060606061, 0.6024955436720143, 0.5953654188948306, 0.5855614973262032, 0.5775401069518716, 0.5793226381461675, 0.5748663101604278, 0.5784313725490197, 0.5802139037433155, 0.5828877005347594]\n",
      "[0.6131907308377896, 0.6033868092691622, 0.5837789661319074, 0.5730837789661319, 0.5775401069518716, 0.5757575757575757, 0.5793226381461675, 0.5784313725490197, 0.5766488413547237, 0.5793226381461675]\n",
      "[0.6105169340463458, 0.6033868092691622, 0.5864527629233511, 0.5748663101604278, 0.5775401069518716, 0.5730837789661319, 0.5793226381461675, 0.570409982174688, 0.5757575757575757, 0.5793226381461675]\n",
      "[0.6194295900178254, 0.5944741532976828, 0.5819964349376114, 0.5686274509803922, 0.5793226381461675, 0.5775401069518716, 0.570409982174688, 0.5739750445632797, 0.5828877005347594, 0.5766488413547237]\n",
      "[0.6238859180035651, 0.5846702317290552, 0.5855614973262032, 0.5775401069518716, 0.5721925133689839, 0.5766488413547237, 0.5730837789661319, 0.5748663101604278, 0.5793226381461675, 0.5730837789661319]\n",
      "[0.6185383244206774, 0.5918003565062389, 0.5828877005347594, 0.5784313725490197, 0.5757575757575758, 0.5784313725490197, 0.5766488413547237, 0.5730837789661319, 0.5775401069518716, 0.5766488413547237]\n",
      "[0.6203208556149733, 0.5909090909090909, 0.5828877005347594, 0.5793226381461677, 0.5730837789661319, 0.5730837789661319, 0.5819964349376114, 0.5748663101604278, 0.5828877005347594, 0.571301247771836]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = seaborn.heatmap(result, xticklabels=x_axis, yticklabels=y_axis, vmin=0.5, vmax=0.65)\n",
    "ax.set_title('Fasttext train on preprocessed data')\n",
    "ax.set_xlabel('Number of epochs')\n",
    "ax.set_ylabel('Learning rate')\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(374, 0.5962566844919787, 0.5962566844919787)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model = fasttext.train_supervised(input=\"ibc_fasttext.train\", autotuneValidationFile=\"ibc_fasttext.val\")\n",
    "fasttext_model.test(\"ibc_fasttext.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__label__CONSERVATIVE': {'precision': 0.6666666666666666,\n",
       "  'recall': 0.23391812865497075,\n",
       "  'f1score': 0.3463203463203463},\n",
       " '__label__LIBERAL': {'precision': 0.5828025477707006,\n",
       "  'recall': 0.9014778325123153,\n",
       "  'f1score': 0.7079303675048356}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model.test_label(\"ibc_fasttext.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(374, 0.5935828877005348, 0.5935828877005348)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_fasttext_model = fasttext.train_supervised(input=\"raw_ibc_fasttext.train\", autotuneValidationFile=\"raw_ibc_fasttext.val\")\n",
    "raw_fasttext_model.test(\"raw_ibc_fasttext.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__label__CONSERVATIVE': {'precision': 0.6019417475728155,\n",
       "  'recall': 0.36257309941520466,\n",
       "  'f1score': 0.45255474452554745},\n",
       " '__label__LIBERAL': {'precision': 0.5977859778597786,\n",
       "  'recall': 0.7980295566502463,\n",
       "  'f1score': 0.6835443037974683}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_fasttext_model.test_label(\"ibc_fasttext.test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

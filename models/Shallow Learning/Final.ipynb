{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick fix final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x12d80955bd0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import torch\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, classification_report\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "import string\n",
    "import tqdm\n",
    "spacy.load('en_core_web_sm')\n",
    "stopwords = stopwords.words('english')\n",
    "# torch.backends.cudnn.enabled = False \n",
    "torch.random.manual_seed(123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.00001\n",
    "NODES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 ./dataset_70/train_70.csv ./dataset_70/test_70.csv\n"
     ]
    }
   ],
   "source": [
    "train_split = 70\n",
    "split_train = train_split/100\n",
    "train_file_name = \"./dataset_{}/train_{}.csv\".format(train_split,train_split) \n",
    "test_file_name = \"./dataset_{}/test_{}.csv\".format(train_split,train_split) \n",
    "vocab_file_name =  \"./dataset_{}/vocab_{}.csv\".format(train_split,train_split)\n",
    "print(split_train, train_file_name, test_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19930,\n",
       " 8541,\n",
       " Index(['tweet_id', 'created_time', 'count', '1', '2', '3', '4', '5', '6',\n",
       "        'user_id', 'screen_name', 'url', 'follower_count', 'title', 'content',\n",
       "        'expanded_url', 'title_len', 'content_len', 'max_retweets',\n",
       "        'label_log_10', 'label_mean', 'label_median', 'label_quantile',\n",
       "        'label_grouped_median', 'grouped_median'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(train_file_name, sep=\"|\", index_col=0)\n",
    "test = pd.read_csv(test_file_name, sep=\"|\", index_col=0)\n",
    "len(train),len(test), train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.loc[train.max_retweets==32870]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of words in len 20\n"
     ]
    }
   ],
   "source": [
    "tok = spacy.load('en_core_web_sm')\n",
    "max_len = -1\n",
    "def tokenize(text):\n",
    "    text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)\n",
    "    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]')\n",
    "    nopunct_num = regex.sub(\" \", text.lower()) \n",
    "#     text = \" \".join([word for word in text.split() if word not in stopwords])\n",
    "    # Removing the odd apostrophes\n",
    "    tokens = [token for token in nopunct_num.split() if len(token)>=2 and token not in stopwords]\n",
    "    return tokens\n",
    "#     text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)\n",
    "#     regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]')\n",
    "#     nopunct = regex.sub(\" \", text.lower())\n",
    "#     return [token.text for token in tok.tokenizer(nopunct)]\n",
    "#count number of occurences of each word\n",
    "counts = Counter()\n",
    "for index, row in train.iterrows():\n",
    "    tokenized = tokenize(row['title'])\n",
    "    if max_len < len(tokenized):\n",
    "        max_len = len(tokenized)\n",
    "    counts.update(tokenized)\n",
    "print(\"Max number of words in len\",max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting infrequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'UNK', 'man', 'accused', 'golden']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating vocab\n",
    "vocab2index = {\"\":0, \"UNK\":1}\n",
    "words = [\"\",\"UNK\"]\n",
    "for word in counts:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)\n",
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(text, vocab2index, N=max_len):\n",
    "    tokenized = tokenize(text)\n",
    "    encoded = np.zeros(N,dtype=int)\n",
    "    enc1 = np.array([vocab2index.get(word,vocab2index[\"UNK\"]) for word in tokenized])\n",
    "    length = min(N, len(enc1))\n",
    "    encoded[:length] = enc1[:length]\n",
    "    return encoded, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['encoded'] = train['title'].apply(lambda x: np.array(encode_sentence(x,vocab2index)))\n",
    "test['encoded'] = test['title'].apply(lambda x: np.array(encode_sentence(x,vocab2index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    [[2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 0, 0, 0, 0, 0,...\n",
       " 1    [[10, 11, 12, 13, 14, 15, 16, 17, 18, 0, 0, 0,...\n",
       " Name: encoded, dtype: object,\n",
       " 0    1\n",
       " 1    1\n",
       " Name: label_log_10, dtype: int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = train['encoded'], train['label_log_10']\n",
    "X_train.head(2),y_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    [[354, 638, 5250, 12, 4213, 3322, 250, 3750, 7...\n",
       " 1    [[13, 57, 127, 1, 13439, 4632, 50, 516, 1079, ...\n",
       " Name: encoded, dtype: object,\n",
       " 0    2\n",
       " 1    2\n",
       " Name: label_log_10, dtype: int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test = test['encoded'], test['label_log_10']\n",
    "X_test.head(2), y_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "            self.X = X\n",
    "            self.y = Y\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.X[idx][0].astype(np.int32)), self.y[idx], self.X[idx][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = NewsDataset(X_train, y_train)\n",
    "test_ds = NewsDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=LEARNING_RATE)#, momentum=0.7)\n",
    "#     model_fixed.load_state_dict(torch.load(\"./model_dropout.pt\"))\n",
    "#     optimizer.load_state_dict(torch.load(\"./optimizer_dropout.pt\"))\n",
    "    actual_loss = None\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', verbose=True,\n",
    "                                                     patience=3, factor=0.6)\n",
    "    softmax = nn.LogSoftmax(dim=0)\n",
    "    for i in tqdm.tqdm(range(EPOCHS), total=EPOCHS):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, y, l in train_dl:\n",
    "            x = x.long().to(device)\n",
    "            y = y.long().to(device)\n",
    "            y_pred = model(x, l)\n",
    "#             y_hat = softmax(y_pred)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.cross_entropy(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item() *y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        val_loss, val_acc, val_rmse = validation_metrics(model, test_dl, i)\n",
    "        scheduler.step(val_loss)\n",
    "        actual_loss = val_loss\n",
    "        print(\"Model Dict updated\")\n",
    "        torch.save(model.state_dict(),\"./model_dropout.pt\" )\n",
    "        torch.save(optimizer.state_dict(),\"./optimizer_dropout_adam.pt\")\n",
    "            \n",
    "#         if i%5 == 0:\n",
    "        print(\"train loss %.3f, val loss %.3f, val accuracy %.3f, and val rmse %.3f\" % (sum_loss/total, val_loss, val_acc, val_rmse))\n",
    "\n",
    "def validation_metrics (model, valid_dl, i):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    sum_rmse = 0.0\n",
    "    total_preds, total_actual= [], []\n",
    "    for x, y, l in valid_dl:\n",
    "        x = x.long().to(device)\n",
    "        y = y.long()\n",
    "        y_hat = model(x, l).cpu()\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        pred = torch.max(y_hat, 1)[1]\n",
    "#         print(pred.numpy())\n",
    "#         print(y.numpy())\n",
    "        total_preds += pred.tolist()\n",
    "        total_actual += y.tolist()\n",
    "        correct += (pred == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "        sum_rmse += np.sqrt(mean_squared_error(pred, y.unsqueeze(-1)))*y.shape[0]\n",
    "#     if i%5 == 0:\n",
    "#         print(i)\n",
    "    print(classification_report(total_preds, total_actual))\n",
    "    return sum_loss/total, correct/total, sum_rmse/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14322\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(words)\n",
    "print(vocab_size)\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "# np.save('vocab2index.npy',vocab2index)\n",
    "# np.save('wordlist.npy',words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312, torch.Size([1, 20]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y,l = train_ds[0]\n",
    "len(train_dl), x.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_fixed_len(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "#         self.model = nn.Sequential(*[\n",
    "#             nn.Embedding(vocab_size, embedding_dim, padding_idx=0),\n",
    "#             nn.Dropout(0.2),\n",
    "#             nn.LSTM(embedding_dim, hidden_dim, batch_first=True),\n",
    "#             nn.Linear(hidden_dim, 2)\n",
    "#         ])\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, num_layers=3, bidirectional=True)\n",
    "        self.linear = nn.Linear(hidden_dim*2, 4, bias=False)\n",
    "        \n",
    "    def forward(self, x, l):\n",
    "#         print(x[0])\n",
    "#         result = self.model(x)\n",
    "#         print(result)\n",
    "#         return 0\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        lstm_out,( ht, ct) = self.lstm(x)\n",
    "#         print(ht[-1].shape, torch.cat((ht[-2],ht[-1]), dim=1).shape)\n",
    "#         print(ht.view(3, 2, 128, 256).shape)\n",
    "        return self.linear(torch.cat((ht[-2],ht[-1]), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_fixed_len(\n",
       "  (embeddings): Embedding(14322, 200, padding_idx=0)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (lstm): LSTM(200, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
       "  (linear): Linear(in_features=512, out_features=4, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fixed = LSTM_fixed_len(vocab_size, 200, 256)\n",
    "model_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                    | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AC:\\Users\\gnsd1\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "\n",
      "\n",
      "  1%|█▏                                                                                                                          | 1/100 [00:12<21:20, 12.94s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.39      0.09        66\n",
      "           1       0.89      0.71      0.79      7119\n",
      "           2       0.30      0.48      0.37      1356\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.67      8541\n",
      "   macro avg       0.31      0.40      0.31      8541\n",
      "weighted avg       0.79      0.67      0.72      8541\n",
      "\n",
      "Model Dict updated\n",
      "train loss 0.846, val loss 0.803, val accuracy 0.671, and val rmse 0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gnsd1\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "\n",
      "\n",
      "  2%|██▍                                                                                                                         | 2/100 [00:26<21:23, 13.10s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.46      0.21       156\n",
      "           1       0.88      0.72      0.79      6915\n",
      "           2       0.35      0.51      0.42      1470\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.68      8541\n",
      "   macro avg       0.34      0.42      0.36      8541\n",
      "weighted avg       0.77      0.68      0.72      8541\n",
      "\n",
      "Model Dict updated\n",
      "train loss 0.744, val loss 0.762, val accuracy 0.683, and val rmse 0.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gnsd1\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "\n",
      "\n",
      "  3%|███▋                                                                                                                        | 3/100 [00:40<21:26, 13.26s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.40      0.30       307\n",
      "           1       0.75      0.77      0.76      5583\n",
      "           2       0.58      0.47      0.52      2651\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.66      8541\n",
      "   macro avg       0.39      0.41      0.40      8541\n",
      "weighted avg       0.68      0.66      0.67      8541\n",
      "\n",
      "Model Dict updated\n",
      "train loss 0.648, val loss 0.794, val accuracy 0.664, and val rmse 0.610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  4%|████▉                                                                                                                       | 4/100 [00:53<21:22, 13.36s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.35      0.29       358\n",
      "           1       0.79      0.76      0.77      5948\n",
      "           2       0.50      0.49      0.49      2220\n",
      "           3       0.02      0.20      0.03        15\n",
      "\n",
      "    accuracy                           0.67      8541\n",
      "   macro avg       0.39      0.45      0.40      8541\n",
      "weighted avg       0.69      0.67      0.68      8541\n",
      "\n",
      "Model Dict updated\n",
      "train loss 0.556, val loss 0.826, val accuracy 0.669, and val rmse 0.613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  5%|██████▏                                                                                                                     | 5/100 [01:07<21:20, 13.48s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.38      0.30       347\n",
      "           1       0.84      0.74      0.79      6444\n",
      "           2       0.42      0.52      0.46      1738\n",
      "           3       0.02      0.25      0.03        12\n",
      "\n",
      "    accuracy                           0.68      8541\n",
      "   macro avg       0.38      0.47      0.40      8541\n",
      "weighted avg       0.73      0.68      0.70      8541\n",
      "\n",
      "Model Dict updated\n",
      "train loss 0.477, val loss 0.828, val accuracy 0.681, and val rmse 0.598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  6%|███████▍                                                                                                                    | 6/100 [01:20<21:09, 13.51s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.35      0.30       384\n",
      "           1       0.77      0.76      0.77      5769\n",
      "           2       0.53      0.48      0.50      2363\n",
      "           3       0.02      0.12      0.03        25\n",
      "\n",
      "    accuracy                           0.66      8541\n",
      "   macro avg       0.39      0.43      0.40      8541\n",
      "weighted avg       0.68      0.66      0.67      8541\n",
      "\n",
      "Epoch     6: reducing learning rate of group 0 to 6.0000e-04.\n",
      "Model Dict updated\n",
      "train loss 0.414, val loss 0.937, val accuracy 0.665, and val rmse 0.615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  7%|████████▋                                                                                                                   | 7/100 [01:34<21:04, 13.59s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.33      0.31       464\n",
      "           1       0.76      0.76      0.76      5648\n",
      "           2       0.53      0.48      0.50      2381\n",
      "           3       0.07      0.23      0.11        48\n",
      "\n",
      "    accuracy                           0.66      8541\n",
      "   macro avg       0.41      0.45      0.42      8541\n",
      "weighted avg       0.66      0.66      0.66      8541\n",
      "\n",
      "Model Dict updated\n",
      "train loss 0.338, val loss 1.020, val accuracy 0.658, and val rmse 0.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  8%|█████████▉                                                                                                                  | 8/100 [01:48<20:49, 13.59s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.34      0.30       410\n",
      "           1       0.78      0.76      0.77      5815\n",
      "           2       0.48      0.48      0.48      2150\n",
      "           3       0.14      0.13      0.13       166\n",
      "\n",
      "    accuracy                           0.66      8541\n",
      "   macro avg       0.42      0.43      0.42      8541\n",
      "weighted avg       0.67      0.66      0.66      8541\n",
      "\n",
      "Model Dict updated\n",
      "train loss 0.293, val loss 1.131, val accuracy 0.660, and val rmse 0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  9%|███████████▏                                                                                                                | 9/100 [02:02<20:41, 13.64s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.33      0.30       440\n",
      "           1       0.78      0.76      0.77      5852\n",
      "           2       0.50      0.49      0.49      2198\n",
      "           3       0.06      0.20      0.09        51\n",
      "\n",
      "    accuracy                           0.66      8541\n",
      "   macro avg       0.40      0.44      0.41      8541\n",
      "weighted avg       0.68      0.66      0.67      8541\n",
      "\n",
      "Model Dict updated\n",
      "train loss 0.267, val loss 1.234, val accuracy 0.663, and val rmse 0.620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 10%|████████████▎                                                                                                              | 10/100 [02:16<20:37, 13.75s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.34      0.31       443\n",
      "           1       0.77      0.76      0.77      5760\n",
      "           2       0.50      0.49      0.49      2202\n",
      "           3       0.12      0.14      0.13       136\n",
      "\n",
      "    accuracy                           0.66      8541\n",
      "   macro avg       0.42      0.43      0.42      8541\n",
      "weighted avg       0.66      0.66      0.66      8541\n",
      "\n",
      "Epoch    10: reducing learning rate of group 0 to 3.6000e-04.\n",
      "Model Dict updated\n",
      "train loss 0.249, val loss 1.279, val accuracy 0.659, and val rmse 0.624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 11%|█████████████▌                                                                                                             | 11/100 [02:29<20:24, 13.76s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.33      0.31       466\n",
      "           1       0.77      0.76      0.77      5828\n",
      "           2       0.48      0.49      0.48      2118\n",
      "           3       0.12      0.15      0.13       129\n",
      "\n",
      "    accuracy                           0.66      8541\n",
      "   macro avg       0.42      0.43      0.42      8541\n",
      "weighted avg       0.66      0.66      0.66      8541\n",
      "\n",
      "Model Dict updated\n",
      "train loss 0.217, val loss 1.437, val accuracy 0.658, and val rmse 0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 12%|██████████████▊                                                                                                            | 12/100 [02:44<20:44, 14.14s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.36      0.29       359\n",
      "           1       0.80      0.75      0.77      6069\n",
      "           2       0.45      0.49      0.47      1983\n",
      "           3       0.11      0.14      0.12       130\n",
      "\n",
      "    accuracy                           0.66      8541\n",
      "   macro avg       0.40      0.43      0.41      8541\n",
      "weighted avg       0.68      0.66      0.67      8541\n",
      "\n",
      "Model Dict updated\n",
      "train loss 0.205, val loss 1.482, val accuracy 0.665, and val rmse 0.620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 13%|███████████████▉                                                                                                           | 13/100 [02:59<20:43, 14.30s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.35      0.29       373\n",
      "           1       0.79      0.76      0.77      5953\n",
      "           2       0.46      0.48      0.47      2056\n",
      "           3       0.12      0.13      0.13       159\n",
      "\n",
      "    accuracy                           0.66      8541\n",
      "   macro avg       0.41      0.43      0.41      8541\n",
      "weighted avg       0.67      0.66      0.67      8541\n",
      "\n",
      "Model Dict updated\n",
      "train loss 0.196, val loss 1.626, val accuracy 0.660, and val rmse 0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 14%|█████████████████▏                                                                                                         | 14/100 [03:13<20:29, 14.30s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.37      0.31       374\n",
      "           1       0.78      0.76      0.77      5875\n",
      "           2       0.48      0.48      0.48      2149\n",
      "           3       0.12      0.13      0.13       143\n",
      "\n",
      "    accuracy                           0.66      8541\n",
      "   macro avg       0.41      0.44      0.42      8541\n",
      "weighted avg       0.67      0.66      0.67      8541\n",
      "\n",
      "Epoch    14: reducing learning rate of group 0 to 2.1600e-04.\n",
      "Model Dict updated\n",
      "train loss 0.192, val loss 1.614, val accuracy 0.662, and val rmse 0.622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 15%|██████████████████▍                                                                                                        | 15/100 [03:28<20:19, 14.35s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.38      0.31       372\n",
      "           1       0.80      0.75      0.78      6071\n",
      "           2       0.45      0.49      0.47      1967\n",
      "           3       0.12      0.15      0.13       131\n",
      "\n",
      "    accuracy                           0.67      8541\n",
      "   macro avg       0.41      0.44      0.42      8541\n",
      "weighted avg       0.69      0.67      0.68      8541\n",
      "\n",
      "Model Dict updated\n",
      "train loss 0.178, val loss 1.720, val accuracy 0.668, and val rmse 0.615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 16%|███████████████████▋                                                                                                       | 16/100 [03:42<20:00, 14.29s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.35      0.30       400\n",
      "           1       0.78      0.76      0.77      5891\n",
      "           2       0.48      0.49      0.49      2128\n",
      "           3       0.09      0.12      0.11       122\n",
      "\n",
      "    accuracy                           0.66      8541\n",
      "   macro avg       0.41      0.43      0.42      8541\n",
      "weighted avg       0.67      0.66      0.67      8541\n",
      "\n",
      "Model Dict updated\n",
      "train loss 0.170, val loss 1.830, val accuracy 0.664, and val rmse 0.620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 17%|████████████████████▉                                                                                                      | 17/100 [03:56<19:36, 14.17s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.34      0.30       418\n",
      "           1       0.79      0.76      0.77      5906\n",
      "           2       0.48      0.50      0.49      2094\n",
      "           3       0.10      0.13      0.11       123\n",
      "\n",
      "    accuracy                           0.67      8541\n",
      "   macro avg       0.41      0.43      0.42      8541\n",
      "weighted avg       0.68      0.67      0.67      8541\n",
      "\n",
      "Model Dict updated\n",
      "train loss 0.168, val loss 1.814, val accuracy 0.667, and val rmse 0.618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 18%|██████████████████████▏                                                                                                    | 18/100 [04:10<19:19, 14.14s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.34      0.31       444\n",
      "           1       0.79      0.76      0.78      5978\n",
      "           2       0.46      0.50      0.48      1999\n",
      "           3       0.10      0.13      0.11       120\n",
      "\n",
      "    accuracy                           0.67      8541\n",
      "   macro avg       0.41      0.43      0.42      8541\n",
      "weighted avg       0.68      0.67      0.67      8541\n",
      "\n",
      "Epoch    18: reducing learning rate of group 0 to 1.2960e-04.\n",
      "Model Dict updated\n",
      "train loss 0.169, val loss 1.796, val accuracy 0.667, and val rmse 0.620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 19%|███████████████████████▎                                                                                                   | 19/100 [04:24<19:04, 14.13s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.35      0.30       379\n",
      "           1       0.78      0.76      0.77      5860\n",
      "           2       0.49      0.48      0.48      2187\n",
      "           3       0.10      0.14      0.12       115\n",
      "\n",
      "    accuracy                           0.66      8541\n",
      "   macro avg       0.41      0.43      0.42      8541\n",
      "weighted avg       0.67      0.66      0.67      8541\n",
      "\n",
      "Model Dict updated\n",
      "train loss 0.160, val loss 1.928, val accuracy 0.662, and val rmse 0.621\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-926c461f3391>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_fixed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-62-30efa0356983>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;31m#             y_hat = softmax(y_pred)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-69-ee5321244a1a>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, l)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mht\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mct\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;31m#         print(ht[-1].shape, torch.cat((ht[-2],ht[-1]), dim=1).shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m#         print(ht.view(3, 2, 128, 256).shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    557\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 559\u001b[1;33m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    560\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(model_fixed.to(device))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from textblob import TextBlob\n",
    "\n",
    "import torch\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "BATCH_SIZE = 1024\n",
    "LEARNING_RATE = 0.001\n",
    "NODES = 1000\n",
    "NUM_FEATURES = 30\n",
    "NUM_CLASSES = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/Organic_extended_finalv2.csv\", sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find max retweets\n",
    "max_list = list()\n",
    "for index, row in df.iterrows():\n",
    "    num_list = list()\n",
    "    num_list = {row[\"1\"], row[\"2\"],row[\"3\"], row[\"4\"],row[\"5\"], row[\"6\"]}\n",
    "    max_list.append(max(num_list))\n",
    "df[\"max_retweets\"] = max_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating mean/median\n",
      "mean:  144.079085973584\n",
      "median:  49.0\n",
      "Number of entries:  12341\n"
     ]
    }
   ],
   "source": [
    "# Find mean/median and size\n",
    "print(\"calculating mean/median\")\n",
    "mean =  df[\"max_retweets\"].mean()\n",
    "median = df[\"max_retweets\"].median()\n",
    "print(\"mean: \", mean)\n",
    "print(\"median: \", median)\n",
    "print(\"Number of entries: \", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date strings to datetime objeccts\n",
    "date_time = list()\n",
    "for index, row in df.iterrows():\n",
    "    if(row[\"created_time\"].lower().islower()):\n",
    "        # date time w/ letter (Jun, Mon, etc)\n",
    "        date_time_obj = datetime.strptime(row[\"created_time\"], '%a %b %d %H:%M:%S +0000 %Y')\n",
    "        date_time.append(date_time_obj)\n",
    "    else:\n",
    "        # date time w/ not letters (Jun, Mon, etc)\n",
    "        date_time_obj = datetime.strptime(row[\"created_time\"], '%Y-%m-%d %H:%M:%S+00:00')\n",
    "        date_time.append(date_time_obj)\n",
    "df[\"created_datetime\"] = date_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data for what day of week the article was published\n",
    "df['is_mon'] = 0\n",
    "df['is_tue'] = 0\n",
    "df['is_wed'] = 0\n",
    "df['is_thu'] = 0\n",
    "df['is_fri'] = 0\n",
    "df['is_sat'] = 0\n",
    "df['is_sun'] = 0\n",
    "df['is_weekend'] = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    day = row[\"created_datetime\"].weekday()\n",
    "    if day is 0:\n",
    "        df.at[index,'is_sun'] = 1\n",
    "        df.at[index,'is_weekend'] = 1\n",
    "    elif day is 1:\n",
    "        df.at[index,'is_mon'] = 1\n",
    "    elif day is 2:\n",
    "        df.at[index,'is_tue'] = 1\n",
    "    elif day is 3:\n",
    "        df.at[index,'is_wed'] = 1\n",
    "    elif day is 4:\n",
    "        df.at[index,'is_thu'] = 1\n",
    "    elif day is 5:\n",
    "        df.at[index,'is_fri'] = 1\n",
    "    elif day is 6:\n",
    "        df.at[index,'is_sat'] = 1\n",
    "        df.at[index,'is_weekend'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subjectivity and polarity\n",
    "for index, row in df.iterrows():\n",
    "    title_score = TextBlob(row[\"title\"]).sentiment\n",
    "    content_score = TextBlob(row[\"content\"]).sentiment\n",
    "    df.at[index,'title_polarity'] = title_score[0]\n",
    "    df.at[index,'title_subjectivity'] = title_score[1]\n",
    "    df.at[index,'content_polarity'] = content_score[0]\n",
    "    df.at[index,'content_subjectivity'] = content_score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source\n",
    "accounts = [\"CNN\",\"The Wall Street Journal\",\"The Washington Post\",\"NBC News\",\n",
    "            \"The Associated Press\",\"ABC News\",\"Los Angeles Times\",\"The New York Times\",\"NPR\",\"TIME\",\"U.S. News\",\"USA TODAY\",\n",
    "            \"Fox News\",\"Reuters\",\"HuffPost\"]\n",
    "for i in accounts:\n",
    "    df[i] = 0\n",
    "\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    df.at[index,row[\"screen_name\"]] = 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:  10 2:  100 3:  1000\n"
     ]
    }
   ],
   "source": [
    "# 0 -> 0-0.25 quantile\n",
    "# 1 -> 0.26-0.50 quantile\n",
    "# 2 -> < 0.51-0.75 quantile\n",
    "# 3 -> >= 0.76-1.00 quantile\n",
    "\n",
    "\n",
    "#quan_dict=df.max_retweets.quantile([0.25, 0.5, 0.75])\n",
    "#one_quar = quan_dict[0.25]\n",
    "#two_quar = quan_dict[0.5]\n",
    "#three_quar = quan_dict[0.75]\n",
    "\n",
    "\n",
    "one_quar = 10\n",
    "two_quar = 100\n",
    "three_quar = 1000\n",
    "\n",
    "\n",
    "\n",
    "print(\"1: \", one_quar, \"2: \", two_quar, \"3: \", three_quar)\n",
    "\n",
    "df.loc[df['max_retweets'] <= one_quar, 'shares'] = 0\n",
    "df.loc[((df['max_retweets'] > one_quar) & (df['max_retweets'] <= two_quar)), 'shares'] = 1\n",
    "df.loc[((df['max_retweets'] > two_quar) & (df['max_retweets'] <= three_quar)), 'shares'] = 2\n",
    "df.loc[df['max_retweets'] > three_quar, 'shares'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21e9a24fcc8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'shares', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>created_time</th>\n",
       "      <th>count</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>Los Angeles Times</th>\n",
       "      <th>The New York Times</th>\n",
       "      <th>NPR</th>\n",
       "      <th>TIME</th>\n",
       "      <th>U.S. News</th>\n",
       "      <th>USA TODAY</th>\n",
       "      <th>Fox News</th>\n",
       "      <th>Reuters</th>\n",
       "      <th>HuffPost</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1272217655630458881</td>\n",
       "      <td>2020-06-14 17:21:40+00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>454</td>\n",
       "      <td>463.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>466.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1272216897237516289</td>\n",
       "      <td>2020-06-14 17:18:39+00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>163</td>\n",
       "      <td>163.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1272220034065186817</td>\n",
       "      <td>2020-06-14 17:31:07+00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>910</td>\n",
       "      <td>927.0</td>\n",
       "      <td>929.0</td>\n",
       "      <td>933.0</td>\n",
       "      <td>934.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1272219784743202816</td>\n",
       "      <td>2020-06-14 17:30:08+00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>2352</td>\n",
       "      <td>2377.0</td>\n",
       "      <td>2381.0</td>\n",
       "      <td>2378.0</td>\n",
       "      <td>2376.0</td>\n",
       "      <td>2373.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1272220746014572545</td>\n",
       "      <td>2020-06-14 17:33:57+00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>241</td>\n",
       "      <td>267.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             tweet_id               created_time  count     1  \\\n",
       "0           0  1272217655630458881  2020-06-14 17:21:40+00:00     17   454   \n",
       "1           1  1272216897237516289  2020-06-14 17:18:39+00:00     17   163   \n",
       "2           2  1272220034065186817  2020-06-14 17:31:07+00:00     17   910   \n",
       "3           3  1272219784743202816  2020-06-14 17:30:08+00:00     17  2352   \n",
       "4           4  1272220746014572545  2020-06-14 17:33:57+00:00     17   241   \n",
       "\n",
       "        2       3       4       5       6  ...  Los Angeles Times  \\\n",
       "0   463.0   462.0   464.0   464.0   466.0  ...                  1   \n",
       "1   163.0   163.0   163.0   162.0   162.0  ...                  0   \n",
       "2   927.0   929.0   933.0   934.0   936.0  ...                  0   \n",
       "3  2377.0  2381.0  2378.0  2376.0  2373.0  ...                  0   \n",
       "4   267.0   267.0   267.0   267.0   267.0  ...                  1   \n",
       "\n",
       "  The New York Times NPR  TIME U.S. News USA TODAY Fox News  Reuters  \\\n",
       "0                  0   0     0         0         0        0        0   \n",
       "1                  0   0     0         0         0        0        0   \n",
       "2                  0   0     0         0         0        0        0   \n",
       "3                  1   0     0         0         0        0        0   \n",
       "4                  0   0     0         0         0        0        0   \n",
       "\n",
       "   HuffPost  shares  \n",
       "0         0     2.0  \n",
       "1         0     2.0  \n",
       "2         0     2.0  \n",
       "3         0     3.0  \n",
       "4         0     2.0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['tweet_id','created_time','count','1','2','3','4','5','6','user_id','screen_name','title','content','url','expanded_url','created_datetime','max_retweets'], axis = 1)\n",
    "X = df.iloc[:, 1:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>follower_count</th>\n",
       "      <th>title_len</th>\n",
       "      <th>content_len</th>\n",
       "      <th>is_mon</th>\n",
       "      <th>is_tue</th>\n",
       "      <th>is_wed</th>\n",
       "      <th>is_thu</th>\n",
       "      <th>is_fri</th>\n",
       "      <th>is_sat</th>\n",
       "      <th>is_sun</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>title_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>content_polarity</th>\n",
       "      <th>content_subjectivity</th>\n",
       "      <th>CNN</th>\n",
       "      <th>The Wall Street Journal</th>\n",
       "      <th>The Washington Post</th>\n",
       "      <th>NBC News</th>\n",
       "      <th>The Associated Press</th>\n",
       "      <th>ABC News</th>\n",
       "      <th>Los Angeles Times</th>\n",
       "      <th>The New York Times</th>\n",
       "      <th>NPR</th>\n",
       "      <th>TIME</th>\n",
       "      <th>U.S. News</th>\n",
       "      <th>USA TODAY</th>\n",
       "      <th>Fox News</th>\n",
       "      <th>Reuters</th>\n",
       "      <th>HuffPost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3634148.0</td>\n",
       "      <td>8</td>\n",
       "      <td>369</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.072377</td>\n",
       "      <td>0.383025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15735968.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1766</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.019223</td>\n",
       "      <td>0.347613</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48817611.0</td>\n",
       "      <td>15</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.209750</td>\n",
       "      <td>0.475417</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46861284.0</td>\n",
       "      <td>9</td>\n",
       "      <td>4174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.017214</td>\n",
       "      <td>0.481129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3634146.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2826</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.418182</td>\n",
       "      <td>0.627273</td>\n",
       "      <td>0.066627</td>\n",
       "      <td>0.399637</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   follower_count  title_len  content_len  is_mon  is_tue  is_wed  is_thu  \\\n",
       "0       3634148.0          8          369       0       0       0       0   \n",
       "1      15735968.0         14         1766       0       0       0       0   \n",
       "2      48817611.0         15          190       0       0       0       0   \n",
       "3      46861284.0          9         4174       0       0       0       0   \n",
       "4       3634146.0         16         2826       0       0       0       0   \n",
       "\n",
       "   is_fri  is_sat  is_sun  is_weekend  title_polarity  title_subjectivity  \\\n",
       "0       0       1       0           1       -0.166667            0.433333   \n",
       "1       0       1       0           1        0.016667            0.266667   \n",
       "2       0       1       0           1        0.075000            0.216667   \n",
       "3       0       1       0           1        0.033333            0.066667   \n",
       "4       0       1       0           1        0.418182            0.627273   \n",
       "\n",
       "   content_polarity  content_subjectivity  CNN  The Wall Street Journal  \\\n",
       "0          0.072377              0.383025    0                        0   \n",
       "1          0.019223              0.347613    0                        0   \n",
       "2          0.209750              0.475417    1                        0   \n",
       "3          0.017214              0.481129    0                        0   \n",
       "4          0.066627              0.399637    0                        0   \n",
       "\n",
       "   The Washington Post  NBC News  The Associated Press  ABC News  \\\n",
       "0                    0         0                     0         0   \n",
       "1                    0         0                     0         1   \n",
       "2                    0         0                     0         0   \n",
       "3                    0         0                     0         0   \n",
       "4                    0         0                     0         0   \n",
       "\n",
       "   Los Angeles Times  The New York Times  NPR  TIME  U.S. News  USA TODAY  \\\n",
       "0                  1                   0    0     0          0          0   \n",
       "1                  0                   0    0     0          0          0   \n",
       "2                  0                   0    0     0          0          0   \n",
       "3                  0                   1    0     0          0          0   \n",
       "4                  1                   0    0     0          0          0   \n",
       "\n",
       "   Fox News  Reuters  HuffPost  \n",
       "0         0        0         0  \n",
       "1         0        0         0  \n",
       "2         0        0         0  \n",
       "3         0        0         0  \n",
       "4         0        0         0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "len(X.columns)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2.0\n",
       "1        2.0\n",
       "2        2.0\n",
       "3        3.0\n",
       "4        2.0\n",
       "        ... \n",
       "12336    1.0\n",
       "12337    2.0\n",
       "12338    2.0\n",
       "12339    1.0\n",
       "12340    1.0\n",
       "Name: shares, Length: 12341, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3601b09da92d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m432\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y, random_state=432)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_test, y_test = np.array(X_test), (y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "train_data = trainData(torch.FloatTensor(X_train), torch.LongTensor(y_train))\n",
    "\n",
    "## test data    \n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "test_data = testData(torch.FloatTensor(X_test), torch.LongTensor(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_distribution(obj):\n",
    "    count_dict = {\n",
    "        \"0\":0,\n",
    "        \"1\":0,\n",
    "        \"2\":0,\n",
    "        \"3\":0\n",
    "    }\n",
    "    \n",
    "    for i in obj:\n",
    "        if i == 0:\n",
    "            count_dict[\"0\"] += 1\n",
    "        elif i == 1:\n",
    "            count_dict[\"1\"] += 1\n",
    "        elif i == 2:\n",
    "            count_dict[\"2\"] += 1\n",
    "        else:\n",
    "            count_dict[\"3\"] += 1\n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = []\n",
    "\n",
    "for _, t in train_data:\n",
    "    target_list.append(t)\n",
    "    \n",
    "target_list = torch.tensor(target_list)\n",
    "target_list = target_list[torch.randperm(len(target_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0016, 0.0002, 0.0004, 0.0052])\n"
     ]
    }
   ],
   "source": [
    "class_count = [i for i in get_class_distribution(y_train).values()]\n",
    "class_weights = 1./torch.tensor(class_count, dtype=torch.float)\n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_all = class_weights[target_list]\n",
    "\n",
    "weighted_sampler = WeightedRandomSampler(\n",
    "    weights = class_weights_all, \n",
    "    num_samples = len(class_weights_all),\n",
    "    replacement = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, sampler=weighted_sampler)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulticlassClassification(nn.Module):\n",
    "    def __init__(self, num_feature, num_class):\n",
    "        super(MulticlassClassification, self).__init__()\n",
    "        # Number of input features is 30.\n",
    "        self.layer_1 = nn.Linear(num_feature, 2048) \n",
    "        self.layer_2 = nn.Linear(2048, 1024)\n",
    "        self.layer_3 = nn.Linear(1024, 256)\n",
    "        #self.layer_3 = nn.Linear(NODES, NODES)\n",
    "        #self.layer_4= nn.Linear(NODES, NODES)\n",
    "        self.layer_out = nn.Linear(256, num_class) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(2048)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(1024)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(256)\n",
    "        #self.batchnorm4 = nn.BatchNorm1d(NODES)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "       #x = self.relu(self.layer_4(x))\n",
    "       #x = self.batchnorm4(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MulticlassClassification(\n",
      "  (layer_1): Linear(in_features=30, out_features=2048, bias=True)\n",
      "  (layer_2): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "  (layer_3): Linear(in_features=1024, out_features=256, bias=True)\n",
      "  (layer_out): Linear(in_features=256, out_features=4, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MulticlassClassification(num_feature=NUM_FEATURES, num_class=NUM_CLASSES)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "#criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_acc(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
    "    \n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    \n",
    "    acc = torch.round(acc) * 100\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 1.13744 | Acc: 0.000\n",
      "Epoch 002: | Loss: 0.97619 | Acc: 0.000\n",
      "Epoch 003: | Loss: 0.92124 | Acc: 0.000\n",
      "Epoch 004: | Loss: 0.88813 | Acc: 0.000\n",
      "Epoch 005: | Loss: 0.87362 | Acc: 10.000\n",
      "Epoch 006: | Loss: 0.85709 | Acc: 30.000\n",
      "Epoch 007: | Loss: 0.82110 | Acc: 60.000\n",
      "Epoch 008: | Loss: 0.78322 | Acc: 80.000\n",
      "Epoch 009: | Loss: 0.77915 | Acc: 80.000\n",
      "Epoch 010: | Loss: 0.77817 | Acc: 100.000\n",
      "Epoch 011: | Loss: 0.74275 | Acc: 100.000\n",
      "Epoch 012: | Loss: 0.70293 | Acc: 100.000\n",
      "Epoch 013: | Loss: 0.74428 | Acc: 100.000\n",
      "Epoch 014: | Loss: 0.72333 | Acc: 100.000\n",
      "Epoch 015: | Loss: 0.67814 | Acc: 100.000\n",
      "Epoch 016: | Loss: 0.70889 | Acc: 100.000\n",
      "Epoch 017: | Loss: 0.70707 | Acc: 100.000\n",
      "Epoch 018: | Loss: 0.69626 | Acc: 100.000\n",
      "Epoch 019: | Loss: 0.65492 | Acc: 100.000\n",
      "Epoch 020: | Loss: 0.64807 | Acc: 100.000\n",
      "Epoch 021: | Loss: 0.66301 | Acc: 100.000\n",
      "Epoch 022: | Loss: 0.65209 | Acc: 100.000\n",
      "Epoch 023: | Loss: 0.65720 | Acc: 100.000\n",
      "Epoch 024: | Loss: 0.63511 | Acc: 100.000\n",
      "Epoch 025: | Loss: 0.63658 | Acc: 100.000\n",
      "Epoch 026: | Loss: 0.65227 | Acc: 100.000\n",
      "Epoch 027: | Loss: 0.59756 | Acc: 100.000\n",
      "Epoch 028: | Loss: 0.60675 | Acc: 100.000\n",
      "Epoch 029: | Loss: 0.58133 | Acc: 100.000\n",
      "Epoch 030: | Loss: 0.56388 | Acc: 100.000\n",
      "Epoch 031: | Loss: 0.55273 | Acc: 100.000\n",
      "Epoch 032: | Loss: 0.57955 | Acc: 100.000\n",
      "Epoch 033: | Loss: 0.60259 | Acc: 100.000\n",
      "Epoch 034: | Loss: 0.54039 | Acc: 100.000\n",
      "Epoch 035: | Loss: 0.55175 | Acc: 100.000\n",
      "Epoch 036: | Loss: 0.55184 | Acc: 100.000\n",
      "Epoch 037: | Loss: 0.54589 | Acc: 100.000\n",
      "Epoch 038: | Loss: 0.54134 | Acc: 100.000\n",
      "Epoch 039: | Loss: 0.54822 | Acc: 100.000\n",
      "Epoch 040: | Loss: 0.50616 | Acc: 100.000\n",
      "Epoch 041: | Loss: 0.51768 | Acc: 100.000\n",
      "Epoch 042: | Loss: 0.51830 | Acc: 100.000\n",
      "Epoch 043: | Loss: 0.53372 | Acc: 100.000\n",
      "Epoch 044: | Loss: 0.50959 | Acc: 100.000\n",
      "Epoch 045: | Loss: 0.51457 | Acc: 100.000\n",
      "Epoch 046: | Loss: 0.49412 | Acc: 100.000\n",
      "Epoch 047: | Loss: 0.51410 | Acc: 100.000\n",
      "Epoch 048: | Loss: 0.48775 | Acc: 100.000\n",
      "Epoch 049: | Loss: 0.48822 | Acc: 100.000\n",
      "Epoch 050: | Loss: 0.46977 | Acc: 100.000\n",
      "Epoch 051: | Loss: 0.49744 | Acc: 100.000\n",
      "Epoch 052: | Loss: 0.45058 | Acc: 100.000\n",
      "Epoch 053: | Loss: 0.45089 | Acc: 100.000\n",
      "Epoch 054: | Loss: 0.46869 | Acc: 100.000\n",
      "Epoch 055: | Loss: 0.45324 | Acc: 100.000\n",
      "Epoch 056: | Loss: 0.45440 | Acc: 100.000\n",
      "Epoch 057: | Loss: 0.44876 | Acc: 100.000\n",
      "Epoch 058: | Loss: 0.45349 | Acc: 100.000\n",
      "Epoch 059: | Loss: 0.44338 | Acc: 100.000\n",
      "Epoch 060: | Loss: 0.42364 | Acc: 100.000\n",
      "Epoch 061: | Loss: 0.43850 | Acc: 100.000\n",
      "Epoch 062: | Loss: 0.40087 | Acc: 100.000\n",
      "Epoch 063: | Loss: 0.42264 | Acc: 100.000\n",
      "Epoch 064: | Loss: 0.42179 | Acc: 100.000\n",
      "Epoch 065: | Loss: 0.41363 | Acc: 100.000\n",
      "Epoch 066: | Loss: 0.41903 | Acc: 100.000\n",
      "Epoch 067: | Loss: 0.42825 | Acc: 100.000\n",
      "Epoch 068: | Loss: 0.39640 | Acc: 100.000\n",
      "Epoch 069: | Loss: 0.41594 | Acc: 100.000\n",
      "Epoch 070: | Loss: 0.40278 | Acc: 100.000\n",
      "Epoch 071: | Loss: 0.39351 | Acc: 100.000\n",
      "Epoch 072: | Loss: 0.40321 | Acc: 100.000\n",
      "Epoch 073: | Loss: 0.37773 | Acc: 100.000\n",
      "Epoch 074: | Loss: 0.37566 | Acc: 100.000\n",
      "Epoch 075: | Loss: 0.37986 | Acc: 100.000\n",
      "Epoch 076: | Loss: 0.36620 | Acc: 100.000\n",
      "Epoch 077: | Loss: 0.35448 | Acc: 100.000\n",
      "Epoch 078: | Loss: 0.35615 | Acc: 100.000\n",
      "Epoch 079: | Loss: 0.33915 | Acc: 100.000\n",
      "Epoch 080: | Loss: 0.34841 | Acc: 100.000\n",
      "Epoch 081: | Loss: 0.32335 | Acc: 100.000\n",
      "Epoch 082: | Loss: 0.36772 | Acc: 100.000\n",
      "Epoch 083: | Loss: 0.35872 | Acc: 100.000\n",
      "Epoch 084: | Loss: 0.34147 | Acc: 100.000\n",
      "Epoch 085: | Loss: 0.33507 | Acc: 100.000\n",
      "Epoch 086: | Loss: 0.33397 | Acc: 100.000\n",
      "Epoch 087: | Loss: 0.35676 | Acc: 100.000\n",
      "Epoch 088: | Loss: 0.34207 | Acc: 100.000\n",
      "Epoch 089: | Loss: 0.32448 | Acc: 100.000\n",
      "Epoch 090: | Loss: 0.32524 | Acc: 100.000\n",
      "Epoch 091: | Loss: 0.33610 | Acc: 100.000\n",
      "Epoch 092: | Loss: 0.31595 | Acc: 100.000\n",
      "Epoch 093: | Loss: 0.31417 | Acc: 100.000\n",
      "Epoch 094: | Loss: 0.32597 | Acc: 100.000\n",
      "Epoch 095: | Loss: 0.30660 | Acc: 100.000\n",
      "Epoch 096: | Loss: 0.31450 | Acc: 100.000\n",
      "Epoch 097: | Loss: 0.30469 | Acc: 100.000\n",
      "Epoch 098: | Loss: 0.30477 | Acc: 100.000\n",
      "Epoch 099: | Loss: 0.30054 | Acc: 100.000\n",
      "Epoch 100: | Loss: 0.29377 | Acc: 100.000\n",
      "Epoch 101: | Loss: 0.30909 | Acc: 100.000\n",
      "Epoch 102: | Loss: 0.29255 | Acc: 100.000\n",
      "Epoch 103: | Loss: 0.27384 | Acc: 100.000\n",
      "Epoch 104: | Loss: 0.28706 | Acc: 100.000\n",
      "Epoch 105: | Loss: 0.27638 | Acc: 100.000\n",
      "Epoch 106: | Loss: 0.27682 | Acc: 100.000\n",
      "Epoch 107: | Loss: 0.28072 | Acc: 100.000\n",
      "Epoch 108: | Loss: 0.27158 | Acc: 100.000\n",
      "Epoch 109: | Loss: 0.26892 | Acc: 100.000\n",
      "Epoch 110: | Loss: 0.29581 | Acc: 100.000\n",
      "Epoch 111: | Loss: 0.28776 | Acc: 100.000\n",
      "Epoch 112: | Loss: 0.28686 | Acc: 100.000\n",
      "Epoch 113: | Loss: 0.25506 | Acc: 100.000\n",
      "Epoch 114: | Loss: 0.25381 | Acc: 100.000\n",
      "Epoch 115: | Loss: 0.26375 | Acc: 100.000\n",
      "Epoch 116: | Loss: 0.25398 | Acc: 100.000\n",
      "Epoch 117: | Loss: 0.24064 | Acc: 100.000\n",
      "Epoch 118: | Loss: 0.25045 | Acc: 100.000\n",
      "Epoch 119: | Loss: 0.26677 | Acc: 100.000\n",
      "Epoch 120: | Loss: 0.25119 | Acc: 100.000\n",
      "Epoch 121: | Loss: 0.24353 | Acc: 100.000\n",
      "Epoch 122: | Loss: 0.23740 | Acc: 100.000\n",
      "Epoch 123: | Loss: 0.24843 | Acc: 100.000\n",
      "Epoch 124: | Loss: 0.24455 | Acc: 100.000\n",
      "Epoch 125: | Loss: 0.23046 | Acc: 100.000\n",
      "Epoch 126: | Loss: 0.23271 | Acc: 100.000\n",
      "Epoch 127: | Loss: 0.22334 | Acc: 100.000\n",
      "Epoch 128: | Loss: 0.23084 | Acc: 100.000\n",
      "Epoch 129: | Loss: 0.22248 | Acc: 100.000\n",
      "Epoch 130: | Loss: 0.22062 | Acc: 100.000\n",
      "Epoch 131: | Loss: 0.23565 | Acc: 100.000\n",
      "Epoch 132: | Loss: 0.23329 | Acc: 100.000\n",
      "Epoch 133: | Loss: 0.22482 | Acc: 100.000\n",
      "Epoch 134: | Loss: 0.21425 | Acc: 100.000\n",
      "Epoch 135: | Loss: 0.21991 | Acc: 100.000\n",
      "Epoch 136: | Loss: 0.21485 | Acc: 100.000\n",
      "Epoch 137: | Loss: 0.20673 | Acc: 100.000\n",
      "Epoch 138: | Loss: 0.20953 | Acc: 100.000\n",
      "Epoch 139: | Loss: 0.21558 | Acc: 100.000\n",
      "Epoch 140: | Loss: 0.22446 | Acc: 100.000\n",
      "Epoch 141: | Loss: 0.21247 | Acc: 100.000\n",
      "Epoch 142: | Loss: 0.20183 | Acc: 100.000\n",
      "Epoch 143: | Loss: 0.20719 | Acc: 100.000\n",
      "Epoch 144: | Loss: 0.21730 | Acc: 100.000\n",
      "Epoch 145: | Loss: 0.20721 | Acc: 100.000\n",
      "Epoch 146: | Loss: 0.21054 | Acc: 100.000\n",
      "Epoch 147: | Loss: 0.20212 | Acc: 100.000\n",
      "Epoch 148: | Loss: 0.18919 | Acc: 100.000\n",
      "Epoch 149: | Loss: 0.19671 | Acc: 100.000\n",
      "Epoch 150: | Loss: 0.18747 | Acc: 100.000\n",
      "Epoch 151: | Loss: 0.19617 | Acc: 100.000\n",
      "Epoch 152: | Loss: 0.19527 | Acc: 100.000\n",
      "Epoch 153: | Loss: 0.20162 | Acc: 100.000\n",
      "Epoch 154: | Loss: 0.20340 | Acc: 100.000\n",
      "Epoch 155: | Loss: 0.18819 | Acc: 100.000\n",
      "Epoch 156: | Loss: 0.19231 | Acc: 100.000\n",
      "Epoch 157: | Loss: 0.19118 | Acc: 100.000\n",
      "Epoch 158: | Loss: 0.18547 | Acc: 100.000\n",
      "Epoch 159: | Loss: 0.18268 | Acc: 100.000\n",
      "Epoch 160: | Loss: 0.16959 | Acc: 100.000\n",
      "Epoch 161: | Loss: 0.17814 | Acc: 100.000\n",
      "Epoch 162: | Loss: 0.17435 | Acc: 100.000\n",
      "Epoch 163: | Loss: 0.17339 | Acc: 100.000\n",
      "Epoch 164: | Loss: 0.17013 | Acc: 100.000\n",
      "Epoch 165: | Loss: 0.17113 | Acc: 100.000\n",
      "Epoch 166: | Loss: 0.17898 | Acc: 100.000\n",
      "Epoch 167: | Loss: 0.17554 | Acc: 100.000\n",
      "Epoch 168: | Loss: 0.18562 | Acc: 100.000\n",
      "Epoch 169: | Loss: 0.17227 | Acc: 100.000\n",
      "Epoch 170: | Loss: 0.16316 | Acc: 100.000\n",
      "Epoch 171: | Loss: 0.17722 | Acc: 100.000\n",
      "Epoch 172: | Loss: 0.15628 | Acc: 100.000\n",
      "Epoch 173: | Loss: 0.18125 | Acc: 100.000\n",
      "Epoch 174: | Loss: 0.16508 | Acc: 100.000\n",
      "Epoch 175: | Loss: 0.17229 | Acc: 100.000\n",
      "Epoch 176: | Loss: 0.16561 | Acc: 100.000\n",
      "Epoch 177: | Loss: 0.18373 | Acc: 100.000\n",
      "Epoch 178: | Loss: 0.17450 | Acc: 100.000\n",
      "Epoch 179: | Loss: 0.17201 | Acc: 100.000\n",
      "Epoch 180: | Loss: 0.17967 | Acc: 100.000\n",
      "Epoch 181: | Loss: 0.16129 | Acc: 100.000\n",
      "Epoch 182: | Loss: 0.16399 | Acc: 100.000\n",
      "Epoch 183: | Loss: 0.16442 | Acc: 100.000\n",
      "Epoch 184: | Loss: 0.16208 | Acc: 100.000\n",
      "Epoch 185: | Loss: 0.16719 | Acc: 100.000\n",
      "Epoch 186: | Loss: 0.15731 | Acc: 100.000\n",
      "Epoch 187: | Loss: 0.15919 | Acc: 100.000\n",
      "Epoch 188: | Loss: 0.16351 | Acc: 100.000\n",
      "Epoch 189: | Loss: 0.15194 | Acc: 100.000\n",
      "Epoch 190: | Loss: 0.16091 | Acc: 100.000\n",
      "Epoch 191: | Loss: 0.15499 | Acc: 100.000\n",
      "Epoch 192: | Loss: 0.16271 | Acc: 100.000\n",
      "Epoch 193: | Loss: 0.17107 | Acc: 100.000\n",
      "Epoch 194: | Loss: 0.16353 | Acc: 100.000\n",
      "Epoch 195: | Loss: 0.15048 | Acc: 100.000\n",
      "Epoch 196: | Loss: 0.14418 | Acc: 100.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197: | Loss: 0.14884 | Acc: 100.000\n",
      "Epoch 198: | Loss: 0.15567 | Acc: 100.000\n",
      "Epoch 199: | Loss: 0.14552 | Acc: 100.000\n",
      "Epoch 200: | Loss: 0.14398 | Acc: 100.000\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = multi_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for X_batch, _ in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_pred_softmax = torch.log_softmax(y_test_pred, dim = 1)\n",
    "        _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
    "        y_pred_list.append(y_pred_tags.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  46,   95,   18,    1],\n",
       "       [ 150, 1050,  423,   22],\n",
       "       [  13,  249,  324,   30],\n",
       "       [   3,   16,   26,    3]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.22      0.29      0.25       160\n",
      "         1.0       0.74      0.64      0.69      1645\n",
      "         2.0       0.41      0.53      0.46       616\n",
      "         3.0       0.05      0.06      0.06        48\n",
      "\n",
      "    accuracy                           0.58      2469\n",
      "   macro avg       0.36      0.38      0.36      2469\n",
      "weighted avg       0.61      0.58      0.59      2469\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

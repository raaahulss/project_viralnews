{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from textblob import TextBlob\n",
    "\n",
    "import torch\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "BATCH_SIZE = 1024\n",
    "LEARNING_RATE = 0.001\n",
    "NODES = 1000\n",
    "NUM_FEATURES = 30\n",
    "NUM_CLASSES = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/Organic_extended_finalv3.csv\", sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find max retweets\n",
    "max_list = list()\n",
    "for index, row in df.iterrows():\n",
    "    num_list = list()\n",
    "    num_list = {row[\"1\"], row[\"2\"],row[\"3\"], row[\"4\"],row[\"5\"], row[\"6\"]}\n",
    "    max_list.append(max(num_list))\n",
    "df[\"max_retweets\"] = max_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating mean/median\n",
      "mean:  149.06297636191212\n",
      "median:  50.0\n",
      "Number of entries:  28471\n"
     ]
    }
   ],
   "source": [
    "# Find mean/median and size\n",
    "print(\"calculating mean/median\")\n",
    "mean =  df[\"max_retweets\"].mean()\n",
    "median = df[\"max_retweets\"].median()\n",
    "print(\"mean: \", mean)\n",
    "print(\"median: \", median)\n",
    "print(\"Number of entries: \", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date strings to datetime objeccts\n",
    "date_time = list()\n",
    "for index, row in df.iterrows():\n",
    "    if(row[\"created_time\"].lower().islower()):\n",
    "        # date time w/ letter (Jun, Mon, etc)\n",
    "        date_time_obj = datetime.strptime(row[\"created_time\"], '%a %b %d %H:%M:%S +0000 %Y')\n",
    "        date_time.append(date_time_obj)\n",
    "    else:\n",
    "        # date time w/ not letters (Jun, Mon, etc)\n",
    "        date_time_obj = datetime.strptime(row[\"created_time\"], '%Y-%m-%d %H:%M:%S+00:00')\n",
    "        date_time.append(date_time_obj)\n",
    "df[\"created_datetime\"] = date_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data for what day of week the article was published\n",
    "df['is_mon'] = 0\n",
    "df['is_tue'] = 0\n",
    "df['is_wed'] = 0\n",
    "df['is_thu'] = 0\n",
    "df['is_fri'] = 0\n",
    "df['is_sat'] = 0\n",
    "df['is_sun'] = 0\n",
    "df['is_weekend'] = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    day = row[\"created_datetime\"].weekday()\n",
    "    if day is 0:\n",
    "        df.at[index,'is_sun'] = 1\n",
    "        df.at[index,'is_weekend'] = 1\n",
    "    elif day is 1:\n",
    "        df.at[index,'is_mon'] = 1\n",
    "    elif day is 2:\n",
    "        df.at[index,'is_tue'] = 1\n",
    "    elif day is 3:\n",
    "        df.at[index,'is_wed'] = 1\n",
    "    elif day is 4:\n",
    "        df.at[index,'is_thu'] = 1\n",
    "    elif day is 5:\n",
    "        df.at[index,'is_fri'] = 1\n",
    "    elif day is 6:\n",
    "        df.at[index,'is_sat'] = 1\n",
    "        df.at[index,'is_weekend'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subjectivity and polarity\n",
    "for index, row in df.iterrows():\n",
    "    title_score = TextBlob(row[\"title\"]).sentiment\n",
    "    content_score = TextBlob(row[\"content\"]).sentiment\n",
    "    df.at[index,'title_polarity'] = title_score[0]\n",
    "    df.at[index,'title_subjectivity'] = title_score[1]\n",
    "    df.at[index,'content_polarity'] = content_score[0]\n",
    "    df.at[index,'content_subjectivity'] = content_score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source\n",
    "accounts = [\"CNN\",\"The Wall Street Journal\",\"The Washington Post\",\"NBC News\",\n",
    "            \"The Associated Press\",\"ABC News\",\"Los Angeles Times\",\"The New York Times\",\"NPR\",\"TIME\",\"U.S. News\",\"USA TODAY\",\n",
    "            \"Fox News\",\"Reuters\",\"HuffPost\"]\n",
    "for i in accounts:\n",
    "    df[i] = 0\n",
    "\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    df.at[index,row[\"screen_name\"]] = 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:  24.0 2:  50.0 3:  110.0\n"
     ]
    }
   ],
   "source": [
    "# 0 -> 0-0.25 quantile\n",
    "# 1 -> 0.26-0.50 quantile\n",
    "# 2 -> < 0.51-0.75 quantile\n",
    "# 3 -> >= 0.76-1.00 quantile\n",
    "\n",
    "\n",
    "quan_dict=df.max_retweets.quantile([0.25, 0.5, 0.75])\n",
    "one_quar = quan_dict[0.25]\n",
    "two_quar = quan_dict[0.5]\n",
    "three_quar = quan_dict[0.75]\n",
    "\n",
    "\n",
    "#one_quar = 10\n",
    "#two_quar = 100\n",
    "#three_quar = 1000\n",
    "\n",
    "\n",
    "\n",
    "print(\"1: \", one_quar, \"2: \", two_quar, \"3: \", three_quar)\n",
    "\n",
    "df.loc[df['max_retweets'] <= one_quar, 'shares'] = 0\n",
    "df.loc[((df['max_retweets'] > one_quar) & (df['max_retweets'] <= two_quar)), 'shares'] = 1\n",
    "df.loc[((df['max_retweets'] > two_quar) & (df['max_retweets'] <= three_quar)), 'shares'] = 2\n",
    "df.loc[df['max_retweets'] > three_quar, 'shares'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x20384ef41c8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'shares', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>created_time</th>\n",
       "      <th>count</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>Los Angeles Times</th>\n",
       "      <th>The New York Times</th>\n",
       "      <th>NPR</th>\n",
       "      <th>TIME</th>\n",
       "      <th>U.S. News</th>\n",
       "      <th>USA TODAY</th>\n",
       "      <th>Fox News</th>\n",
       "      <th>Reuters</th>\n",
       "      <th>HuffPost</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1272217655630458881</td>\n",
       "      <td>2020-06-14 17:21:40+00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>454</td>\n",
       "      <td>463.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>466.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1272216897237516289</td>\n",
       "      <td>2020-06-14 17:18:39+00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>163</td>\n",
       "      <td>163.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1272220034065186817</td>\n",
       "      <td>2020-06-14 17:31:07+00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>910</td>\n",
       "      <td>927.0</td>\n",
       "      <td>929.0</td>\n",
       "      <td>933.0</td>\n",
       "      <td>934.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1272219784743202816</td>\n",
       "      <td>2020-06-14 17:30:08+00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>2352</td>\n",
       "      <td>2377.0</td>\n",
       "      <td>2381.0</td>\n",
       "      <td>2378.0</td>\n",
       "      <td>2376.0</td>\n",
       "      <td>2373.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1272220746014572545</td>\n",
       "      <td>2020-06-14 17:33:57+00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>241</td>\n",
       "      <td>267.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             tweet_id               created_time  count     1  \\\n",
       "0           0  1272217655630458881  2020-06-14 17:21:40+00:00     17   454   \n",
       "1           1  1272216897237516289  2020-06-14 17:18:39+00:00     17   163   \n",
       "2           2  1272220034065186817  2020-06-14 17:31:07+00:00     17   910   \n",
       "3           3  1272219784743202816  2020-06-14 17:30:08+00:00     17  2352   \n",
       "4           4  1272220746014572545  2020-06-14 17:33:57+00:00     17   241   \n",
       "\n",
       "        2       3       4       5       6  ...  Los Angeles Times  \\\n",
       "0   463.0   462.0   464.0   464.0   466.0  ...                  1   \n",
       "1   163.0   163.0   163.0   162.0   162.0  ...                  0   \n",
       "2   927.0   929.0   933.0   934.0   936.0  ...                  0   \n",
       "3  2377.0  2381.0  2378.0  2376.0  2373.0  ...                  0   \n",
       "4   267.0   267.0   267.0   267.0   267.0  ...                  1   \n",
       "\n",
       "  The New York Times NPR  TIME U.S. News USA TODAY Fox News  Reuters  \\\n",
       "0                  0   0     0         0         0        0        0   \n",
       "1                  0   0     0         0         0        0        0   \n",
       "2                  0   0     0         0         0        0        0   \n",
       "3                  1   0     0         0         0        0        0   \n",
       "4                  0   0     0         0         0        0        0   \n",
       "\n",
       "   HuffPost  shares  \n",
       "0         0     2.0  \n",
       "1         0     2.0  \n",
       "2         0     2.0  \n",
       "3         0     3.0  \n",
       "4         0     2.0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['tweet_id','created_time','count','1','2','3','4','5','6','user_id','screen_name','title','content','url','expanded_url','created_datetime','max_retweets'], axis = 1)\n",
    "X = df.iloc[:, 1:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>follower_count</th>\n",
       "      <th>title_len</th>\n",
       "      <th>content_len</th>\n",
       "      <th>is_mon</th>\n",
       "      <th>is_tue</th>\n",
       "      <th>is_wed</th>\n",
       "      <th>is_thu</th>\n",
       "      <th>is_fri</th>\n",
       "      <th>is_sat</th>\n",
       "      <th>is_sun</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>title_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>content_polarity</th>\n",
       "      <th>content_subjectivity</th>\n",
       "      <th>CNN</th>\n",
       "      <th>The Wall Street Journal</th>\n",
       "      <th>The Washington Post</th>\n",
       "      <th>NBC News</th>\n",
       "      <th>The Associated Press</th>\n",
       "      <th>ABC News</th>\n",
       "      <th>Los Angeles Times</th>\n",
       "      <th>The New York Times</th>\n",
       "      <th>NPR</th>\n",
       "      <th>TIME</th>\n",
       "      <th>U.S. News</th>\n",
       "      <th>USA TODAY</th>\n",
       "      <th>Fox News</th>\n",
       "      <th>Reuters</th>\n",
       "      <th>HuffPost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3634148.0</td>\n",
       "      <td>8</td>\n",
       "      <td>369</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.072377</td>\n",
       "      <td>0.383025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15735968.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1766</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.019223</td>\n",
       "      <td>0.347613</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48817611.0</td>\n",
       "      <td>15</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.209750</td>\n",
       "      <td>0.475417</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46861284.0</td>\n",
       "      <td>9</td>\n",
       "      <td>4174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.017214</td>\n",
       "      <td>0.481129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3634146.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2826</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.418182</td>\n",
       "      <td>0.627273</td>\n",
       "      <td>0.066627</td>\n",
       "      <td>0.399637</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   follower_count  title_len  content_len  is_mon  is_tue  is_wed  is_thu  \\\n",
       "0       3634148.0          8          369       0       0       0       0   \n",
       "1      15735968.0         14         1766       0       0       0       0   \n",
       "2      48817611.0         15          190       0       0       0       0   \n",
       "3      46861284.0          9         4174       0       0       0       0   \n",
       "4       3634146.0         16         2826       0       0       0       0   \n",
       "\n",
       "   is_fri  is_sat  is_sun  is_weekend  title_polarity  title_subjectivity  \\\n",
       "0       0       1       0           1       -0.166667            0.433333   \n",
       "1       0       1       0           1        0.016667            0.266667   \n",
       "2       0       1       0           1        0.075000            0.216667   \n",
       "3       0       1       0           1        0.033333            0.066667   \n",
       "4       0       1       0           1        0.418182            0.627273   \n",
       "\n",
       "   content_polarity  content_subjectivity  CNN  The Wall Street Journal  \\\n",
       "0          0.072377              0.383025    0                        0   \n",
       "1          0.019223              0.347613    0                        0   \n",
       "2          0.209750              0.475417    1                        0   \n",
       "3          0.017214              0.481129    0                        0   \n",
       "4          0.066627              0.399637    0                        0   \n",
       "\n",
       "   The Washington Post  NBC News  The Associated Press  ABC News  \\\n",
       "0                    0         0                     0         0   \n",
       "1                    0         0                     0         1   \n",
       "2                    0         0                     0         0   \n",
       "3                    0         0                     0         0   \n",
       "4                    0         0                     0         0   \n",
       "\n",
       "   Los Angeles Times  The New York Times  NPR  TIME  U.S. News  USA TODAY  \\\n",
       "0                  1                   0    0     0          0          0   \n",
       "1                  0                   0    0     0          0          0   \n",
       "2                  0                   0    0     0          0          0   \n",
       "3                  0                   1    0     0          0          0   \n",
       "4                  1                   0    0     0          0          0   \n",
       "\n",
       "   Fox News  Reuters  HuffPost  \n",
       "0         0        0         0  \n",
       "1         0        0         0  \n",
       "2         0        0         0  \n",
       "3         0        0         0  \n",
       "4         0        0         0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "len(X.columns)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        3.0\n",
       "1        3.0\n",
       "2        3.0\n",
       "3        3.0\n",
       "4        3.0\n",
       "        ... \n",
       "28466    1.0\n",
       "28467    3.0\n",
       "28468    3.0\n",
       "28469    3.0\n",
       "28470    0.0\n",
       "Name: shares, Length: 28471, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "train_data = trainData(torch.FloatTensor(X_train), torch.LongTensor(y_train))\n",
    "\n",
    "## test data    \n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "test_data = testData(torch.FloatTensor(X_test), torch.LongTensor(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_distribution(obj):\n",
    "    count_dict = {\n",
    "        \"0\":0,\n",
    "        \"1\":0,\n",
    "        \"2\":0,\n",
    "        \"3\":0\n",
    "    }\n",
    "    \n",
    "    for i in obj:\n",
    "        if i == 0:\n",
    "            count_dict[\"0\"] += 1\n",
    "        elif i == 1:\n",
    "            count_dict[\"1\"] += 1\n",
    "        elif i == 2:\n",
    "            count_dict[\"2\"] += 1\n",
    "        else:\n",
    "            count_dict[\"3\"] += 1\n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = []\n",
    "\n",
    "for _, t in train_data:\n",
    "    target_list.append(t)\n",
    "    \n",
    "target_list = torch.tensor(target_list)\n",
    "target_list = target_list[torch.randperm(len(target_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0002, 0.0002, 0.0002, 0.0002])\n"
     ]
    }
   ],
   "source": [
    "class_count = [i for i in get_class_distribution(y_train).values()]\n",
    "class_weights = 1./torch.tensor(class_count, dtype=torch.float)\n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_all = class_weights[target_list]\n",
    "\n",
    "weighted_sampler = WeightedRandomSampler(\n",
    "    weights = class_weights_all, \n",
    "    num_samples = len(class_weights_all),\n",
    "    replacement = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, sampler=weighted_sampler)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulticlassClassification(nn.Module):\n",
    "    def __init__(self, num_feature, num_class):\n",
    "        super(MulticlassClassification, self).__init__()\n",
    "        # Number of input features is 30.\n",
    "        self.layer_1 = nn.Linear(num_feature, 2048) \n",
    "        self.layer_2 = nn.Linear(2048, 1024)\n",
    "        self.layer_3 = nn.Linear(1024, 256)\n",
    "        #self.layer_3 = nn.Linear(NODES, NODES)\n",
    "        #self.layer_4= nn.Linear(NODES, NODES)\n",
    "        self.layer_out = nn.Linear(256, num_class) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(2048)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(1024)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(256)\n",
    "        #self.batchnorm4 = nn.BatchNorm1d(NODES)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "       #x = self.relu(self.layer_4(x))\n",
    "       #x = self.batchnorm4(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MulticlassClassification(\n",
      "  (layer_1): Linear(in_features=30, out_features=2048, bias=True)\n",
      "  (layer_2): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "  (layer_3): Linear(in_features=1024, out_features=256, bias=True)\n",
      "  (layer_out): Linear(in_features=256, out_features=4, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MulticlassClassification(num_feature=NUM_FEATURES, num_class=NUM_CLASSES)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "#criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_acc(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
    "    \n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    \n",
    "    acc = torch.round(acc) * 100\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 1.30281 | Acc: 0.000\n",
      "Epoch 002: | Loss: 1.20304 | Acc: 0.000\n",
      "Epoch 003: | Loss: 1.19698 | Acc: 0.000\n",
      "Epoch 004: | Loss: 1.18410 | Acc: 0.000\n",
      "Epoch 005: | Loss: 1.18083 | Acc: 0.000\n",
      "Epoch 006: | Loss: 1.17955 | Acc: 0.000\n",
      "Epoch 007: | Loss: 1.17710 | Acc: 0.000\n",
      "Epoch 008: | Loss: 1.17468 | Acc: 0.000\n",
      "Epoch 009: | Loss: 1.17371 | Acc: 0.000\n",
      "Epoch 010: | Loss: 1.16546 | Acc: 0.000\n",
      "Epoch 011: | Loss: 1.16027 | Acc: 0.000\n",
      "Epoch 012: | Loss: 1.16118 | Acc: 4.348\n",
      "Epoch 013: | Loss: 1.15800 | Acc: 0.000\n",
      "Epoch 014: | Loss: 1.15862 | Acc: 4.348\n",
      "Epoch 015: | Loss: 1.15229 | Acc: 0.000\n",
      "Epoch 016: | Loss: 1.15113 | Acc: 0.000\n",
      "Epoch 017: | Loss: 1.15282 | Acc: 4.348\n",
      "Epoch 018: | Loss: 1.13639 | Acc: 0.000\n",
      "Epoch 019: | Loss: 1.13634 | Acc: 4.348\n",
      "Epoch 020: | Loss: 1.13260 | Acc: 8.696\n",
      "Epoch 021: | Loss: 1.13511 | Acc: 8.696\n",
      "Epoch 022: | Loss: 1.13740 | Acc: 4.348\n",
      "Epoch 023: | Loss: 1.12419 | Acc: 13.043\n",
      "Epoch 024: | Loss: 1.12706 | Acc: 8.696\n",
      "Epoch 025: | Loss: 1.13066 | Acc: 8.696\n",
      "Epoch 026: | Loss: 1.12243 | Acc: 13.043\n",
      "Epoch 027: | Loss: 1.11560 | Acc: 17.391\n",
      "Epoch 028: | Loss: 1.11371 | Acc: 26.087\n",
      "Epoch 029: | Loss: 1.11493 | Acc: 17.391\n",
      "Epoch 030: | Loss: 1.10680 | Acc: 30.435\n",
      "Epoch 031: | Loss: 1.11245 | Acc: 30.435\n",
      "Epoch 032: | Loss: 1.10077 | Acc: 26.087\n",
      "Epoch 033: | Loss: 1.09682 | Acc: 47.826\n",
      "Epoch 034: | Loss: 1.09634 | Acc: 47.826\n",
      "Epoch 035: | Loss: 1.08699 | Acc: 65.217\n",
      "Epoch 036: | Loss: 1.07835 | Acc: 78.261\n",
      "Epoch 037: | Loss: 1.08196 | Acc: 78.261\n",
      "Epoch 038: | Loss: 1.07505 | Acc: 78.261\n",
      "Epoch 039: | Loss: 1.06548 | Acc: 78.261\n",
      "Epoch 040: | Loss: 1.06232 | Acc: 82.609\n",
      "Epoch 041: | Loss: 1.06114 | Acc: 82.609\n",
      "Epoch 042: | Loss: 1.05104 | Acc: 95.652\n",
      "Epoch 043: | Loss: 1.04092 | Acc: 100.000\n",
      "Epoch 044: | Loss: 1.03683 | Acc: 95.652\n",
      "Epoch 045: | Loss: 1.04301 | Acc: 91.304\n",
      "Epoch 046: | Loss: 1.03450 | Acc: 91.304\n",
      "Epoch 047: | Loss: 1.02510 | Acc: 95.652\n",
      "Epoch 048: | Loss: 1.00363 | Acc: 100.000\n",
      "Epoch 049: | Loss: 1.01050 | Acc: 100.000\n",
      "Epoch 050: | Loss: 0.99028 | Acc: 100.000\n",
      "Epoch 051: | Loss: 0.98033 | Acc: 100.000\n",
      "Epoch 052: | Loss: 0.98384 | Acc: 100.000\n",
      "Epoch 053: | Loss: 0.97642 | Acc: 100.000\n",
      "Epoch 054: | Loss: 0.96776 | Acc: 100.000\n",
      "Epoch 055: | Loss: 0.95740 | Acc: 100.000\n",
      "Epoch 056: | Loss: 0.94130 | Acc: 100.000\n",
      "Epoch 057: | Loss: 0.93040 | Acc: 100.000\n",
      "Epoch 058: | Loss: 0.93891 | Acc: 100.000\n",
      "Epoch 059: | Loss: 0.92236 | Acc: 100.000\n",
      "Epoch 060: | Loss: 0.90960 | Acc: 100.000\n",
      "Epoch 061: | Loss: 0.89084 | Acc: 100.000\n",
      "Epoch 062: | Loss: 0.88419 | Acc: 100.000\n",
      "Epoch 063: | Loss: 0.88060 | Acc: 100.000\n",
      "Epoch 064: | Loss: 0.86731 | Acc: 100.000\n",
      "Epoch 065: | Loss: 0.85752 | Acc: 100.000\n",
      "Epoch 066: | Loss: 0.85305 | Acc: 100.000\n",
      "Epoch 067: | Loss: 0.83724 | Acc: 100.000\n",
      "Epoch 068: | Loss: 0.83228 | Acc: 100.000\n",
      "Epoch 069: | Loss: 0.81337 | Acc: 100.000\n",
      "Epoch 070: | Loss: 0.80211 | Acc: 100.000\n",
      "Epoch 071: | Loss: 0.80120 | Acc: 100.000\n",
      "Epoch 072: | Loss: 0.78420 | Acc: 100.000\n",
      "Epoch 073: | Loss: 0.77333 | Acc: 100.000\n",
      "Epoch 074: | Loss: 0.75908 | Acc: 100.000\n",
      "Epoch 075: | Loss: 0.74260 | Acc: 100.000\n",
      "Epoch 076: | Loss: 0.73815 | Acc: 100.000\n",
      "Epoch 077: | Loss: 0.72673 | Acc: 100.000\n",
      "Epoch 078: | Loss: 0.73057 | Acc: 100.000\n",
      "Epoch 079: | Loss: 0.72699 | Acc: 100.000\n",
      "Epoch 080: | Loss: 0.69250 | Acc: 100.000\n",
      "Epoch 081: | Loss: 0.68648 | Acc: 100.000\n",
      "Epoch 082: | Loss: 0.67902 | Acc: 100.000\n",
      "Epoch 083: | Loss: 0.66420 | Acc: 100.000\n",
      "Epoch 084: | Loss: 0.65663 | Acc: 100.000\n",
      "Epoch 085: | Loss: 0.64768 | Acc: 100.000\n",
      "Epoch 086: | Loss: 0.64315 | Acc: 100.000\n",
      "Epoch 087: | Loss: 0.64202 | Acc: 100.000\n",
      "Epoch 088: | Loss: 0.62090 | Acc: 100.000\n",
      "Epoch 089: | Loss: 0.60553 | Acc: 100.000\n",
      "Epoch 090: | Loss: 0.61312 | Acc: 100.000\n",
      "Epoch 091: | Loss: 0.59273 | Acc: 100.000\n",
      "Epoch 092: | Loss: 0.59921 | Acc: 100.000\n",
      "Epoch 093: | Loss: 0.58202 | Acc: 100.000\n",
      "Epoch 094: | Loss: 0.57193 | Acc: 100.000\n",
      "Epoch 095: | Loss: 0.57418 | Acc: 100.000\n",
      "Epoch 096: | Loss: 0.55391 | Acc: 100.000\n",
      "Epoch 097: | Loss: 0.54747 | Acc: 100.000\n",
      "Epoch 098: | Loss: 0.53855 | Acc: 100.000\n",
      "Epoch 099: | Loss: 0.54286 | Acc: 100.000\n",
      "Epoch 100: | Loss: 0.52949 | Acc: 100.000\n",
      "Epoch 101: | Loss: 0.53298 | Acc: 100.000\n",
      "Epoch 102: | Loss: 0.51800 | Acc: 100.000\n",
      "Epoch 103: | Loss: 0.51943 | Acc: 100.000\n",
      "Epoch 104: | Loss: 0.50432 | Acc: 100.000\n",
      "Epoch 105: | Loss: 0.50352 | Acc: 100.000\n",
      "Epoch 106: | Loss: 0.48760 | Acc: 100.000\n",
      "Epoch 107: | Loss: 0.48884 | Acc: 100.000\n",
      "Epoch 108: | Loss: 0.48146 | Acc: 100.000\n",
      "Epoch 109: | Loss: 0.46944 | Acc: 100.000\n",
      "Epoch 110: | Loss: 0.47860 | Acc: 100.000\n",
      "Epoch 111: | Loss: 0.46987 | Acc: 100.000\n",
      "Epoch 112: | Loss: 0.47581 | Acc: 100.000\n",
      "Epoch 113: | Loss: 0.47124 | Acc: 100.000\n",
      "Epoch 114: | Loss: 0.46132 | Acc: 100.000\n",
      "Epoch 115: | Loss: 0.45488 | Acc: 100.000\n",
      "Epoch 116: | Loss: 0.45561 | Acc: 100.000\n",
      "Epoch 117: | Loss: 0.43944 | Acc: 100.000\n",
      "Epoch 118: | Loss: 0.44230 | Acc: 100.000\n",
      "Epoch 119: | Loss: 0.43487 | Acc: 100.000\n",
      "Epoch 120: | Loss: 0.44044 | Acc: 100.000\n",
      "Epoch 121: | Loss: 0.42840 | Acc: 100.000\n",
      "Epoch 122: | Loss: 0.42062 | Acc: 100.000\n",
      "Epoch 123: | Loss: 0.41782 | Acc: 100.000\n",
      "Epoch 124: | Loss: 0.42229 | Acc: 100.000\n",
      "Epoch 125: | Loss: 0.41525 | Acc: 100.000\n",
      "Epoch 126: | Loss: 0.40295 | Acc: 100.000\n",
      "Epoch 127: | Loss: 0.40987 | Acc: 100.000\n",
      "Epoch 128: | Loss: 0.40700 | Acc: 100.000\n",
      "Epoch 129: | Loss: 0.40851 | Acc: 100.000\n",
      "Epoch 130: | Loss: 0.40172 | Acc: 100.000\n",
      "Epoch 131: | Loss: 0.40561 | Acc: 100.000\n",
      "Epoch 132: | Loss: 0.40855 | Acc: 100.000\n",
      "Epoch 133: | Loss: 0.40021 | Acc: 100.000\n",
      "Epoch 134: | Loss: 0.40590 | Acc: 100.000\n",
      "Epoch 135: | Loss: 0.39694 | Acc: 100.000\n",
      "Epoch 136: | Loss: 0.37658 | Acc: 100.000\n",
      "Epoch 137: | Loss: 0.38542 | Acc: 100.000\n",
      "Epoch 138: | Loss: 0.37387 | Acc: 100.000\n",
      "Epoch 139: | Loss: 0.38193 | Acc: 100.000\n",
      "Epoch 140: | Loss: 0.38150 | Acc: 100.000\n",
      "Epoch 141: | Loss: 0.36793 | Acc: 100.000\n",
      "Epoch 142: | Loss: 0.35768 | Acc: 100.000\n",
      "Epoch 143: | Loss: 0.35522 | Acc: 100.000\n",
      "Epoch 144: | Loss: 0.36485 | Acc: 100.000\n",
      "Epoch 145: | Loss: 0.36072 | Acc: 100.000\n",
      "Epoch 146: | Loss: 0.35415 | Acc: 100.000\n",
      "Epoch 147: | Loss: 0.33884 | Acc: 100.000\n",
      "Epoch 148: | Loss: 0.36006 | Acc: 100.000\n",
      "Epoch 149: | Loss: 0.34763 | Acc: 100.000\n",
      "Epoch 150: | Loss: 0.34507 | Acc: 100.000\n",
      "Epoch 151: | Loss: 0.34690 | Acc: 100.000\n",
      "Epoch 152: | Loss: 0.35420 | Acc: 100.000\n",
      "Epoch 153: | Loss: 0.35501 | Acc: 100.000\n",
      "Epoch 154: | Loss: 0.34856 | Acc: 100.000\n",
      "Epoch 155: | Loss: 0.35294 | Acc: 100.000\n",
      "Epoch 156: | Loss: 0.34773 | Acc: 100.000\n",
      "Epoch 157: | Loss: 0.34868 | Acc: 100.000\n",
      "Epoch 158: | Loss: 0.34338 | Acc: 100.000\n",
      "Epoch 159: | Loss: 0.35063 | Acc: 100.000\n",
      "Epoch 160: | Loss: 0.34386 | Acc: 100.000\n",
      "Epoch 161: | Loss: 0.34177 | Acc: 100.000\n",
      "Epoch 162: | Loss: 0.33669 | Acc: 100.000\n",
      "Epoch 163: | Loss: 0.33435 | Acc: 100.000\n",
      "Epoch 164: | Loss: 0.33294 | Acc: 100.000\n",
      "Epoch 165: | Loss: 0.32941 | Acc: 100.000\n",
      "Epoch 166: | Loss: 0.32764 | Acc: 100.000\n",
      "Epoch 167: | Loss: 0.32835 | Acc: 100.000\n",
      "Epoch 168: | Loss: 0.33861 | Acc: 100.000\n",
      "Epoch 169: | Loss: 0.33190 | Acc: 100.000\n",
      "Epoch 170: | Loss: 0.33157 | Acc: 100.000\n",
      "Epoch 171: | Loss: 0.32704 | Acc: 100.000\n",
      "Epoch 172: | Loss: 0.32189 | Acc: 100.000\n",
      "Epoch 173: | Loss: 0.32198 | Acc: 100.000\n",
      "Epoch 174: | Loss: 0.31727 | Acc: 100.000\n",
      "Epoch 175: | Loss: 0.31985 | Acc: 100.000\n",
      "Epoch 176: | Loss: 0.30260 | Acc: 100.000\n",
      "Epoch 177: | Loss: 0.30377 | Acc: 100.000\n",
      "Epoch 178: | Loss: 0.31136 | Acc: 100.000\n",
      "Epoch 179: | Loss: 0.32321 | Acc: 100.000\n",
      "Epoch 180: | Loss: 0.30565 | Acc: 100.000\n",
      "Epoch 181: | Loss: 0.30729 | Acc: 100.000\n",
      "Epoch 182: | Loss: 0.31088 | Acc: 100.000\n",
      "Epoch 183: | Loss: 0.31766 | Acc: 100.000\n",
      "Epoch 184: | Loss: 0.30489 | Acc: 100.000\n",
      "Epoch 185: | Loss: 0.31191 | Acc: 100.000\n",
      "Epoch 186: | Loss: 0.30145 | Acc: 100.000\n",
      "Epoch 187: | Loss: 0.30853 | Acc: 100.000\n",
      "Epoch 188: | Loss: 0.31594 | Acc: 100.000\n",
      "Epoch 189: | Loss: 0.30842 | Acc: 100.000\n",
      "Epoch 190: | Loss: 0.31105 | Acc: 100.000\n",
      "Epoch 191: | Loss: 0.31539 | Acc: 100.000\n",
      "Epoch 192: | Loss: 0.30380 | Acc: 100.000\n",
      "Epoch 193: | Loss: 0.30584 | Acc: 100.000\n",
      "Epoch 194: | Loss: 0.30942 | Acc: 100.000\n",
      "Epoch 195: | Loss: 0.30137 | Acc: 100.000\n",
      "Epoch 196: | Loss: 0.29657 | Acc: 100.000\n",
      "Epoch 197: | Loss: 0.29540 | Acc: 100.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198: | Loss: 0.29248 | Acc: 100.000\n",
      "Epoch 199: | Loss: 0.28928 | Acc: 100.000\n",
      "Epoch 200: | Loss: 0.29028 | Acc: 100.000\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = multi_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for X_batch, _ in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_pred_softmax = torch.log_softmax(y_test_pred, dim = 1)\n",
    "        _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
    "        y_pred_list.append(y_pred_tags.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[656, 392, 268, 143],\n",
       "       [402, 435, 385, 223],\n",
       "       [235, 305, 418, 421],\n",
       "       [132, 183, 413, 684]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.46      0.45      0.45      1459\n",
      "         1.0       0.33      0.30      0.32      1445\n",
      "         2.0       0.28      0.30      0.29      1379\n",
      "         3.0       0.46      0.48      0.47      1412\n",
      "\n",
      "    accuracy                           0.39      5695\n",
      "   macro avg       0.38      0.38      0.38      5695\n",
      "weighted avg       0.39      0.39      0.38      5695\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

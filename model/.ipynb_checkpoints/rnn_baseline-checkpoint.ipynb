{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating mean/median\n",
      "mean:  3395.3801836343455\n",
      "median:  1400.0\n",
      "39644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../uci_data/OnlineNewsPopularity.csv\")\n",
    "print(\"calculating mean/median\")\n",
    "mean =  df[\" shares\"].mean()\n",
    "median = df[\" shares\"].median()\n",
    "print(\"mean: \", mean)\n",
    "print(\"median: \", median)\n",
    "[print(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[' shares'] < median, ' shares'] = 0\n",
    "df.loc[df[' shares'] >= median, ' shares'] = 1\n",
    "df = df.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13a46d2d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = ' shares', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 0:-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.680365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378636</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.913725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286915</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.393365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.495833</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.404896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.682836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411127</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39639</th>\n",
       "      <td>11.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>0.529052</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.684783</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.523121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333791</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.260000</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39640</th>\n",
       "      <td>12.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>0.696296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.885057</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>4.405488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374825</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.211111</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39641</th>\n",
       "      <td>10.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>0.516355</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.644128</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.076923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307273</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.356439</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39642</th>\n",
       "      <td>6.0</td>\n",
       "      <td>682.0</td>\n",
       "      <td>0.539493</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.692661</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.975073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236851</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.205246</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.012500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39643</th>\n",
       "      <td>10.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.471338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247338</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39644 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        n_tokens_title   n_tokens_content   n_unique_tokens  \\\n",
       "0                 12.0              219.0          0.663594   \n",
       "1                  9.0              255.0          0.604743   \n",
       "2                  9.0              211.0          0.575130   \n",
       "3                  9.0              531.0          0.503788   \n",
       "4                 13.0             1072.0          0.415646   \n",
       "...                ...                ...               ...   \n",
       "39639             11.0              346.0          0.529052   \n",
       "39640             12.0              328.0          0.696296   \n",
       "39641             10.0              442.0          0.516355   \n",
       "39642              6.0              682.0          0.539493   \n",
       "39643             10.0              157.0          0.701987   \n",
       "\n",
       "        n_non_stop_words   n_non_stop_unique_tokens   num_hrefs  \\\n",
       "0                    1.0                   0.815385         4.0   \n",
       "1                    1.0                   0.791946         3.0   \n",
       "2                    1.0                   0.663866         3.0   \n",
       "3                    1.0                   0.665635         9.0   \n",
       "4                    1.0                   0.540890        19.0   \n",
       "...                  ...                        ...         ...   \n",
       "39639                1.0                   0.684783         9.0   \n",
       "39640                1.0                   0.885057         9.0   \n",
       "39641                1.0                   0.644128        24.0   \n",
       "39642                1.0                   0.692661        10.0   \n",
       "39643                1.0                   0.846154         1.0   \n",
       "\n",
       "        num_self_hrefs   num_imgs   num_videos   average_token_length  ...  \\\n",
       "0                  2.0        1.0          0.0               4.680365  ...   \n",
       "1                  1.0        1.0          0.0               4.913725  ...   \n",
       "2                  1.0        1.0          0.0               4.393365  ...   \n",
       "3                  0.0        1.0          0.0               4.404896  ...   \n",
       "4                 19.0       20.0          0.0               4.682836  ...   \n",
       "...                ...        ...          ...                    ...  ...   \n",
       "39639              7.0        1.0          1.0               4.523121  ...   \n",
       "39640              7.0        3.0         48.0               4.405488  ...   \n",
       "39641              1.0       12.0          1.0               5.076923  ...   \n",
       "39642              1.0        1.0          0.0               4.975073  ...   \n",
       "39643              1.0        0.0          2.0               4.471338  ...   \n",
       "\n",
       "        avg_positive_polarity   min_positive_polarity   max_positive_polarity  \\\n",
       "0                    0.378636                0.100000                    0.70   \n",
       "1                    0.286915                0.033333                    0.70   \n",
       "2                    0.495833                0.100000                    1.00   \n",
       "3                    0.385965                0.136364                    0.80   \n",
       "4                    0.411127                0.033333                    1.00   \n",
       "...                       ...                     ...                     ...   \n",
       "39639                0.333791                0.100000                    0.75   \n",
       "39640                0.374825                0.136364                    0.70   \n",
       "39641                0.307273                0.136364                    0.50   \n",
       "39642                0.236851                0.062500                    0.50   \n",
       "39643                0.247338                0.100000                    0.50   \n",
       "\n",
       "        avg_negative_polarity   min_negative_polarity   max_negative_polarity  \\\n",
       "0                   -0.350000                  -0.600               -0.200000   \n",
       "1                   -0.118750                  -0.125               -0.100000   \n",
       "2                   -0.466667                  -0.800               -0.133333   \n",
       "3                   -0.369697                  -0.600               -0.166667   \n",
       "4                   -0.220192                  -0.500               -0.050000   \n",
       "...                       ...                     ...                     ...   \n",
       "39639               -0.260000                  -0.500               -0.125000   \n",
       "39640               -0.211111                  -0.400               -0.100000   \n",
       "39641               -0.356439                  -0.800               -0.166667   \n",
       "39642               -0.205246                  -0.500               -0.012500   \n",
       "39643               -0.200000                  -0.200               -0.200000   \n",
       "\n",
       "        title_subjectivity   title_sentiment_polarity  \\\n",
       "0                 0.500000                  -0.187500   \n",
       "1                 0.000000                   0.000000   \n",
       "2                 0.000000                   0.000000   \n",
       "3                 0.000000                   0.000000   \n",
       "4                 0.454545                   0.136364   \n",
       "...                    ...                        ...   \n",
       "39639             0.100000                   0.000000   \n",
       "39640             0.300000                   1.000000   \n",
       "39641             0.454545                   0.136364   \n",
       "39642             0.000000                   0.000000   \n",
       "39643             0.333333                   0.250000   \n",
       "\n",
       "        abs_title_subjectivity   abs_title_sentiment_polarity  \n",
       "0                     0.000000                       0.187500  \n",
       "1                     0.500000                       0.000000  \n",
       "2                     0.500000                       0.000000  \n",
       "3                     0.500000                       0.000000  \n",
       "4                     0.045455                       0.136364  \n",
       "...                        ...                            ...  \n",
       "39639                 0.400000                       0.000000  \n",
       "39640                 0.200000                       1.000000  \n",
       "39641                 0.045455                       0.136364  \n",
       "39642                 0.500000                       0.000000  \n",
       "39643                 0.166667                       0.250000  \n",
       "\n",
       "[39644 rows x 58 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        1\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "39639    1\n",
       "39640    1\n",
       "39641    1\n",
       "39642    0\n",
       "39643    0\n",
       "Name:  shares, Length: 39644, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "train_data = trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "## test data    \n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "test_data = testData(torch.FloatTensor(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        # Number of input features is 58.\n",
    "        self.layer_1 = nn.Linear(58, 256) \n",
    "        self.layer_2 = nn.Linear(256, 256)\n",
    "        self.layer_out = nn.Linear(256, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(256)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(256)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binaryClassification(\n",
      "  (layer_1): Linear(in_features=58, out_features=256, bias=True)\n",
      "  (layer_2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (layer_out): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = binaryClassification()\n",
    "model.to(device)\n",
    "print(model)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.63757 | Acc: 64.010\n",
      "Epoch 002: | Loss: 0.60674 | Acc: 66.885\n",
      "Epoch 003: | Loss: 0.59701 | Acc: 67.462\n",
      "Epoch 004: | Loss: 0.58944 | Acc: 68.154\n",
      "Epoch 005: | Loss: 0.58121 | Acc: 69.038\n",
      "Epoch 006: | Loss: 0.57605 | Acc: 69.452\n",
      "Epoch 007: | Loss: 0.56404 | Acc: 70.433\n",
      "Epoch 008: | Loss: 0.55749 | Acc: 70.644\n",
      "Epoch 009: | Loss: 0.54868 | Acc: 71.721\n",
      "Epoch 010: | Loss: 0.53723 | Acc: 72.413\n",
      "Epoch 011: | Loss: 0.52949 | Acc: 73.269\n",
      "Epoch 012: | Loss: 0.52144 | Acc: 73.433\n",
      "Epoch 013: | Loss: 0.50741 | Acc: 74.433\n",
      "Epoch 014: | Loss: 0.49246 | Acc: 75.654\n",
      "Epoch 015: | Loss: 0.48350 | Acc: 76.288\n",
      "Epoch 016: | Loss: 0.46815 | Acc: 77.192\n",
      "Epoch 017: | Loss: 0.45305 | Acc: 78.231\n",
      "Epoch 018: | Loss: 0.43542 | Acc: 79.365\n",
      "Epoch 019: | Loss: 0.42385 | Acc: 80.144\n",
      "Epoch 020: | Loss: 0.41265 | Acc: 80.635\n",
      "Epoch 021: | Loss: 0.40024 | Acc: 81.337\n",
      "Epoch 022: | Loss: 0.38058 | Acc: 82.635\n",
      "Epoch 023: | Loss: 0.37165 | Acc: 82.971\n",
      "Epoch 024: | Loss: 0.35237 | Acc: 84.202\n",
      "Epoch 025: | Loss: 0.34303 | Acc: 84.587\n",
      "Epoch 026: | Loss: 0.32997 | Acc: 85.404\n",
      "Epoch 027: | Loss: 0.32077 | Acc: 85.875\n",
      "Epoch 028: | Loss: 0.30290 | Acc: 86.904\n",
      "Epoch 029: | Loss: 0.29328 | Acc: 87.654\n",
      "Epoch 030: | Loss: 0.27803 | Acc: 88.202\n",
      "Epoch 031: | Loss: 0.26783 | Acc: 88.606\n",
      "Epoch 032: | Loss: 0.26194 | Acc: 88.875\n",
      "Epoch 033: | Loss: 0.25074 | Acc: 89.317\n",
      "Epoch 034: | Loss: 0.24009 | Acc: 90.087\n",
      "Epoch 035: | Loss: 0.23168 | Acc: 90.375\n",
      "Epoch 036: | Loss: 0.22304 | Acc: 90.683\n",
      "Epoch 037: | Loss: 0.21248 | Acc: 91.452\n",
      "Epoch 038: | Loss: 0.20895 | Acc: 91.163\n",
      "Epoch 039: | Loss: 0.20541 | Acc: 91.356\n",
      "Epoch 040: | Loss: 0.19141 | Acc: 92.212\n",
      "Epoch 041: | Loss: 0.19448 | Acc: 92.010\n",
      "Epoch 042: | Loss: 0.19209 | Acc: 91.981\n",
      "Epoch 043: | Loss: 0.18027 | Acc: 92.615\n",
      "Epoch 044: | Loss: 0.17071 | Acc: 93.231\n",
      "Epoch 045: | Loss: 0.16875 | Acc: 93.202\n",
      "Epoch 046: | Loss: 0.16052 | Acc: 93.625\n",
      "Epoch 047: | Loss: 0.15819 | Acc: 93.702\n",
      "Epoch 048: | Loss: 0.16007 | Acc: 93.644\n",
      "Epoch 049: | Loss: 0.15144 | Acc: 93.971\n",
      "Epoch 050: | Loss: 0.15398 | Acc: 93.808\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3531, 2476],\n",
       "       [2662, 4414]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.59      0.58      6007\n",
      "           1       0.64      0.62      0.63      7076\n",
      "\n",
      "    accuracy                           0.61     13083\n",
      "   macro avg       0.61      0.61      0.61     13083\n",
      "weighted avg       0.61      0.61      0.61     13083\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

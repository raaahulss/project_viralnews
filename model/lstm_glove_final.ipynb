{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "from datetime import datetime\n",
    "\n",
    "import spacy\n",
    "import torch\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "#from torchsampler import ImbalancedDatasetSampler\n",
    "\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "import string\n",
    "from random import randint\n",
    "from random import getrandbits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 700\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in CSV\n",
    "df = pd.read_csv(\"../data/train_80.csv\", sep=\"|\")\n",
    "df_test = pd.read_csv(\"../data/test_80.csv\", sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df['content'] = df.content.str.replace(\"[^\\w\\s]\",\"\").str.lower()\n",
    "df['content'] = df['content'].apply(lambda x: ' '.join([item for item in x.split() if item not in stop_words]))\n",
    "\n",
    "df_test['content'] = df_test.content.str.replace(\"[^\\w\\s]\",\"\").str.lower()\n",
    "df_test['content'] = df_test['content'].apply(lambda x: ' '.join([item for item in x.split() if item not in stop_words]))\n",
    "\n",
    "df['title'] = df.title.str.replace(\"[^\\w\\s]\",\"\").str.lower()\n",
    "df['title'] = df['title'].apply(lambda x: ' '.join([item for item in x.split() if item not in stop_words]))\n",
    "\n",
    "df_test['title'] = df_test.title.str.replace(\"[^\\w\\s]\",\"\").str.lower()\n",
    "df_test['title'] = df_test['title'].apply(lambda x: ' '.join([item for item in x.split() if item not in stop_words]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "436.6719497738947"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_list = list()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    content = row['content']\n",
    "    length = len(content.split())\n",
    "    len_list.append(length)\n",
    "df['content_length'] = len_list\n",
    "df['content_length'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label 0 -> gen 5 for each\n",
    "# label 1 -> skip\n",
    "# label 2 -> gen 2\n",
    "# label 3 -> gen 15\n",
    "\n",
    "def get_syn(word):\n",
    "    replacements = []\n",
    "    for syn in wn.synsets(word):\n",
    "        syn_word = syn.name().split('.')[0]\n",
    "        if syn_word != word and re.match('\\w', word):\n",
    "            replacements.append(syn_word)\n",
    "            \n",
    "    if len(replacements) > 0:\n",
    "        return replacements[randint(0, len(replacements)-1)]\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def random_insertion(sentence, alpha=0.5):\n",
    "    new_sentence = sentence.copy()\n",
    "    for i in range(int(len(sentence) * alpha)):\n",
    "        syn = get_syn(sentence[randint(0, len(sentence) - 1)])\n",
    "        if syn:\n",
    "            new_sentence.insert(randint(0, len(new_sentence)), syn)\n",
    "    return new_sentence\n",
    "\n",
    "def random_replacement(sentence, alpha=0.5):\n",
    "    new_sentence = sentence.copy()\n",
    "    for i in range(int(len(sentence) * alpha)):\n",
    "        word_id = randint(0, len(sentence) - 1)\n",
    "        syn = get_syn(sentence[word_id])\n",
    "        if syn:\n",
    "            new_sentence[word_id] = syn\n",
    "    return new_sentence\n",
    "\n",
    "def augment(dataframe):\n",
    "    df = dataframe   \n",
    "    df = df[[\"title\", \"content\", \"label_log_10\"]]\n",
    "    new_sentences_df = pd.DataFrame(columns=['title','content','label_log_10'])\n",
    "    for index, row in df.iterrows():\n",
    "        if row[\"label_log_10\"] is 0:\n",
    "            for i in range (10):\n",
    "                tmp = \" \"\n",
    "                tmp_title = \" \"\n",
    "                str_list = list(row[\"content\"].split(\" \"))\n",
    "                title_list = list(row[\"title\"].split(\" \"))\n",
    "                if bool(getrandbits(1)) is True:\n",
    "                    new_sentence = random_insertion(str_list)\n",
    "                    new_title = random_insertion(title_list)\n",
    "                else:\n",
    "                    new_sentence = random_replacement(str_list)\n",
    "                    new_title = random_replacement(title_list)\n",
    "                new_sentence = tmp.join(new_sentence)\n",
    "                new_title = tmp_title.join(new_title)\n",
    "                new_sentences_df = new_sentences_df.append(pd.DataFrame([[new_title, new_sentence, row[\"label_log_10\"]]], columns=['title','content','label_log_10']))\n",
    "            continue\n",
    "        if row[\"label_log_10\"] is 2:\n",
    "            for j in range (2):\n",
    "                tmp = \" \"\n",
    "                tmp_title = \" \"\n",
    "                str_list = list(row[\"content\"].split(\" \"))\n",
    "                title_list = list(row[\"title\"].split(\" \"))\n",
    "                if bool(getrandbits(1)) is True:\n",
    "                    new_sentence = random_insertion(str_list)\n",
    "                    new_title = random_insertion(title_list)\n",
    "                else:\n",
    "                    new_sentence = random_replacement(str_list)\n",
    "                    new_title = random_replacement(title_list)\n",
    "                new_sentence = tmp.join(new_sentence)\n",
    "                new_title = tmp_title.join(new_title)\n",
    "                new_sentences_df = new_sentences_df.append(pd.DataFrame([[new_title, new_sentence, row[\"label_log_10\"]]], columns=['title','content','label_log_10']))\n",
    "            continue\n",
    "        if row[\"label_log_10\"] is 3:\n",
    "            for k in range (30):\n",
    "                tmp = \" \"\n",
    "                tmp_title = \" \"\n",
    "                str_list = list(row[\"content\"].split(\" \"))\n",
    "                title_list = list(row[\"title\"].split(\" \"))\n",
    "                if bool(getrandbits(1)) is True:\n",
    "                    new_sentence = random_insertion(str_list)\n",
    "                    new_title = random_insertion(title_list)\n",
    "                else:\n",
    "                    new_sentence = random_replacement(str_list)\n",
    "                    new_title = random_replacement(title_list)\n",
    "                new_sentence = tmp.join(new_sentence)\n",
    "                new_title = tmp_title.join(new_title)\n",
    "                new_sentences_df = new_sentences_df.append(pd.DataFrame([[new_title, new_sentence, row[\"label_log_10\"]]], columns=['title','content','label_log_10']))\n",
    "            continue\n",
    "\n",
    "    df = df.append(new_sentences_df)\n",
    "    return df\n",
    "\n",
    "df = augment(df)\n",
    "df_test = augment(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine title and text, delete other columns\n",
    "df[\"full_text\"] = df['title'] + ' ' + df[\"content\"]\n",
    "#df[\"full_text\"] =  df[\"content\"]\n",
    "df = df[[\"full_text\", \"label_log_10\"]]\n",
    "\n",
    "df_test[\"full_text\"] = df_test['title'] + ' ' + df_test[\"content\"] \n",
    "df_test = df_test[[\"full_text\", \"label_log_10\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df\n",
    "test = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 15862, '1': 15104, '2': 17316, '3': 14229}\n",
      "{'0': 3883, '1': 3809, '2': 4275, '3': 3317}\n"
     ]
    }
   ],
   "source": [
    "def balance_classes(dataframe):\n",
    "    train = dataframe\n",
    "    count_dict = {\n",
    "        \"0\":0,\n",
    "        \"1\":0,\n",
    "        \"2\":0,\n",
    "        \"3\":0\n",
    "    }\n",
    "\n",
    "    for index, row in train.iterrows():\n",
    "        if row['label_log_10'] == 0.0:\n",
    "            count_dict[\"0\"] += 1\n",
    "        elif row['label_log_10'] == 1.0:\n",
    "            count_dict[\"1\"] += 1\n",
    "        elif row['label_log_10'] == 2.0:\n",
    "            count_dict[\"2\"] += 1\n",
    "        else:\n",
    "            count_dict[\"3\"] += 1\n",
    "\n",
    "    print(count_dict)\n",
    "\n",
    "    train_0 = train[train.label_log_10 == 0]\n",
    "    train_1 = train[train.label_log_10 == 1]\n",
    "    train_2 = train[train.label_log_10 == 2]\n",
    "    train_3 = train[train.label_log_10 == 3]\n",
    "\n",
    "    train = train_0.sample(n=count_dict[\"3\"])\n",
    "    train = train.append(train_1.sample(n=count_dict[\"3\"]))\n",
    "    train = train.append(train_2.sample(n=count_dict[\"3\"]))\n",
    "    train = train.append(train_3.sample(n=count_dict[\"3\"]))\n",
    "    train = train.sample(frac=1)\n",
    "    #print(train.shape)\n",
    "    return train\n",
    "\n",
    "train = balance_classes(train)\n",
    "test = balance_classes(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization\n",
    "tok = spacy.load('en')\n",
    "def tokenize(text):\n",
    "    text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)\n",
    "    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]')\n",
    "    nopunct = regex.sub(\" \", text.lower())\n",
    "    return [token.text for token in tok.tokenizer(nopunct)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count number of occurences of each word in train set\n",
    "counts = Counter()\n",
    "for index, row in train.iterrows():\n",
    "    counts.update(tokenize(row['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words before: 121048\n"
     ]
    }
   ],
   "source": [
    "#deleting infrequnet words\n",
    "print(\"num_words before:\", len(counts.keys()))\n",
    "#for word in list(counts):\n",
    "#    if counts[word] < 2:\n",
    "#        del counts[word]\n",
    "#print(\"num_words after:\",len(counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating vocab\n",
    "vocab2index = {\"\":0, \"UNK\":1}\n",
    "words = [\"\",\"UNK\"]\n",
    "for word in counts:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(text, vocab2index, N=450):\n",
    "    tokenized = tokenize(text)\n",
    "    encoded = np.zeros(N,dtype=int)\n",
    "    enc1 = np.array([vocab2index.get(word,vocab2index[\"UNK\"]) for word in tokenized])\n",
    "    length = min(N, len(enc1))\n",
    "    encoded[:length] = enc1[:length]\n",
    "    return encoded, length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_vectors(glove_file=\"../data/glove.6B.100d.txt\"):\n",
    "    \"\"\"Load the glove word vectors\"\"\"\n",
    "    word_vectors = {}\n",
    "    with open(glove_file, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            split = line.split()\n",
    "            word_vectors[split[0]] = np.array([float(x) for x in split[1:]])\n",
    "    return word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emb_matrix(pretrained, word_counts, emb_size = 100):\n",
    "    \"\"\" Creates embedding matrix from word vectors\"\"\"\n",
    "    vocab_size = len(word_counts) + 2\n",
    "    vocab_to_idx = {}\n",
    "    vocab = [\"\", \"UNK\"]\n",
    "    W = np.zeros((vocab_size, emb_size), dtype=\"float32\")\n",
    "    W[0] = np.zeros(emb_size, dtype='float32') # adding a vector for padding\n",
    "    W[1] = np.random.uniform(-0.25, 0.25, emb_size) # adding a vector for unknown words \n",
    "    vocab_to_idx[\"UNK\"] = 1\n",
    "    vocab_to_idx[\"\"] = 0\n",
    "    i = 2\n",
    "    for word in word_counts:\n",
    "        if word in word_vecs:\n",
    "            W[i] = word_vecs[word]\n",
    "        else:\n",
    "            W[i] = np.random.uniform(-0.25,0.25, emb_size)\n",
    "        vocab_to_idx[word] = i\n",
    "        vocab.append(word)\n",
    "        i += 1   \n",
    "    return W, np.array(vocab), vocab_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vecs = load_glove_vectors()\n",
    "pretrained_weights, vocab, vocab2index = get_emb_matrix(word_vecs, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train['encoded'] = train['full_text'].apply(lambda x: np.array(encode_sentence(x,vocab2index)))\n",
    "test['encoded'] = test['full_text'].apply(lambda x: np.array(encode_sentence(x,vocab2index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2460d1874c8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'label_log_10', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = list(train['encoded']), list(train['label_log_10'])\n",
    "X_valid, y_valid = list(test['encoded']), list(test['label_log_10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "            self.X = X\n",
    "            self.y = Y\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.X[idx][0].astype(np.int32)).to(device), self.y[idx], self.X[idx][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = NewsDataset(X_train, y_train)\n",
    "valid_ds = NewsDataset(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MY own sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5.1833,  1.0000,  2.6189, 81.3239])\n"
     ]
    }
   ],
   "source": [
    "class_0 = train[train.label_log_10 == 0].shape[0]\n",
    "class_1 = train[train.label_log_10 == 1].shape[0]\n",
    "class_2 = train[train.label_log_10 == 2].shape[0]\n",
    "class_3 = train[train.label_log_10 == 3].shape[0]\n",
    "total = class_0 + class_1 + class_2 + class_3\n",
    "weights = torch.FloatTensor([1/class_0/2, 1/class_1, 1/class_2, 2.5*(1/class_3)])  * class_1\n",
    "print(weights)\n",
    "\n",
    "weighted_sampler = WeightedRandomSampler(\n",
    "    weights = weights, \n",
    "    num_samples = len(weights),\n",
    "    replacement = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Random Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_distribution(obj):\n",
    "    count_dict = {\n",
    "        \"0\":0,\n",
    "        \"1\":0,\n",
    "        \"2\":0,\n",
    "        \"3\":0\n",
    "    }\n",
    "    \n",
    "    for i in obj:\n",
    "        if i == 0.0:\n",
    "            count_dict[\"0\"] += 1\n",
    "        elif i == 1.0:\n",
    "            count_dict[\"1\"] += 1\n",
    "        elif i == 2.0:\n",
    "            count_dict[\"2\"] += 1\n",
    "        else:\n",
    "            count_dict[\"3\"] += 1\n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = []\n",
    "\n",
    "for _, t, s in train_ds:\n",
    "    target_list.append(t)\n",
    "\n",
    "target_list = torch.tensor(target_list)\n",
    "target_list = target_list[torch.randperm(len(target_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7.8493e-04, 7.5717e-05, 1.9829e-04, 2.4631e-03])\n"
     ]
    }
   ],
   "source": [
    "class_count = [i for i in get_class_distribution(train['label_log_10']).values()]\n",
    "class_weights = 1./torch.tensor(class_count, dtype=torch.float)\n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_all = class_weights[target_list]\n",
    "\n",
    "weighted_sampler = WeightedRandomSampler(\n",
    "    weights = class_weights_all, \n",
    "    num_samples = len(class_weights_all),\n",
    "    replacement = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=LEARNING_RATE)\n",
    "    #criterion = nn.CrossEntropyLoss(weight=weights.to(device))\n",
    "    for i in range(EPOCHS):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, y, l in train_dl:\n",
    "            x = x.long().to(device)\n",
    "            y = y.long().to(device)\n",
    "            y_pred = model(x, l)\n",
    "            optimizer.zero_grad()\n",
    "            #loss = criterion(y_pred, y)\n",
    "            loss = F.cross_entropy(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item() *y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        val_loss, val_acc, val_rmse, y_pred_list = validation_metrics(model, val_dl)\n",
    "        if i%5 == 0:\n",
    "            print(\"EPOCH \", i, \": train loss %.3f, val loss %.3f, val accuracy %.3f, and val rmse %.3f\" % (sum_loss/total, val_loss, val_acc, val_rmse))\n",
    "            print(classification_report(y_valid, y_pred_list))\n",
    "def validation_metrics (model, valid_dl):\n",
    "    #criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "    y_pred_list = list()\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    sum_rmse = 0.0\n",
    "    for x, y, l in valid_dl:\n",
    "        x = x.long().to(device)\n",
    "        y = y.long()\n",
    "        y_hat = model(x, l).cpu()\n",
    "        #loss = criterion(y_hat, y)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        pred = torch.max(y_hat, 1)[1]\n",
    "        for i in pred:\n",
    "            tmp = int(i.numpy())\n",
    "            y_pred_list.append(tmp)\n",
    "        correct += (pred == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "        sum_rmse += np.sqrt(mean_squared_error(pred, y.unsqueeze(-1)))*y.shape[0]\n",
    "    return sum_loss/total, correct/total, sum_rmse/total, y_pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(words)\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dl = DataLoader(valid_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_glove_vecs(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, glove_weights) :\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.embeddings.weight.data.copy_(torch.from_numpy(glove_weights))\n",
    "        self.embeddings.weight.requires_grad = False ## freeze embeddings\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True, num_layers=2)\n",
    "        self.linear = nn.Linear(2*hidden_dim, 4)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x, l):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        lstm_out, (ht, ct) = self.lstm(x)\n",
    "        return self.linear(torch.cat((ht[-2], ht[-1]), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_variable_len(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 4)\n",
    "        \n",
    "    def forward(self, x, s):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        x_pack = pack_padded_sequence(x, s, batch_first=True, enforce_sorted=False)\n",
    "        out_pack, (ht, ct) = self.lstm(x_pack)\n",
    "        out = self.linear(ht[-1])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_glove_vecs(vocab_size, 100, 50, pretrained_weights)\n",
    "#model = LSTM_variable_len(vocab_size, 50, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full content no punc [log10 distribution]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.382, val loss 1.383, val accuracy 0.399, and val rmse 1.195\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.04      0.06       521\n",
      "           1       0.71      0.51      0.59      5706\n",
      "           2       0.26      0.19      0.22      2154\n",
      "           3       0.03      0.44      0.05       160\n",
      "\n",
      "    accuracy                           0.40      8541\n",
      "   macro avg       0.28      0.29      0.23      8541\n",
      "weighted avg       0.55      0.40      0.46      8541\n",
      "\n",
      "train loss 1.357, val loss 1.440, val accuracy 0.340, and val rmse 1.396\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.03      0.05       521\n",
      "           1       0.71      0.48      0.57      5706\n",
      "           2       0.26      0.01      0.02      2154\n",
      "           3       0.03      0.69      0.05       160\n",
      "\n",
      "    accuracy                           0.34      8541\n",
      "   macro avg       0.28      0.31      0.18      8541\n",
      "weighted avg       0.55      0.34      0.39      8541\n",
      "\n",
      "train loss 1.328, val loss 1.417, val accuracy 0.371, and val rmse 1.189\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.44      0.17       521\n",
      "           1       0.71      0.48      0.57      5706\n",
      "           2       0.32      0.05      0.09      2154\n",
      "           3       0.03      0.40      0.06       160\n",
      "\n",
      "    accuracy                           0.37      8541\n",
      "   macro avg       0.29      0.35      0.22      8541\n",
      "weighted avg       0.56      0.37      0.42      8541\n",
      "\n",
      "train loss 1.283, val loss 1.381, val accuracy 0.390, and val rmse 1.153\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.39      0.23       521\n",
      "           1       0.71      0.49      0.58      5706\n",
      "           2       0.32      0.13      0.19      2154\n",
      "           3       0.03      0.44      0.05       160\n",
      "\n",
      "    accuracy                           0.39      8541\n",
      "   macro avg       0.30      0.36      0.26      8541\n",
      "weighted avg       0.57      0.39      0.45      8541\n",
      "\n",
      "train loss 1.256, val loss 1.339, val accuracy 0.429, and val rmse 1.034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.43      0.22       521\n",
      "           1       0.71      0.50      0.59      5706\n",
      "           2       0.35      0.25      0.29      2154\n",
      "           3       0.03      0.28      0.06       160\n",
      "\n",
      "    accuracy                           0.43      8541\n",
      "   macro avg       0.31      0.36      0.29      8541\n",
      "weighted avg       0.57      0.43      0.48      8541\n",
      "\n",
      "train loss 1.289, val loss 1.361, val accuracy 0.426, and val rmse 1.081\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.28      0.23       521\n",
      "           1       0.71      0.50      0.58      5706\n",
      "           2       0.32      0.28      0.30      2154\n",
      "           3       0.03      0.36      0.05       160\n",
      "\n",
      "    accuracy                           0.43      8541\n",
      "   macro avg       0.31      0.35      0.29      8541\n",
      "weighted avg       0.57      0.43      0.48      8541\n",
      "\n",
      "train loss 1.254, val loss 1.346, val accuracy 0.429, and val rmse 1.057\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.36      0.22       521\n",
      "           1       0.71      0.51      0.59      5706\n",
      "           2       0.33      0.25      0.29      2154\n",
      "           3       0.03      0.30      0.05       160\n",
      "\n",
      "    accuracy                           0.43      8541\n",
      "   macro avg       0.31      0.35      0.29      8541\n",
      "weighted avg       0.57      0.43      0.48      8541\n",
      "\n",
      "train loss 1.213, val loss 1.353, val accuracy 0.423, and val rmse 1.043\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.42      0.22       521\n",
      "           1       0.71      0.49      0.58      5706\n",
      "           2       0.33      0.26      0.29      2154\n",
      "           3       0.03      0.26      0.05       160\n",
      "\n",
      "    accuracy                           0.42      8541\n",
      "   macro avg       0.30      0.36      0.29      8541\n",
      "weighted avg       0.57      0.42      0.47      8541\n",
      "\n",
      "train loss 1.216, val loss 1.374, val accuracy 0.361, and val rmse 1.076\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.61      0.23       521\n",
      "           1       0.69      0.37      0.48      5706\n",
      "           2       0.33      0.28      0.30      2154\n",
      "           3       0.03      0.31      0.06       160\n",
      "\n",
      "    accuracy                           0.36      8541\n",
      "   macro avg       0.30      0.39      0.27      8541\n",
      "weighted avg       0.55      0.36      0.41      8541\n",
      "\n",
      "train loss 1.205, val loss 1.348, val accuracy 0.332, and val rmse 1.086\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.70      0.21       521\n",
      "           1       0.68      0.33      0.44      5706\n",
      "           2       0.34      0.25      0.29      2154\n",
      "           3       0.04      0.29      0.07       160\n",
      "\n",
      "    accuracy                           0.33      8541\n",
      "   macro avg       0.30      0.39      0.25      8541\n",
      "weighted avg       0.55      0.33      0.38      8541\n",
      "\n",
      "train loss 1.185, val loss 1.324, val accuracy 0.384, and val rmse 1.033\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.56      0.24       521\n",
      "           1       0.69      0.39      0.50      5706\n",
      "           2       0.32      0.33      0.33      2154\n",
      "           3       0.03      0.27      0.06       160\n",
      "\n",
      "    accuracy                           0.38      8541\n",
      "   macro avg       0.30      0.39      0.28      8541\n",
      "weighted avg       0.55      0.38      0.43      8541\n",
      "\n",
      "train loss 1.179, val loss 1.330, val accuracy 0.233, and val rmse 1.103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.64      0.21       521\n",
      "           1       0.72      0.03      0.07      5706\n",
      "           2       0.31      0.66      0.42      2154\n",
      "           3       0.04      0.23      0.07       160\n",
      "\n",
      "    accuracy                           0.23      8541\n",
      "   macro avg       0.30      0.39      0.19      8541\n",
      "weighted avg       0.57      0.23      0.16      8541\n",
      "\n",
      "train loss 1.160, val loss 1.311, val accuracy 0.251, and val rmse 1.079\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.57      0.24       521\n",
      "           1       0.70      0.05      0.10      5706\n",
      "           2       0.30      0.70      0.42      2154\n",
      "           3       0.04      0.23      0.06       160\n",
      "\n",
      "    accuracy                           0.25      8541\n",
      "   macro avg       0.30      0.39      0.20      8541\n",
      "weighted avg       0.55      0.25      0.19      8541\n",
      "\n",
      "train loss 1.159, val loss 1.318, val accuracy 0.428, and val rmse 0.982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.51      0.24       521\n",
      "           1       0.70      0.47      0.56      5706\n",
      "           2       0.34      0.31      0.32      2154\n",
      "           3       0.03      0.22      0.06       160\n",
      "\n",
      "    accuracy                           0.43      8541\n",
      "   macro avg       0.31      0.38      0.30      8541\n",
      "weighted avg       0.56      0.43      0.47      8541\n",
      "\n",
      "train loss 1.144, val loss 1.297, val accuracy 0.175, and val rmse 1.414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.55      0.24       521\n",
      "           1       0.72      0.09      0.16      5706\n",
      "           2       0.33      0.28      0.30      2154\n",
      "           3       0.02      0.51      0.04       160\n",
      "\n",
      "    accuracy                           0.17      8541\n",
      "   macro avg       0.30      0.36      0.19      8541\n",
      "weighted avg       0.57      0.17      0.20      8541\n",
      "\n",
      "train loss 1.144, val loss 1.375, val accuracy 0.134, and val rmse 1.365\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.83      0.17       521\n",
      "           1       0.69      0.04      0.08      5706\n",
      "           2       0.36      0.19      0.25      2154\n",
      "           3       0.02      0.36      0.04       160\n",
      "\n",
      "    accuracy                           0.13      8541\n",
      "   macro avg       0.29      0.36      0.14      8541\n",
      "weighted avg       0.56      0.13      0.13      8541\n",
      "\n",
      "train loss 1.128, val loss 1.321, val accuracy 0.162, and val rmse 1.446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.45      0.23       521\n",
      "           1       0.72      0.07      0.12      5706\n",
      "           2       0.32      0.32      0.32      2154\n",
      "           3       0.02      0.48      0.03       160\n",
      "\n",
      "    accuracy                           0.16      8541\n",
      "   macro avg       0.30      0.33      0.18      8541\n",
      "weighted avg       0.57      0.16      0.18      8541\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.114, val loss 1.302, val accuracy 0.253, and val rmse 1.060\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.59      0.23       521\n",
      "           1       0.73      0.05      0.10      5706\n",
      "           2       0.30      0.71      0.42      2154\n",
      "           3       0.03      0.18      0.06       160\n",
      "\n",
      "    accuracy                           0.25      8541\n",
      "   macro avg       0.30      0.38      0.20      8541\n",
      "weighted avg       0.57      0.25      0.19      8541\n",
      "\n",
      "train loss 1.113, val loss 1.273, val accuracy 0.273, and val rmse 1.045\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.51      0.25       521\n",
      "           1       0.72      0.08      0.14      5706\n",
      "           2       0.29      0.74      0.42      2154\n",
      "           3       0.03      0.17      0.05       160\n",
      "\n",
      "    accuracy                           0.27      8541\n",
      "   macro avg       0.30      0.38      0.22      8541\n",
      "weighted avg       0.57      0.27      0.22      8541\n",
      "\n",
      "train loss 1.118, val loss 1.260, val accuracy 0.268, and val rmse 1.037\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.62      0.24       521\n",
      "           1       0.71      0.08      0.14      5706\n",
      "           2       0.30      0.70      0.42      2154\n",
      "           3       0.04      0.17      0.06       160\n",
      "\n",
      "    accuracy                           0.27      8541\n",
      "   macro avg       0.30      0.39      0.21      8541\n",
      "weighted avg       0.56      0.27      0.21      8541\n",
      "\n",
      "train loss 1.096, val loss 1.316, val accuracy 0.250, and val rmse 1.057\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.66      0.23       521\n",
      "           1       0.68      0.05      0.10      5706\n",
      "           2       0.31      0.68      0.42      2154\n",
      "           3       0.03      0.17      0.06       160\n",
      "\n",
      "    accuracy                           0.25      8541\n",
      "   macro avg       0.29      0.39      0.20      8541\n",
      "weighted avg       0.54      0.25      0.19      8541\n",
      "\n",
      "train loss 1.145, val loss 1.207, val accuracy 0.371, and val rmse 0.945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.18      0.22       521\n",
      "           1       0.75      0.25      0.37      5706\n",
      "           2       0.29      0.75      0.42      2154\n",
      "           3       0.04      0.16      0.06       160\n",
      "\n",
      "    accuracy                           0.37      8541\n",
      "   macro avg       0.34      0.34      0.27      8541\n",
      "weighted avg       0.59      0.37      0.37      8541\n",
      "\n",
      "train loss 1.123, val loss 1.343, val accuracy 0.229, and val rmse 1.105\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.67      0.21       521\n",
      "           1       0.70      0.05      0.09      5706\n",
      "           2       0.30      0.61      0.40      2154\n",
      "           3       0.03      0.19      0.05       160\n",
      "\n",
      "    accuracy                           0.23      8541\n",
      "   macro avg       0.29      0.38      0.19      8541\n",
      "weighted avg       0.55      0.23      0.17      8541\n",
      "\n",
      "train loss 1.078, val loss 1.308, val accuracy 0.241, and val rmse 1.081\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.74      0.19       521\n",
      "           1       0.68      0.08      0.14      5706\n",
      "           2       0.32      0.56      0.41      2154\n",
      "           3       0.04      0.14      0.06       160\n",
      "\n",
      "    accuracy                           0.24      8541\n",
      "   macro avg       0.29      0.38      0.20      8541\n",
      "weighted avg       0.54      0.24      0.21      8541\n",
      "\n",
      "train loss 1.096, val loss 1.285, val accuracy 0.250, and val rmse 1.073\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.67      0.19       521\n",
      "           1       0.70      0.08      0.15      5706\n",
      "           2       0.32      0.59      0.42      2154\n",
      "           3       0.04      0.17      0.06       160\n",
      "\n",
      "    accuracy                           0.25      8541\n",
      "   macro avg       0.29      0.38      0.21      8541\n",
      "weighted avg       0.55      0.25      0.22      8541\n",
      "\n",
      "train loss 1.082, val loss 1.302, val accuracy 0.258, and val rmse 1.062\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.60      0.22       521\n",
      "           1       0.71      0.07      0.14      5706\n",
      "           2       0.30      0.67      0.42      2154\n",
      "           3       0.03      0.18      0.06       160\n",
      "\n",
      "    accuracy                           0.26      8541\n",
      "   macro avg       0.29      0.38      0.21      8541\n",
      "weighted avg       0.56      0.26      0.21      8541\n",
      "\n",
      "train loss 1.085, val loss 1.277, val accuracy 0.274, and val rmse 1.034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.54      0.23       521\n",
      "           1       0.73      0.08      0.15      5706\n",
      "           2       0.30      0.73      0.43      2154\n",
      "           3       0.03      0.16      0.06       160\n",
      "\n",
      "    accuracy                           0.27      8541\n",
      "   macro avg       0.30      0.38      0.21      8541\n",
      "weighted avg       0.58      0.27      0.22      8541\n",
      "\n",
      "train loss 1.099, val loss 1.289, val accuracy 0.243, and val rmse 1.099\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.78      0.16       521\n",
      "           1       0.67      0.15      0.24      5706\n",
      "           2       0.34      0.38      0.36      2154\n",
      "           3       0.05      0.11      0.07       160\n",
      "\n",
      "    accuracy                           0.24      8541\n",
      "   macro avg       0.29      0.35      0.21      8541\n",
      "weighted avg       0.54      0.24      0.26      8541\n",
      "\n",
      "train loss 1.075, val loss 1.289, val accuracy 0.257, and val rmse 1.076\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.59      0.19       521\n",
      "           1       0.72      0.09      0.17      5706\n",
      "           2       0.32      0.61      0.42      2154\n",
      "           3       0.04      0.21      0.06       160\n",
      "\n",
      "    accuracy                           0.26      8541\n",
      "   macro avg       0.30      0.38      0.21      8541\n",
      "weighted avg       0.57      0.26      0.23      8541\n",
      "\n",
      "train loss 1.054, val loss 1.273, val accuracy 0.268, and val rmse 1.043\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.64      0.20       521\n",
      "           1       0.69      0.10      0.18      5706\n",
      "           2       0.32      0.62      0.42      2154\n",
      "           3       0.04      0.16      0.07       160\n",
      "\n",
      "    accuracy                           0.27      8541\n",
      "   macro avg       0.29      0.38      0.22      8541\n",
      "weighted avg       0.55      0.27      0.24      8541\n",
      "\n",
      "train loss 1.048, val loss 1.272, val accuracy 0.279, and val rmse 1.044\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.61      0.22       521\n",
      "           1       0.71      0.12      0.20      5706\n",
      "           2       0.31      0.63      0.41      2154\n",
      "           3       0.04      0.21      0.06       160\n",
      "\n",
      "    accuracy                           0.28      8541\n",
      "   macro avg       0.30      0.39      0.23      8541\n",
      "weighted avg       0.56      0.28      0.25      8541\n",
      "\n",
      "train loss 1.043, val loss 1.264, val accuracy 0.277, and val rmse 1.018\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.60      0.23       521\n",
      "           1       0.73      0.08      0.15      5706\n",
      "           2       0.31      0.72      0.43      2154\n",
      "           3       0.04      0.17      0.07       160\n",
      "\n",
      "    accuracy                           0.28      8541\n",
      "   macro avg       0.31      0.39      0.22      8541\n",
      "weighted avg       0.57      0.28      0.22      8541\n",
      "\n",
      "train loss 1.033, val loss 1.297, val accuracy 0.274, and val rmse 1.048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.66      0.23       521\n",
      "           1       0.70      0.11      0.18      5706\n",
      "           2       0.31      0.63      0.42      2154\n",
      "           3       0.04      0.19      0.06       160\n",
      "\n",
      "    accuracy                           0.27      8541\n",
      "   macro avg       0.30      0.40      0.22      8541\n",
      "weighted avg       0.56      0.27      0.24      8541\n",
      "\n",
      "train loss 1.010, val loss 1.280, val accuracy 0.282, and val rmse 1.026\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.64      0.22       521\n",
      "           1       0.71      0.11      0.19      5706\n",
      "           2       0.32      0.66      0.43      2154\n",
      "           3       0.04      0.17      0.06       160\n",
      "\n",
      "    accuracy                           0.28      8541\n",
      "   macro avg       0.30      0.40      0.23      8541\n",
      "weighted avg       0.57      0.28      0.25      8541\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.026, val loss 1.287, val accuracy 0.276, and val rmse 1.051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.64      0.22       521\n",
      "           1       0.71      0.11      0.20      5706\n",
      "           2       0.32      0.62      0.42      2154\n",
      "           3       0.04      0.23      0.07       160\n",
      "\n",
      "    accuracy                           0.28      8541\n",
      "   macro avg       0.30      0.40      0.23      8541\n",
      "weighted avg       0.56      0.28      0.25      8541\n",
      "\n",
      "train loss 1.025, val loss 1.296, val accuracy 0.278, and val rmse 1.043\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.64      0.23       521\n",
      "           1       0.72      0.12      0.20      5706\n",
      "           2       0.31      0.62      0.42      2154\n",
      "           3       0.04      0.22      0.07       160\n",
      "\n",
      "    accuracy                           0.28      8541\n",
      "   macro avg       0.30      0.40      0.23      8541\n",
      "weighted avg       0.57      0.28      0.25      8541\n",
      "\n",
      "train loss 1.015, val loss 1.245, val accuracy 0.293, and val rmse 1.010\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.58      0.21       521\n",
      "           1       0.72      0.13      0.22      5706\n",
      "           2       0.31      0.66      0.42      2154\n",
      "           3       0.05      0.16      0.07       160\n",
      "\n",
      "    accuracy                           0.29      8541\n",
      "   macro avg       0.30      0.38      0.23      8541\n",
      "weighted avg       0.57      0.29      0.27      8541\n",
      "\n",
      "train loss 1.021, val loss 1.319, val accuracy 0.258, and val rmse 1.071\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.67      0.20       521\n",
      "           1       0.72      0.09      0.17      5706\n",
      "           2       0.33      0.60      0.42      2154\n",
      "           3       0.04      0.21      0.07       160\n",
      "\n",
      "    accuracy                           0.26      8541\n",
      "   macro avg       0.30      0.39      0.21      8541\n",
      "weighted avg       0.57      0.26      0.23      8541\n",
      "\n",
      "train loss 1.030, val loss 1.285, val accuracy 0.287, and val rmse 1.034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.63      0.22       521\n",
      "           1       0.71      0.14      0.24      5706\n",
      "           2       0.31      0.60      0.40      2154\n",
      "           3       0.05      0.23      0.08       160\n",
      "\n",
      "    accuracy                           0.29      8541\n",
      "   macro avg       0.30      0.40      0.24      8541\n",
      "weighted avg       0.56      0.29      0.27      8541\n",
      "\n",
      "train loss 1.148, val loss 1.234, val accuracy 0.434, and val rmse 0.896\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.33      0.20       521\n",
      "           1       0.72      0.41      0.52      5706\n",
      "           2       0.32      0.54      0.40      2154\n",
      "           3       0.05      0.13      0.07       160\n",
      "\n",
      "    accuracy                           0.43      8541\n",
      "   macro avg       0.31      0.35      0.30      8541\n",
      "weighted avg       0.57      0.43      0.46      8541\n",
      "\n",
      "train loss 1.115, val loss 1.304, val accuracy 0.238, and val rmse 1.095\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.69      0.19       521\n",
      "           1       0.67      0.07      0.13      5706\n",
      "           2       0.31      0.58      0.40      2154\n",
      "           3       0.04      0.17      0.06       160\n",
      "\n",
      "    accuracy                           0.24      8541\n",
      "   macro avg       0.28      0.38      0.20      8541\n",
      "weighted avg       0.54      0.24      0.20      8541\n",
      "\n",
      "train loss 1.122, val loss 1.279, val accuracy 0.238, and val rmse 1.098\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.73      0.18       521\n",
      "           1       0.67      0.09      0.17      5706\n",
      "           2       0.32      0.51      0.40      2154\n",
      "           3       0.04      0.14      0.06       160\n",
      "\n",
      "    accuracy                           0.24      8541\n",
      "   macro avg       0.28      0.37      0.20      8541\n",
      "weighted avg       0.54      0.24      0.22      8541\n",
      "\n",
      "train loss 1.060, val loss 1.297, val accuracy 0.253, and val rmse 1.091\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.63      0.20       521\n",
      "           1       0.69      0.09      0.16      5706\n",
      "           2       0.31      0.59      0.41      2154\n",
      "           3       0.04      0.22      0.07       160\n",
      "\n",
      "    accuracy                           0.25      8541\n",
      "   macro avg       0.29      0.38      0.21      8541\n",
      "weighted avg       0.55      0.25      0.22      8541\n",
      "\n",
      "train loss 1.044, val loss 1.276, val accuracy 0.264, and val rmse 1.062\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.66      0.21       521\n",
      "           1       0.68      0.11      0.19      5706\n",
      "           2       0.31      0.59      0.40      2154\n",
      "           3       0.04      0.18      0.06       160\n",
      "\n",
      "    accuracy                           0.26      8541\n",
      "   macro avg       0.29      0.38      0.22      8541\n",
      "weighted avg       0.54      0.26      0.24      8541\n",
      "\n",
      "train loss 1.042, val loss 1.259, val accuracy 0.272, and val rmse 1.048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.65      0.20       521\n",
      "           1       0.68      0.13      0.22      5706\n",
      "           2       0.31      0.56      0.40      2154\n",
      "           3       0.05      0.17      0.07       160\n",
      "\n",
      "    accuracy                           0.27      8541\n",
      "   macro avg       0.29      0.38      0.22      8541\n",
      "weighted avg       0.54      0.27      0.26      8541\n",
      "\n",
      "train loss 1.027, val loss 1.279, val accuracy 0.284, and val rmse 1.042\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.66      0.21       521\n",
      "           1       0.68      0.15      0.24      5706\n",
      "           2       0.31      0.56      0.40      2154\n",
      "           3       0.04      0.20      0.07       160\n",
      "\n",
      "    accuracy                           0.28      8541\n",
      "   macro avg       0.29      0.39      0.23      8541\n",
      "weighted avg       0.54      0.28      0.28      8541\n",
      "\n",
      "train loss 1.029, val loss 1.266, val accuracy 0.286, and val rmse 1.014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.61      0.22       521\n",
      "           1       0.71      0.12      0.20      5706\n",
      "           2       0.31      0.67      0.43      2154\n",
      "           3       0.04      0.16      0.07       160\n",
      "\n",
      "    accuracy                           0.29      8541\n",
      "   macro avg       0.30      0.39      0.23      8541\n",
      "weighted avg       0.56      0.29      0.26      8541\n",
      "\n",
      "train loss 1.011, val loss 1.262, val accuracy 0.289, and val rmse 1.016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.61      0.23       521\n",
      "           1       0.70      0.12      0.21      5706\n",
      "           2       0.31      0.66      0.42      2154\n",
      "           3       0.04      0.19      0.07       160\n",
      "\n",
      "    accuracy                           0.29      8541\n",
      "   macro avg       0.30      0.40      0.23      8541\n",
      "weighted avg       0.56      0.29      0.26      8541\n",
      "\n",
      "train loss 1.108, val loss 1.245, val accuracy 0.517, and val rmse 0.896\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.22      0.18       521\n",
      "           1       0.70      0.65      0.68      5706\n",
      "           2       0.33      0.26      0.29      2154\n",
      "           3       0.04      0.20      0.07       160\n",
      "\n",
      "    accuracy                           0.52      8541\n",
      "   macro avg       0.31      0.33      0.30      8541\n",
      "weighted avg       0.56      0.52      0.54      8541\n",
      "\n",
      "train loss 1.074, val loss 1.273, val accuracy 0.505, and val rmse 0.875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.32      0.21       521\n",
      "           1       0.71      0.60      0.65      5706\n",
      "           2       0.32      0.31      0.32      2154\n",
      "           3       0.05      0.17      0.08       160\n",
      "\n",
      "    accuracy                           0.50      8541\n",
      "   macro avg       0.31      0.35      0.31      8541\n",
      "weighted avg       0.56      0.50      0.53      8541\n",
      "\n",
      "train loss 1.037, val loss 1.275, val accuracy 0.509, and val rmse 0.876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.34      0.21       521\n",
      "           1       0.71      0.63      0.66      5706\n",
      "           2       0.33      0.27      0.30      2154\n",
      "           3       0.05      0.17      0.07       160\n",
      "\n",
      "    accuracy                           0.51      8541\n",
      "   macro avg       0.31      0.35      0.31      8541\n",
      "weighted avg       0.57      0.51      0.53      8541\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.041, val loss 1.333, val accuracy 0.185, and val rmse 1.493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.32      0.21       521\n",
      "           1       0.69      0.12      0.21      5706\n",
      "           2       0.33      0.29      0.31      2154\n",
      "           3       0.02      0.48      0.03       160\n",
      "\n",
      "    accuracy                           0.18      8541\n",
      "   macro avg       0.30      0.30      0.19      8541\n",
      "weighted avg       0.56      0.18      0.23      8541\n",
      "\n",
      "train loss 1.037, val loss 1.266, val accuracy 0.509, and val rmse 0.869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.36      0.21       521\n",
      "           1       0.70      0.62      0.66      5706\n",
      "           2       0.35      0.27      0.30      2154\n",
      "           3       0.05      0.17      0.08       160\n",
      "\n",
      "    accuracy                           0.51      8541\n",
      "   macro avg       0.31      0.36      0.31      8541\n",
      "weighted avg       0.57      0.51      0.53      8541\n",
      "\n",
      "train loss 1.048, val loss 1.290, val accuracy 0.506, and val rmse 0.869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.34      0.23       521\n",
      "           1       0.71      0.60      0.65      5706\n",
      "           2       0.34      0.32      0.33      2154\n",
      "           3       0.05      0.18      0.08       160\n",
      "\n",
      "    accuracy                           0.51      8541\n",
      "   macro avg       0.31      0.36      0.32      8541\n",
      "weighted avg       0.57      0.51      0.53      8541\n",
      "\n",
      "train loss 1.024, val loss 1.278, val accuracy 0.515, and val rmse 0.863\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.34      0.23       521\n",
      "           1       0.71      0.62      0.66      5706\n",
      "           2       0.34      0.30      0.32      2154\n",
      "           3       0.05      0.19      0.08       160\n",
      "\n",
      "    accuracy                           0.52      8541\n",
      "   macro avg       0.32      0.36      0.32      8541\n",
      "weighted avg       0.57      0.52      0.54      8541\n",
      "\n",
      "train loss 1.022, val loss 1.268, val accuracy 0.517, and val rmse 0.846\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.34      0.22       521\n",
      "           1       0.70      0.62      0.66      5706\n",
      "           2       0.35      0.32      0.33      2154\n",
      "           3       0.05      0.17      0.08       160\n",
      "\n",
      "    accuracy                           0.52      8541\n",
      "   macro avg       0.32      0.36      0.32      8541\n",
      "weighted avg       0.57      0.52      0.54      8541\n",
      "\n",
      "train loss 1.023, val loss 1.276, val accuracy 0.515, and val rmse 0.845\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.34      0.24       521\n",
      "           1       0.71      0.60      0.65      5706\n",
      "           2       0.34      0.35      0.34      2154\n",
      "           3       0.05      0.16      0.07       160\n",
      "\n",
      "    accuracy                           0.52      8541\n",
      "   macro avg       0.32      0.36      0.33      8541\n",
      "weighted avg       0.57      0.52      0.54      8541\n",
      "\n",
      "train loss 0.988, val loss 1.321, val accuracy 0.439, and val rmse 0.907\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.54      0.23       521\n",
      "           1       0.69      0.47      0.56      5706\n",
      "           2       0.35      0.35      0.35      2154\n",
      "           3       0.05      0.17      0.08       160\n",
      "\n",
      "    accuracy                           0.44      8541\n",
      "   macro avg       0.31      0.38      0.30      8541\n",
      "weighted avg       0.56      0.44      0.48      8541\n",
      "\n",
      "train loss 0.969, val loss 1.269, val accuracy 0.233, and val rmse 1.300\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.56      0.21       521\n",
      "           1       0.72      0.17      0.28      5706\n",
      "           2       0.35      0.30      0.32      2154\n",
      "           3       0.02      0.46      0.04       160\n",
      "\n",
      "    accuracy                           0.23      8541\n",
      "   macro avg       0.31      0.37      0.22      8541\n",
      "weighted avg       0.58      0.23      0.28      8541\n",
      "\n",
      "train loss 1.171, val loss 1.293, val accuracy 0.255, and val rmse 1.040\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.21      0.21       521\n",
      "           1       0.72      0.04      0.08      5706\n",
      "           2       0.26      0.83      0.39      2154\n",
      "           3       0.04      0.19      0.07       160\n",
      "\n",
      "    accuracy                           0.26      8541\n",
      "   macro avg       0.30      0.32      0.19      8541\n",
      "weighted avg       0.56      0.26      0.17      8541\n",
      "\n",
      "train loss 1.055, val loss 1.217, val accuracy 0.531, and val rmse 0.859\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.37      0.22       521\n",
      "           1       0.69      0.70      0.69      5706\n",
      "           2       0.33      0.16      0.21      2154\n",
      "           3       0.05      0.16      0.07       160\n",
      "\n",
      "    accuracy                           0.53      8541\n",
      "   macro avg       0.31      0.35      0.30      8541\n",
      "weighted avg       0.56      0.53      0.53      8541\n",
      "\n",
      "train loss 1.025, val loss 1.283, val accuracy 0.474, and val rmse 0.910\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.35      0.22       521\n",
      "           1       0.71      0.55      0.62      5706\n",
      "           2       0.31      0.34      0.32      2154\n",
      "           3       0.04      0.17      0.06       160\n",
      "\n",
      "    accuracy                           0.47      8541\n",
      "   macro avg       0.31      0.35      0.31      8541\n",
      "weighted avg       0.56      0.47      0.51      8541\n",
      "\n",
      "train loss 1.014, val loss 1.277, val accuracy 0.481, and val rmse 0.896\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.45      0.24       521\n",
      "           1       0.70      0.56      0.62      5706\n",
      "           2       0.33      0.30      0.31      2154\n",
      "           3       0.04      0.16      0.06       160\n",
      "\n",
      "    accuracy                           0.48      8541\n",
      "   macro avg       0.31      0.37      0.31      8541\n",
      "weighted avg       0.56      0.48      0.51      8541\n",
      "\n",
      "train loss 0.991, val loss 1.277, val accuracy 0.474, and val rmse 0.897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.47      0.24       521\n",
      "           1       0.70      0.54      0.61      5706\n",
      "           2       0.33      0.31      0.32      2154\n",
      "           3       0.04      0.16      0.07       160\n",
      "\n",
      "    accuracy                           0.47      8541\n",
      "   macro avg       0.31      0.37      0.31      8541\n",
      "weighted avg       0.56      0.47      0.51      8541\n",
      "\n",
      "train loss 1.004, val loss 1.264, val accuracy 0.461, and val rmse 0.915\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.53      0.24       521\n",
      "           1       0.70      0.53      0.60      5706\n",
      "           2       0.34      0.29      0.31      2154\n",
      "           3       0.04      0.17      0.07       160\n",
      "\n",
      "    accuracy                           0.46      8541\n",
      "   macro avg       0.31      0.38      0.31      8541\n",
      "weighted avg       0.56      0.46      0.50      8541\n",
      "\n",
      "train loss 1.007, val loss 1.280, val accuracy 0.448, and val rmse 0.918\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.54      0.24       521\n",
      "           1       0.70      0.49      0.58      5706\n",
      "           2       0.34      0.32      0.33      2154\n",
      "           3       0.04      0.16      0.06       160\n",
      "\n",
      "    accuracy                           0.45      8541\n",
      "   macro avg       0.31      0.38      0.30      8541\n",
      "weighted avg       0.56      0.45      0.49      8541\n",
      "\n",
      "train loss 0.948, val loss 1.254, val accuracy 0.306, and val rmse 0.989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.55      0.24       521\n",
      "           1       0.70      0.15      0.24      5706\n",
      "           2       0.29      0.69      0.41      2154\n",
      "           3       0.05      0.15      0.07       160\n",
      "\n",
      "    accuracy                           0.31      8541\n",
      "   macro avg       0.30      0.38      0.24      8541\n",
      "weighted avg       0.55      0.31      0.28      8541\n",
      "\n",
      "train loss 0.948, val loss 1.259, val accuracy 0.301, and val rmse 0.992\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.51      0.25       521\n",
      "           1       0.70      0.14      0.23      5706\n",
      "           2       0.29      0.70      0.41      2154\n",
      "           3       0.04      0.14      0.06       160\n",
      "\n",
      "    accuracy                           0.30      8541\n",
      "   macro avg       0.30      0.37      0.24      8541\n",
      "weighted avg       0.55      0.30      0.27      8541\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.934, val loss 1.247, val accuracy 0.309, and val rmse 0.983\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.51      0.25       521\n",
      "           1       0.71      0.15      0.24      5706\n",
      "           2       0.29      0.70      0.41      2154\n",
      "           3       0.05      0.16      0.07       160\n",
      "\n",
      "    accuracy                           0.31      8541\n",
      "   macro avg       0.30      0.38      0.24      8541\n",
      "weighted avg       0.56      0.31      0.28      8541\n",
      "\n",
      "train loss 0.943, val loss 1.246, val accuracy 0.317, and val rmse 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.47      0.25       521\n",
      "           1       0.70      0.16      0.26      5706\n",
      "           2       0.29      0.70      0.41      2154\n",
      "           3       0.04      0.16      0.07       160\n",
      "\n",
      "    accuracy                           0.32      8541\n",
      "   macro avg       0.30      0.37      0.25      8541\n",
      "weighted avg       0.55      0.32      0.30      8541\n",
      "\n",
      "train loss 0.953, val loss 1.253, val accuracy 0.307, and val rmse 0.991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.50      0.25       521\n",
      "           1       0.71      0.14      0.24      5706\n",
      "           2       0.29      0.70      0.41      2154\n",
      "           3       0.04      0.15      0.06       160\n",
      "\n",
      "    accuracy                           0.31      8541\n",
      "   macro avg       0.30      0.37      0.24      8541\n",
      "weighted avg       0.56      0.31      0.28      8541\n",
      "\n",
      "train loss 0.937, val loss 1.254, val accuracy 0.306, and val rmse 0.984\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.52      0.24       521\n",
      "           1       0.70      0.14      0.24      5706\n",
      "           2       0.30      0.70      0.42      2154\n",
      "           3       0.04      0.14      0.06       160\n",
      "\n",
      "    accuracy                           0.31      8541\n",
      "   macro avg       0.30      0.38      0.24      8541\n",
      "weighted avg       0.56      0.31      0.28      8541\n",
      "\n",
      "train loss 0.940, val loss 1.241, val accuracy 0.315, and val rmse 0.974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.51      0.23       521\n",
      "           1       0.71      0.15      0.25      5706\n",
      "           2       0.30      0.71      0.42      2154\n",
      "           3       0.04      0.14      0.07       160\n",
      "\n",
      "    accuracy                           0.31      8541\n",
      "   macro avg       0.30      0.38      0.24      8541\n",
      "weighted avg       0.56      0.31      0.29      8541\n",
      "\n",
      "train loss 0.935, val loss 1.248, val accuracy 0.311, and val rmse 0.980\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.58      0.23       521\n",
      "           1       0.69      0.16      0.26      5706\n",
      "           2       0.31      0.66      0.42      2154\n",
      "           3       0.06      0.17      0.08       160\n",
      "\n",
      "    accuracy                           0.31      8541\n",
      "   macro avg       0.30      0.39      0.25      8541\n",
      "weighted avg       0.55      0.31      0.30      8541\n",
      "\n",
      "train loss 0.954, val loss 1.262, val accuracy 0.313, and val rmse 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.51      0.24       521\n",
      "           1       0.72      0.15      0.25      5706\n",
      "           2       0.30      0.71      0.42      2154\n",
      "           3       0.04      0.16      0.07       160\n",
      "\n",
      "    accuracy                           0.31      8541\n",
      "   macro avg       0.31      0.38      0.24      8541\n",
      "weighted avg       0.57      0.31      0.29      8541\n",
      "\n",
      "train loss 0.930, val loss 1.247, val accuracy 0.316, and val rmse 0.972\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.55      0.23       521\n",
      "           1       0.70      0.17      0.27      5706\n",
      "           2       0.31      0.67      0.42      2154\n",
      "           3       0.05      0.14      0.07       160\n",
      "\n",
      "    accuracy                           0.32      8541\n",
      "   macro avg       0.30      0.38      0.25      8541\n",
      "weighted avg       0.56      0.32      0.30      8541\n",
      "\n",
      "train loss 0.916, val loss 1.257, val accuracy 0.313, and val rmse 0.974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.52      0.23       521\n",
      "           1       0.71      0.15      0.25      5706\n",
      "           2       0.30      0.70      0.42      2154\n",
      "           3       0.05      0.17      0.08       160\n",
      "\n",
      "    accuracy                           0.31      8541\n",
      "   macro avg       0.30      0.39      0.25      8541\n",
      "weighted avg       0.56      0.31      0.29      8541\n",
      "\n",
      "train loss 0.930, val loss 1.247, val accuracy 0.312, and val rmse 0.979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.54      0.23       521\n",
      "           1       0.71      0.15      0.25      5706\n",
      "           2       0.31      0.69      0.42      2154\n",
      "           3       0.05      0.16      0.07       160\n",
      "\n",
      "    accuracy                           0.31      8541\n",
      "   macro avg       0.30      0.39      0.25      8541\n",
      "weighted avg       0.56      0.31      0.29      8541\n",
      "\n",
      "train loss 0.905, val loss 1.270, val accuracy 0.313, and val rmse 0.981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.49      0.24       521\n",
      "           1       0.71      0.16      0.26      5706\n",
      "           2       0.30      0.69      0.42      2154\n",
      "           3       0.05      0.18      0.08       160\n",
      "\n",
      "    accuracy                           0.31      8541\n",
      "   macro avg       0.30      0.38      0.25      8541\n",
      "weighted avg       0.56      0.31      0.29      8541\n",
      "\n",
      "train loss 0.928, val loss 1.234, val accuracy 0.322, and val rmse 0.960\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.51      0.23       521\n",
      "           1       0.72      0.16      0.27      5706\n",
      "           2       0.30      0.71      0.42      2154\n",
      "           3       0.05      0.14      0.07       160\n",
      "\n",
      "    accuracy                           0.32      8541\n",
      "   macro avg       0.31      0.38      0.25      8541\n",
      "weighted avg       0.57      0.32      0.30      8541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM, hidden_dim=50 GloVe embeddings emb_size=50, no stop words (train only), N=800, weighted random sampler, (batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.357, val loss 1.436, val accuracy 0.041, and val rmse 1.780\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.19      0.15       521\n",
      "           1       0.60      0.01      0.02      5706\n",
      "           2       0.26      0.02      0.04      2154\n",
      "           3       0.02      0.86      0.04       160\n",
      "\n",
      "    accuracy                           0.04      8541\n",
      "   macro avg       0.25      0.27      0.06      8541\n",
      "weighted avg       0.47      0.04      0.04      8541\n",
      "\n",
      "train loss 1.292, val loss 1.377, val accuracy 0.241, and val rmse 1.039\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.28      0.19       521\n",
      "           1       0.65      0.03      0.06      5706\n",
      "           2       0.25      0.80      0.39      2154\n",
      "           3       0.03      0.09      0.04       160\n",
      "\n",
      "    accuracy                           0.24      8541\n",
      "   macro avg       0.27      0.30      0.17      8541\n",
      "weighted avg       0.51      0.24      0.15      8541\n",
      "\n",
      "train loss 1.288, val loss 1.435, val accuracy 0.519, and val rmse 0.886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.32      0.15       521\n",
      "           1       0.69      0.71      0.70      5706\n",
      "           2       0.33      0.09      0.14      2154\n",
      "           3       0.02      0.04      0.03       160\n",
      "\n",
      "    accuracy                           0.52      8541\n",
      "   macro avg       0.28      0.29      0.25      8541\n",
      "weighted avg       0.55      0.52      0.51      8541\n",
      "\n",
      "train loss 1.279, val loss 1.354, val accuracy 0.551, and val rmse 0.807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.18      0.16       521\n",
      "           1       0.69      0.73      0.71      5706\n",
      "           2       0.31      0.21      0.25      2154\n",
      "           3       0.03      0.08      0.05       160\n",
      "\n",
      "    accuracy                           0.55      8541\n",
      "   macro avg       0.29      0.30      0.29      8541\n",
      "weighted avg       0.55      0.55      0.55      8541\n",
      "\n",
      "train loss 1.245, val loss 1.355, val accuracy 0.560, and val rmse 0.799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.13      0.14       521\n",
      "           1       0.69      0.74      0.71      5706\n",
      "           2       0.31      0.21      0.25      2154\n",
      "           3       0.03      0.09      0.05       160\n",
      "\n",
      "    accuracy                           0.56      8541\n",
      "   macro avg       0.29      0.29      0.29      8541\n",
      "weighted avg       0.55      0.56      0.55      8541\n",
      "\n",
      "train loss 1.234, val loss 1.416, val accuracy 0.553, and val rmse 0.800\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.19      0.15       521\n",
      "           1       0.69      0.74      0.71      5706\n",
      "           2       0.32      0.19      0.24      2154\n",
      "           3       0.03      0.05      0.04       160\n",
      "\n",
      "    accuracy                           0.55      8541\n",
      "   macro avg       0.29      0.29      0.28      8541\n",
      "weighted avg       0.55      0.55      0.54      8541\n",
      "\n",
      "train loss 1.230, val loss 1.370, val accuracy 0.550, and val rmse 0.824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.10      0.13       521\n",
      "           1       0.68      0.74      0.71      5706\n",
      "           2       0.27      0.18      0.22      2154\n",
      "           3       0.05      0.17      0.07       160\n",
      "\n",
      "    accuracy                           0.55      8541\n",
      "   macro avg       0.29      0.30      0.28      8541\n",
      "weighted avg       0.54      0.55      0.54      8541\n",
      "\n",
      "train loss 1.220, val loss 1.363, val accuracy 0.572, and val rmse 0.739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.14      0.15       521\n",
      "           1       0.68      0.76      0.72      5706\n",
      "           2       0.30      0.23      0.26      2154\n",
      "           3       0.02      0.01      0.02       160\n",
      "\n",
      "    accuracy                           0.57      8541\n",
      "   macro avg       0.29      0.28      0.28      8541\n",
      "weighted avg       0.54      0.57      0.55      8541\n",
      "\n",
      "train loss 1.214, val loss 1.438, val accuracy 0.554, and val rmse 0.791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.23      0.21       521\n",
      "           1       0.69      0.72      0.70      5706\n",
      "           2       0.30      0.23      0.26      2154\n",
      "           3       0.03      0.06      0.04       160\n",
      "\n",
      "    accuracy                           0.55      8541\n",
      "   macro avg       0.30      0.31      0.30      8541\n",
      "weighted avg       0.55      0.55      0.55      8541\n",
      "\n",
      "train loss 1.180, val loss 1.299, val accuracy 0.304, and val rmse 0.949\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.11      0.15       521\n",
      "           1       0.63      0.15      0.24      5706\n",
      "           2       0.25      0.78      0.38      2154\n",
      "           3       0.03      0.04      0.03       160\n",
      "\n",
      "    accuracy                           0.30      8541\n",
      "   macro avg       0.29      0.27      0.20      8541\n",
      "weighted avg       0.50      0.30      0.27      8541\n",
      "\n",
      "train loss 1.157, val loss 1.324, val accuracy 0.309, and val rmse 0.966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.26      0.22       521\n",
      "           1       0.64      0.17      0.27      5706\n",
      "           2       0.25      0.70      0.37      2154\n",
      "           3       0.03      0.07      0.04       160\n",
      "\n",
      "    accuracy                           0.31      8541\n",
      "   macro avg       0.28      0.30      0.23      8541\n",
      "weighted avg       0.50      0.31      0.29      8541\n",
      "\n",
      "train loss 1.145, val loss 1.378, val accuracy 0.299, and val rmse 0.960\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.17      0.19       521\n",
      "           1       0.62      0.14      0.23      5706\n",
      "           2       0.25      0.77      0.38      2154\n",
      "           3       0.03      0.04      0.03       160\n",
      "\n",
      "    accuracy                           0.30      8541\n",
      "   macro avg       0.28      0.28      0.21      8541\n",
      "weighted avg       0.49      0.30      0.26      8541\n",
      "\n",
      "train loss 1.136, val loss 1.522, val accuracy 0.284, and val rmse 0.974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.19      0.21       521\n",
      "           1       0.62      0.10      0.17      5706\n",
      "           2       0.25      0.81      0.39      2154\n",
      "           3       0.03      0.06      0.04       160\n",
      "\n",
      "    accuracy                           0.28      8541\n",
      "   macro avg       0.29      0.29      0.20      8541\n",
      "weighted avg       0.50      0.28      0.23      8541\n",
      "\n",
      "train loss 1.121, val loss 1.380, val accuracy 0.315, and val rmse 0.963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.15      0.18       521\n",
      "           1       0.64      0.18      0.28      5706\n",
      "           2       0.25      0.73      0.37      2154\n",
      "           3       0.03      0.06      0.04       160\n",
      "\n",
      "    accuracy                           0.31      8541\n",
      "   macro avg       0.29      0.28      0.22      8541\n",
      "weighted avg       0.51      0.31      0.29      8541\n",
      "\n",
      "train loss 1.143, val loss 1.487, val accuracy 0.169, and val rmse 1.532\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.18      0.21       521\n",
      "           1       0.63      0.12      0.21      5706\n",
      "           2       0.29      0.27      0.28      2154\n",
      "           3       0.02      0.49      0.03       160\n",
      "\n",
      "    accuracy                           0.17      8541\n",
      "   macro avg       0.30      0.26      0.18      8541\n",
      "weighted avg       0.51      0.17      0.22      8541\n",
      "\n",
      "train loss 1.123, val loss 1.434, val accuracy 0.303, and val rmse 0.963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.27      0.21       521\n",
      "           1       0.64      0.14      0.23      5706\n",
      "           2       0.26      0.75      0.39      2154\n",
      "           3       0.03      0.06      0.04       160\n",
      "\n",
      "    accuracy                           0.30      8541\n",
      "   macro avg       0.28      0.31      0.22      8541\n",
      "weighted avg       0.51      0.30      0.27      8541\n",
      "\n",
      "train loss 1.120, val loss 1.395, val accuracy 0.311, and val rmse 0.964\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.18      0.19       521\n",
      "           1       0.64      0.17      0.27      5706\n",
      "           2       0.26      0.73      0.38      2154\n",
      "           3       0.04      0.09      0.05       160\n",
      "\n",
      "    accuracy                           0.31      8541\n",
      "   macro avg       0.28      0.30      0.22      8541\n",
      "weighted avg       0.51      0.31      0.29      8541\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.118, val loss 1.450, val accuracy 0.292, and val rmse 1.013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.31      0.17       521\n",
      "           1       0.63      0.18      0.28      5706\n",
      "           2       0.26      0.61      0.36      2154\n",
      "           3       0.03      0.09      0.04       160\n",
      "\n",
      "    accuracy                           0.29      8541\n",
      "   macro avg       0.26      0.30      0.21      8541\n",
      "weighted avg       0.49      0.29      0.29      8541\n",
      "\n",
      "train loss 1.120, val loss 1.480, val accuracy 0.296, and val rmse 1.014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.21      0.20       521\n",
      "           1       0.63      0.16      0.25      5706\n",
      "           2       0.26      0.70      0.38      2154\n",
      "           3       0.03      0.11      0.04       160\n",
      "\n",
      "    accuracy                           0.30      8541\n",
      "   macro avg       0.28      0.30      0.22      8541\n",
      "weighted avg       0.50      0.30      0.28      8541\n",
      "\n",
      "train loss 1.122, val loss 1.408, val accuracy 0.310, and val rmse 0.967\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.16      0.18       521\n",
      "           1       0.64      0.17      0.27      5706\n",
      "           2       0.25      0.73      0.38      2154\n",
      "           3       0.04      0.11      0.06       160\n",
      "\n",
      "    accuracy                           0.31      8541\n",
      "   macro avg       0.28      0.29      0.22      8541\n",
      "weighted avg       0.50      0.31      0.29      8541\n",
      "\n",
      "train loss 1.139, val loss 1.446, val accuracy 0.305, and val rmse 0.953\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.21      0.19       521\n",
      "           1       0.65      0.15      0.24      5706\n",
      "           2       0.26      0.77      0.39      2154\n",
      "           3       0.02      0.03      0.03       160\n",
      "\n",
      "    accuracy                           0.30      8541\n",
      "   macro avg       0.28      0.29      0.21      8541\n",
      "weighted avg       0.51      0.30      0.27      8541\n",
      "\n",
      "train loss 1.158, val loss 1.524, val accuracy 0.279, and val rmse 1.006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.26      0.17       521\n",
      "           1       0.64      0.12      0.20      5706\n",
      "           2       0.26      0.73      0.38      2154\n",
      "           3       0.03      0.07      0.04       160\n",
      "\n",
      "    accuracy                           0.28      8541\n",
      "   macro avg       0.26      0.29      0.20      8541\n",
      "weighted avg       0.50      0.28      0.24      8541\n",
      "\n",
      "train loss 1.131, val loss 1.540, val accuracy 0.285, and val rmse 1.002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.16      0.16       521\n",
      "           1       0.66      0.12      0.20      5706\n",
      "           2       0.25      0.76      0.38      2154\n",
      "           3       0.03      0.11      0.05       160\n",
      "\n",
      "    accuracy                           0.29      8541\n",
      "   macro avg       0.28      0.29      0.20      8541\n",
      "weighted avg       0.51      0.29      0.24      8541\n",
      "\n",
      "train loss 1.136, val loss 1.488, val accuracy 0.285, and val rmse 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.18      0.16       521\n",
      "           1       0.63      0.11      0.19      5706\n",
      "           2       0.26      0.78      0.39      2154\n",
      "           3       0.04      0.09      0.05       160\n",
      "\n",
      "    accuracy                           0.28      8541\n",
      "   macro avg       0.27      0.29      0.20      8541\n",
      "weighted avg       0.49      0.28      0.24      8541\n",
      "\n",
      "train loss 1.125, val loss 1.521, val accuracy 0.299, and val rmse 0.964\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.17      0.16       521\n",
      "           1       0.63      0.15      0.24      5706\n",
      "           2       0.25      0.75      0.38      2154\n",
      "           3       0.03      0.05      0.04       160\n",
      "\n",
      "    accuracy                           0.30      8541\n",
      "   macro avg       0.27      0.28      0.20      8541\n",
      "weighted avg       0.49      0.30      0.27      8541\n",
      "\n",
      "train loss 1.102, val loss 1.472, val accuracy 0.314, and val rmse 0.984\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.12      0.15       521\n",
      "           1       0.64      0.18      0.29      5706\n",
      "           2       0.26      0.72      0.38      2154\n",
      "           3       0.03      0.10      0.05       160\n",
      "\n",
      "    accuracy                           0.31      8541\n",
      "   macro avg       0.28      0.28      0.21      8541\n",
      "weighted avg       0.50      0.31      0.30      8541\n",
      "\n",
      "train loss 1.315, val loss 1.367, val accuracy 0.145, and val rmse 1.599\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.14      0.10       521\n",
      "           1       0.64      0.13      0.22      5706\n",
      "           2       0.28      0.15      0.19      2154\n",
      "           3       0.01      0.46      0.03       160\n",
      "\n",
      "    accuracy                           0.14      8541\n",
      "   macro avg       0.25      0.22      0.14      8541\n",
      "weighted avg       0.50      0.14      0.20      8541\n",
      "\n",
      "train loss 1.195, val loss 1.416, val accuracy 0.282, and val rmse 0.998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.43      0.18       521\n",
      "           1       0.62      0.14      0.23      5706\n",
      "           2       0.27      0.63      0.38      2154\n",
      "           3       0.04      0.05      0.04       160\n",
      "\n",
      "    accuracy                           0.28      8541\n",
      "   macro avg       0.26      0.31      0.21      8541\n",
      "weighted avg       0.49      0.28      0.26      8541\n",
      "\n",
      "train loss 1.136, val loss 1.406, val accuracy 0.308, and val rmse 0.957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.36      0.20       521\n",
      "           1       0.64      0.17      0.27      5706\n",
      "           2       0.27      0.69      0.39      2154\n",
      "           3       0.04      0.04      0.04       160\n",
      "\n",
      "    accuracy                           0.31      8541\n",
      "   macro avg       0.27      0.31      0.22      8541\n",
      "weighted avg       0.50      0.31      0.29      8541\n",
      "\n",
      "train loss 1.111, val loss 1.479, val accuracy 0.308, and val rmse 0.946\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.26      0.21       521\n",
      "           1       0.62      0.15      0.24      5706\n",
      "           2       0.26      0.76      0.39      2154\n",
      "           3       0.02      0.03      0.03       160\n",
      "\n",
      "    accuracy                           0.31      8541\n",
      "   macro avg       0.27      0.30      0.22      8541\n",
      "weighted avg       0.50      0.31      0.27      8541\n",
      "\n",
      "train loss 1.102, val loss 1.479, val accuracy 0.306, and val rmse 0.957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.31      0.23       521\n",
      "           1       0.63      0.15      0.24      5706\n",
      "           2       0.26      0.75      0.39      2154\n",
      "           3       0.02      0.04      0.03       160\n",
      "\n",
      "    accuracy                           0.31      8541\n",
      "   macro avg       0.28      0.31      0.22      8541\n",
      "weighted avg       0.50      0.31      0.27      8541\n",
      "\n",
      "train loss 1.119, val loss 1.411, val accuracy 0.310, and val rmse 0.966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.32      0.20       521\n",
      "           1       0.63      0.18      0.28      5706\n",
      "           2       0.26      0.67      0.38      2154\n",
      "           3       0.03      0.06      0.04       160\n",
      "\n",
      "    accuracy                           0.31      8541\n",
      "   macro avg       0.27      0.31      0.23      8541\n",
      "weighted avg       0.50      0.31      0.29      8541\n",
      "\n",
      "train loss 1.156, val loss 1.452, val accuracy 0.294, and val rmse 0.988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.35      0.21       521\n",
      "           1       0.63      0.14      0.23      5706\n",
      "           2       0.26      0.69      0.38      2154\n",
      "           3       0.04      0.07      0.05       160\n",
      "\n",
      "    accuracy                           0.29      8541\n",
      "   macro avg       0.27      0.31      0.22      8541\n",
      "weighted avg       0.50      0.29      0.27      8541\n",
      "\n",
      "train loss 1.134, val loss 1.491, val accuracy 0.530, and val rmse 0.845\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.25      0.21       521\n",
      "           1       0.69      0.68      0.68      5706\n",
      "           2       0.29      0.23      0.26      2154\n",
      "           3       0.03      0.10      0.05       160\n",
      "\n",
      "    accuracy                           0.53      8541\n",
      "   macro avg       0.30      0.31      0.30      8541\n",
      "weighted avg       0.54      0.53      0.54      8541\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.147, val loss 1.423, val accuracy 0.592, and val rmse 0.741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.10      0.13       521\n",
      "           1       0.68      0.81      0.74      5706\n",
      "           2       0.31      0.18      0.23      2154\n",
      "           3       0.05      0.07      0.06       160\n",
      "\n",
      "    accuracy                           0.59      8541\n",
      "   macro avg       0.30      0.29      0.29      8541\n",
      "weighted avg       0.55      0.59      0.56      8541\n",
      "\n",
      "train loss 1.183, val loss 1.489, val accuracy 0.563, and val rmse 0.784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.08      0.12       521\n",
      "           1       0.68      0.75      0.71      5706\n",
      "           2       0.29      0.23      0.25      2154\n",
      "           3       0.02      0.04      0.03       160\n",
      "\n",
      "    accuracy                           0.56      8541\n",
      "   macro avg       0.30      0.28      0.28      8541\n",
      "weighted avg       0.54      0.56      0.55      8541\n",
      "\n",
      "train loss 1.174, val loss 1.464, val accuracy 0.313, and val rmse 0.934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.14      0.18       521\n",
      "           1       0.62      0.16      0.26      5706\n",
      "           2       0.25      0.77      0.38      2154\n",
      "           3       0.04      0.04      0.04       160\n",
      "\n",
      "    accuracy                           0.31      8541\n",
      "   macro avg       0.29      0.28      0.21      8541\n",
      "weighted avg       0.49      0.31      0.28      8541\n",
      "\n",
      "train loss 1.078, val loss 1.482, val accuracy 0.308, and val rmse 0.954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.28      0.21       521\n",
      "           1       0.63      0.17      0.26      5706\n",
      "           2       0.26      0.71      0.38      2154\n",
      "           3       0.04      0.08      0.06       160\n",
      "\n",
      "    accuracy                           0.31      8541\n",
      "   macro avg       0.28      0.31      0.23      8541\n",
      "weighted avg       0.50      0.31      0.28      8541\n",
      "\n",
      "train loss 1.139, val loss 1.423, val accuracy 0.319, and val rmse 0.929\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.24      0.22       521\n",
      "           1       0.64      0.17      0.27      5706\n",
      "           2       0.26      0.76      0.39      2154\n",
      "           3       0.03      0.03      0.03       160\n",
      "\n",
      "    accuracy                           0.32      8541\n",
      "   macro avg       0.28      0.30      0.22      8541\n",
      "weighted avg       0.50      0.32      0.29      8541\n",
      "\n",
      "train loss 1.106, val loss 1.413, val accuracy 0.312, and val rmse 0.940\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.23      0.21       521\n",
      "           1       0.62      0.16      0.25      5706\n",
      "           2       0.26      0.76      0.38      2154\n",
      "           3       0.03      0.03      0.03       160\n",
      "\n",
      "    accuracy                           0.31      8541\n",
      "   macro avg       0.28      0.29      0.22      8541\n",
      "weighted avg       0.49      0.31      0.28      8541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM, hidden_dim=50 GloVe embeddings emb_size=50, no stop words (train + test), N=800, weighted random sampler, (batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  1 : train loss 1.364, val loss 1.357, val accuracy 0.621, and val rmse 0.707\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.15      0.13       521\n",
      "           1       0.68      0.90      0.77      5706\n",
      "           2       0.36      0.05      0.09      2154\n",
      "           3       0.00      0.00      0.00       160\n",
      "\n",
      "    accuracy                           0.62      8541\n",
      "   macro avg       0.29      0.27      0.25      8541\n",
      "weighted avg       0.55      0.62      0.55      8541\n",
      "\n",
      "EPOCH  6 : train loss 1.299, val loss 1.314, val accuracy 0.634, and val rmse 0.681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.12      0.14       521\n",
      "           1       0.68      0.92      0.78      5706\n",
      "           2       0.36      0.06      0.10      2154\n",
      "           3       0.04      0.02      0.02       160\n",
      "\n",
      "    accuracy                           0.63      8541\n",
      "   macro avg       0.31      0.28      0.26      8541\n",
      "weighted avg       0.55      0.63      0.55      8541\n",
      "\n",
      "EPOCH  11 : train loss 1.287, val loss 1.377, val accuracy 0.257, and val rmse 0.974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.10      0.13       521\n",
      "           1       0.64      0.02      0.04      5706\n",
      "           2       0.25      0.93      0.40      2154\n",
      "           3       0.03      0.03      0.03       160\n",
      "\n",
      "    accuracy                           0.26      8541\n",
      "   macro avg       0.28      0.27      0.15      8541\n",
      "weighted avg       0.50      0.26      0.14      8541\n",
      "\n",
      "EPOCH  16 : train loss 1.267, val loss 1.323, val accuracy 0.650, and val rmse 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.07      0.10       521\n",
      "           1       0.68      0.94      0.79      5706\n",
      "           2       0.41      0.07      0.12      2154\n",
      "           3       0.04      0.02      0.03       160\n",
      "\n",
      "    accuracy                           0.65      8541\n",
      "   macro avg       0.33      0.27      0.26      8541\n",
      "weighted avg       0.57      0.65      0.56      8541\n",
      "\n",
      "EPOCH  21 : train loss 1.263, val loss 1.342, val accuracy 0.647, and val rmse 0.659\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.09      0.12       521\n",
      "           1       0.68      0.94      0.79      5706\n",
      "           2       0.41      0.06      0.11      2154\n",
      "           3       0.06      0.03      0.03       160\n",
      "\n",
      "    accuracy                           0.65      8541\n",
      "   macro avg       0.33      0.28      0.26      8541\n",
      "weighted avg       0.57      0.65      0.56      8541\n",
      "\n",
      "EPOCH  26 : train loss 1.249, val loss 1.342, val accuracy 0.651, and val rmse 0.652\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.10      0.14       521\n",
      "           1       0.68      0.94      0.79      5706\n",
      "           2       0.43      0.06      0.10      2154\n",
      "           3       0.04      0.02      0.03       160\n",
      "\n",
      "    accuracy                           0.65      8541\n",
      "   macro avg       0.34      0.28      0.26      8541\n",
      "weighted avg       0.58      0.65      0.56      8541\n",
      "\n",
      "EPOCH  31 : train loss 1.260, val loss 1.378, val accuracy 0.270, and val rmse 0.958\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.10      0.12       521\n",
      "           1       0.66      0.05      0.09      5706\n",
      "           2       0.26      0.92      0.40      2154\n",
      "           3       0.04      0.03      0.03       160\n",
      "\n",
      "    accuracy                           0.27      8541\n",
      "   macro avg       0.29      0.27      0.16      8541\n",
      "weighted avg       0.52      0.27      0.17      8541\n",
      "\n",
      "EPOCH  36 : train loss 1.246, val loss 1.351, val accuracy 0.646, and val rmse 0.662\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.08      0.12       521\n",
      "           1       0.68      0.93      0.79      5706\n",
      "           2       0.38      0.07      0.12      2154\n",
      "           3       0.04      0.03      0.04       160\n",
      "\n",
      "    accuracy                           0.65      8541\n",
      "   macro avg       0.33      0.28      0.27      8541\n",
      "weighted avg       0.56      0.65      0.56      8541\n",
      "\n",
      "EPOCH  41 : train loss 1.230, val loss 1.332, val accuracy 0.653, and val rmse 0.650\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.08      0.12       521\n",
      "           1       0.68      0.94      0.79      5706\n",
      "           2       0.42      0.07      0.12      2154\n",
      "           3       0.08      0.04      0.05       160\n",
      "\n",
      "    accuracy                           0.65      8541\n",
      "   macro avg       0.35      0.28      0.27      8541\n",
      "weighted avg       0.57      0.65      0.57      8541\n",
      "\n",
      "EPOCH  46 : train loss 1.235, val loss 1.339, val accuracy 0.279, and val rmse 0.946\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.08      0.12       521\n",
      "           1       0.70      0.06      0.11      5706\n",
      "           2       0.26      0.93      0.40      2154\n",
      "           3       0.08      0.03      0.04       160\n",
      "\n",
      "    accuracy                           0.28      8541\n",
      "   macro avg       0.32      0.27      0.17      8541\n",
      "weighted avg       0.55      0.28      0.18      8541\n",
      "\n",
      "EPOCH  51 : train loss 1.379, val loss 1.340, val accuracy 0.262, and val rmse 0.968\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.06      0.08       521\n",
      "           1       0.62      0.04      0.07      5706\n",
      "           2       0.25      0.92      0.40      2154\n",
      "           3       0.03      0.01      0.02       160\n",
      "\n",
      "    accuracy                           0.26      8541\n",
      "   macro avg       0.26      0.26      0.14      8541\n",
      "weighted avg       0.49      0.26      0.15      8541\n",
      "\n",
      "EPOCH  56 : train loss 1.267, val loss 1.390, val accuracy 0.070, and val rmse 1.774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.09      0.12       521\n",
      "           1       0.67      0.05      0.09      5706\n",
      "           2       0.43      0.06      0.11      2154\n",
      "           3       0.02      0.84      0.03       160\n",
      "\n",
      "    accuracy                           0.07      8541\n",
      "   macro avg       0.33      0.26      0.09      8541\n",
      "weighted avg       0.57      0.07      0.10      8541\n",
      "\n",
      "EPOCH  61 : train loss 1.240, val loss 1.274, val accuracy 0.654, and val rmse 0.646\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.07      0.10       521\n",
      "           1       0.68      0.95      0.79      5706\n",
      "           2       0.41      0.07      0.12      2154\n",
      "           3       0.07      0.03      0.04       160\n",
      "\n",
      "    accuracy                           0.65      8541\n",
      "   macro avg       0.35      0.28      0.26      8541\n",
      "weighted avg       0.57      0.65      0.57      8541\n",
      "\n",
      "EPOCH  66 : train loss 1.242, val loss 1.343, val accuracy 0.650, and val rmse 0.657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.09      0.12       521\n",
      "           1       0.68      0.94      0.79      5706\n",
      "           2       0.41      0.06      0.11      2154\n",
      "           3       0.06      0.04      0.05       160\n",
      "\n",
      "    accuracy                           0.65      8541\n",
      "   macro avg       0.34      0.28      0.27      8541\n",
      "weighted avg       0.57      0.65      0.56      8541\n",
      "\n",
      "EPOCH  71 : train loss 1.250, val loss 1.297, val accuracy 0.647, and val rmse 0.664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.09      0.13       521\n",
      "           1       0.68      0.93      0.79      5706\n",
      "           2       0.38      0.06      0.11      2154\n",
      "           3       0.05      0.04      0.04       160\n",
      "\n",
      "    accuracy                           0.65      8541\n",
      "   macro avg       0.34      0.28      0.27      8541\n",
      "weighted avg       0.56      0.65      0.56      8541\n",
      "\n",
      "EPOCH  76 : train loss 1.239, val loss 1.336, val accuracy 0.274, and val rmse 0.956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.08      0.12       521\n",
      "           1       0.68      0.05      0.10      5706\n",
      "           2       0.25      0.92      0.40      2154\n",
      "           3       0.06      0.04      0.05       160\n",
      "\n",
      "    accuracy                           0.27      8541\n",
      "   macro avg       0.31      0.28      0.17      8541\n",
      "weighted avg       0.53      0.27      0.17      8541\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  81 : train loss 1.238, val loss 1.353, val accuracy 0.652, and val rmse 0.655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.07      0.11       521\n",
      "           1       0.68      0.94      0.79      5706\n",
      "           2       0.41      0.06      0.11      2154\n",
      "           3       0.06      0.04      0.05       160\n",
      "\n",
      "    accuracy                           0.65      8541\n",
      "   macro avg       0.35      0.28      0.27      8541\n",
      "weighted avg       0.57      0.65      0.56      8541\n",
      "\n",
      "EPOCH  86 : train loss 1.233, val loss 1.356, val accuracy 0.653, and val rmse 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.06      0.10       521\n",
      "           1       0.68      0.94      0.79      5706\n",
      "           2       0.39      0.07      0.13      2154\n",
      "           3       0.05      0.03      0.04       160\n",
      "\n",
      "    accuracy                           0.65      8541\n",
      "   macro avg       0.35      0.28      0.26      8541\n",
      "weighted avg       0.57      0.65      0.57      8541\n",
      "\n",
      "EPOCH  91 : train loss 1.229, val loss 1.361, val accuracy 0.073, and val rmse 1.771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.08      0.13       521\n",
      "           1       0.67      0.06      0.10      5706\n",
      "           2       0.41      0.06      0.11      2154\n",
      "           3       0.02      0.83      0.03       160\n",
      "\n",
      "    accuracy                           0.07      8541\n",
      "   macro avg       0.34      0.26      0.09      8541\n",
      "weighted avg       0.57      0.07      0.10      8541\n",
      "\n",
      "EPOCH  96 : train loss 1.247, val loss 1.300, val accuracy 0.651, and val rmse 0.658\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.07      0.11       521\n",
      "           1       0.68      0.94      0.79      5706\n",
      "           2       0.41      0.06      0.11      2154\n",
      "           3       0.05      0.04      0.04       160\n",
      "\n",
      "    accuracy                           0.65      8541\n",
      "   macro avg       0.35      0.28      0.26      8541\n",
      "weighted avg       0.57      0.65      0.56      8541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM (num_layers=1), hidden_dim=50 GloVe embeddings emb_size=50, no stop words (train + test), N=800, own sampler, (batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0 : train loss 1.307, val loss 1.216, val accuracy 0.408, and val rmse 1.112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.31      0.25       521\n",
      "           1       0.79      0.42      0.54      5706\n",
      "           2       0.36      0.41      0.38      2154\n",
      "           3       0.03      0.46      0.06       160\n",
      "\n",
      "    accuracy                           0.41      8541\n",
      "   macro avg       0.35      0.40      0.31      8541\n",
      "weighted avg       0.63      0.41      0.48      8541\n",
      "\n",
      "EPOCH  5 : train loss 1.128, val loss 1.098, val accuracy 0.465, and val rmse 1.025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.31      0.27       521\n",
      "           1       0.80      0.50      0.62      5706\n",
      "           2       0.38      0.40      0.39      2154\n",
      "           3       0.04      0.50      0.07       160\n",
      "\n",
      "    accuracy                           0.47      8541\n",
      "   macro avg       0.37      0.43      0.34      8541\n",
      "weighted avg       0.64      0.47      0.53      8541\n",
      "\n",
      "EPOCH  10 : train loss 1.073, val loss 1.108, val accuracy 0.456, and val rmse 1.030\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.28      0.29       521\n",
      "           1       0.80      0.48      0.60      5706\n",
      "           2       0.36      0.42      0.39      2154\n",
      "           3       0.04      0.49      0.07       160\n",
      "\n",
      "    accuracy                           0.46      8541\n",
      "   macro avg       0.37      0.42      0.34      8541\n",
      "weighted avg       0.64      0.46      0.52      8541\n",
      "\n",
      "EPOCH  15 : train loss 1.010, val loss 1.087, val accuracy 0.467, and val rmse 0.985\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.41      0.29       521\n",
      "           1       0.80      0.49      0.61      5706\n",
      "           2       0.39      0.42      0.40      2154\n",
      "           3       0.04      0.46      0.07       160\n",
      "\n",
      "    accuracy                           0.47      8541\n",
      "   macro avg       0.37      0.44      0.35      8541\n",
      "weighted avg       0.65      0.47      0.53      8541\n",
      "\n",
      "EPOCH  20 : train loss 0.952, val loss 1.080, val accuracy 0.462, and val rmse 0.971\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.46      0.31       521\n",
      "           1       0.81      0.48      0.60      5706\n",
      "           2       0.38      0.42      0.40      2154\n",
      "           3       0.04      0.45      0.08       160\n",
      "\n",
      "    accuracy                           0.46      8541\n",
      "   macro avg       0.37      0.45      0.35      8541\n",
      "weighted avg       0.65      0.46      0.52      8541\n",
      "\n",
      "EPOCH  25 : train loss 0.892, val loss 1.024, val accuracy 0.506, and val rmse 0.883\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.27      0.29       521\n",
      "           1       0.83      0.49      0.62      5706\n",
      "           2       0.37      0.62      0.46      2154\n",
      "           3       0.05      0.34      0.09       160\n",
      "\n",
      "    accuracy                           0.51      8541\n",
      "   macro avg       0.39      0.43      0.36      8541\n",
      "weighted avg       0.67      0.51      0.55      8541\n",
      "\n",
      "EPOCH  30 : train loss 0.817, val loss 1.037, val accuracy 0.517, and val rmse 0.894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.46      0.34       521\n",
      "           1       0.82      0.55      0.66      5706\n",
      "           2       0.41      0.45      0.43      2154\n",
      "           3       0.05      0.45      0.09       160\n",
      "\n",
      "    accuracy                           0.52      8541\n",
      "   macro avg       0.38      0.48      0.38      8541\n",
      "weighted avg       0.66      0.52      0.57      8541\n",
      "\n",
      "EPOCH  35 : train loss 0.816, val loss 1.085, val accuracy 0.477, and val rmse 0.905\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.57      0.30       521\n",
      "           1       0.81      0.47      0.59      5706\n",
      "           2       0.40      0.49      0.44      2154\n",
      "           3       0.05      0.38      0.09       160\n",
      "\n",
      "    accuracy                           0.48      8541\n",
      "   macro avg       0.37      0.48      0.36      8541\n",
      "weighted avg       0.66      0.48      0.53      8541\n",
      "\n",
      "EPOCH  40 : train loss 0.768, val loss 1.059, val accuracy 0.506, and val rmse 0.885\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.51      0.34       521\n",
      "           1       0.81      0.51      0.63      5706\n",
      "           2       0.40      0.49      0.44      2154\n",
      "           3       0.05      0.40      0.09       160\n",
      "\n",
      "    accuracy                           0.51      8541\n",
      "   macro avg       0.38      0.48      0.38      8541\n",
      "weighted avg       0.66      0.51      0.55      8541\n",
      "\n",
      "EPOCH  45 : train loss 0.736, val loss 1.010, val accuracy 0.520, and val rmse 0.813\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.50      0.36       521\n",
      "           1       0.83      0.49      0.61      5706\n",
      "           2       0.39      0.63      0.48      2154\n",
      "           3       0.06      0.27      0.10       160\n",
      "\n",
      "    accuracy                           0.52      8541\n",
      "   macro avg       0.39      0.47      0.39      8541\n",
      "weighted avg       0.67      0.52      0.55      8541\n",
      "\n",
      "EPOCH  50 : train loss 0.710, val loss 1.015, val accuracy 0.534, and val rmse 0.823\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.60      0.33       521\n",
      "           1       0.80      0.56      0.66      5706\n",
      "           2       0.43      0.48      0.45      2154\n",
      "           3       0.06      0.33      0.10       160\n",
      "\n",
      "    accuracy                           0.53      8541\n",
      "   macro avg       0.38      0.49      0.39      8541\n",
      "weighted avg       0.66      0.53      0.57      8541\n",
      "\n",
      "EPOCH  55 : train loss 0.699, val loss 1.006, val accuracy 0.526, and val rmse 0.796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.56      0.34       521\n",
      "           1       0.81      0.50      0.62      5706\n",
      "           2       0.40      0.60      0.48      2154\n",
      "           3       0.07      0.25      0.10       160\n",
      "\n",
      "    accuracy                           0.53      8541\n",
      "   macro avg       0.38      0.48      0.39      8541\n",
      "weighted avg       0.66      0.53      0.56      8541\n",
      "\n",
      "EPOCH  60 : train loss 0.669, val loss 1.270, val accuracy 0.444, and val rmse 0.954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.22      0.28       521\n",
      "           1       0.84      0.40      0.54      5706\n",
      "           2       0.32      0.64      0.43      2154\n",
      "           3       0.04      0.33      0.07       160\n",
      "\n",
      "    accuracy                           0.44      8541\n",
      "   macro avg       0.40      0.40      0.33      8541\n",
      "weighted avg       0.67      0.44      0.49      8541\n",
      "\n",
      "EPOCH  65 : train loss 0.673, val loss 1.007, val accuracy 0.535, and val rmse 0.796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.52      0.37       521\n",
      "           1       0.81      0.52      0.63      5706\n",
      "           2       0.39      0.60      0.48      2154\n",
      "           3       0.06      0.25      0.10       160\n",
      "\n",
      "    accuracy                           0.54      8541\n",
      "   macro avg       0.39      0.47      0.39      8541\n",
      "weighted avg       0.66      0.54      0.57      8541\n",
      "\n",
      "EPOCH  70 : train loss 0.659, val loss 1.026, val accuracy 0.528, and val rmse 0.793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.52      0.36       521\n",
      "           1       0.83      0.48      0.61      5706\n",
      "           2       0.39      0.67      0.50      2154\n",
      "           3       0.06      0.23      0.10       160\n",
      "\n",
      "    accuracy                           0.53      8541\n",
      "   macro avg       0.39      0.48      0.39      8541\n",
      "weighted avg       0.67      0.53      0.56      8541\n",
      "\n",
      "EPOCH  75 : train loss 0.641, val loss 1.007, val accuracy 0.550, and val rmse 0.784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.54      0.36       521\n",
      "           1       0.82      0.54      0.65      5706\n",
      "           2       0.42      0.60      0.49      2154\n",
      "           3       0.06      0.26      0.10       160\n",
      "\n",
      "    accuracy                           0.55      8541\n",
      "   macro avg       0.39      0.48      0.40      8541\n",
      "weighted avg       0.67      0.55      0.58      8541\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  80 : train loss 0.623, val loss 1.049, val accuracy 0.529, and val rmse 0.803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.49      0.37       521\n",
      "           1       0.83      0.50      0.62      5706\n",
      "           2       0.39      0.64      0.49      2154\n",
      "           3       0.06      0.28      0.10       160\n",
      "\n",
      "    accuracy                           0.53      8541\n",
      "   macro avg       0.40      0.48      0.40      8541\n",
      "weighted avg       0.67      0.53      0.56      8541\n",
      "\n",
      "EPOCH  85 : train loss 0.612, val loss 0.974, val accuracy 0.561, and val rmse 0.745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.53      0.36       521\n",
      "           1       0.82      0.54      0.65      5706\n",
      "           2       0.42      0.65      0.51      2154\n",
      "           3       0.07      0.19      0.11       160\n",
      "\n",
      "    accuracy                           0.56      8541\n",
      "   macro avg       0.40      0.48      0.41      8541\n",
      "weighted avg       0.67      0.56      0.59      8541\n",
      "\n",
      "EPOCH  90 : train loss 0.625, val loss 0.975, val accuracy 0.563, and val rmse 0.757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.54      0.35       521\n",
      "           1       0.81      0.56      0.66      5706\n",
      "           2       0.43      0.59      0.50      2154\n",
      "           3       0.07      0.23      0.11       160\n",
      "\n",
      "    accuracy                           0.56      8541\n",
      "   macro avg       0.39      0.48      0.41      8541\n",
      "weighted avg       0.66      0.56      0.59      8541\n",
      "\n",
      "EPOCH  95 : train loss 0.602, val loss 1.008, val accuracy 0.554, and val rmse 0.759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.59      0.35       521\n",
      "           1       0.81      0.54      0.65      5706\n",
      "           2       0.43      0.60      0.50      2154\n",
      "           3       0.08      0.24      0.12       160\n",
      "\n",
      "    accuracy                           0.55      8541\n",
      "   macro avg       0.39      0.49      0.41      8541\n",
      "weighted avg       0.67      0.55      0.58      8541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM (num_layers=2), hidden_dim=50 GloVe embeddings emb_size=50, no stop words (train + test), N=800, own sampler (batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0 : train loss 1.278, val loss 1.134, val accuracy 0.418, and val rmse 1.167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.32      0.24       521\n",
      "           1       0.77      0.52      0.62      5706\n",
      "           2       0.45      0.15      0.22      2154\n",
      "           3       0.03      0.66      0.06       160\n",
      "\n",
      "    accuracy                           0.42      8541\n",
      "   macro avg       0.36      0.41      0.29      8541\n",
      "weighted avg       0.64      0.42      0.49      8541\n",
      "\n",
      "EPOCH  5 : train loss 1.069, val loss 1.096, val accuracy 0.451, and val rmse 1.046\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.46      0.30       521\n",
      "           1       0.81      0.47      0.59      5706\n",
      "           2       0.41      0.39      0.40      2154\n",
      "           3       0.04      0.51      0.07       160\n",
      "\n",
      "    accuracy                           0.45      8541\n",
      "   macro avg       0.37      0.46      0.34      8541\n",
      "weighted avg       0.66      0.45      0.52      8541\n",
      "\n",
      "EPOCH  10 : train loss 0.981, val loss 1.183, val accuracy 0.404, and val rmse 1.131\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.43      0.33       521\n",
      "           1       0.81      0.47      0.60      5706\n",
      "           2       0.33      0.20      0.25      2154\n",
      "           3       0.04      0.68      0.07       160\n",
      "\n",
      "    accuracy                           0.40      8541\n",
      "   macro avg       0.36      0.45      0.31      8541\n",
      "weighted avg       0.64      0.40      0.48      8541\n",
      "\n",
      "EPOCH  15 : train loss 0.895, val loss 0.999, val accuracy 0.514, and val rmse 0.868\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.46      0.33       521\n",
      "           1       0.80      0.54      0.64      5706\n",
      "           2       0.39      0.47      0.43      2154\n",
      "           3       0.05      0.38      0.09       160\n",
      "\n",
      "    accuracy                           0.51      8541\n",
      "   macro avg       0.38      0.46      0.37      8541\n",
      "weighted avg       0.65      0.51      0.56      8541\n",
      "\n",
      "EPOCH  20 : train loss 0.816, val loss 0.977, val accuracy 0.533, and val rmse 0.806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.50      0.35       521\n",
      "           1       0.82      0.53      0.64      5706\n",
      "           2       0.40      0.58      0.47      2154\n",
      "           3       0.06      0.30      0.10       160\n",
      "\n",
      "    accuracy                           0.53      8541\n",
      "   macro avg       0.39      0.47      0.39      8541\n",
      "weighted avg       0.66      0.53      0.57      8541\n",
      "\n",
      "EPOCH  25 : train loss 0.729, val loss 0.987, val accuracy 0.551, and val rmse 0.789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.48      0.36       521\n",
      "           1       0.82      0.55      0.66      5706\n",
      "           2       0.41      0.57      0.48      2154\n",
      "           3       0.06      0.30      0.10       160\n",
      "\n",
      "    accuracy                           0.55      8541\n",
      "   macro avg       0.40      0.48      0.40      8541\n",
      "weighted avg       0.67      0.55      0.59      8541\n",
      "\n",
      "EPOCH  30 : train loss 0.665, val loss 1.008, val accuracy 0.528, and val rmse 0.793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.57      0.37       521\n",
      "           1       0.83      0.50      0.62      5706\n",
      "           2       0.40      0.62      0.48      2154\n",
      "           3       0.07      0.28      0.11       160\n",
      "\n",
      "    accuracy                           0.53      8541\n",
      "   macro avg       0.39      0.49      0.40      8541\n",
      "weighted avg       0.67      0.53      0.56      8541\n",
      "\n",
      "EPOCH  35 : train loss 0.649, val loss 0.999, val accuracy 0.540, and val rmse 0.778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.60      0.35       521\n",
      "           1       0.81      0.52      0.64      5706\n",
      "           2       0.41      0.59      0.49      2154\n",
      "           3       0.07      0.23      0.10       160\n",
      "\n",
      "    accuracy                           0.54      8541\n",
      "   macro avg       0.39      0.48      0.40      8541\n",
      "weighted avg       0.66      0.54      0.57      8541\n",
      "\n",
      "EPOCH  40 : train loss 0.611, val loss 0.960, val accuracy 0.567, and val rmse 0.751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.55      0.37       521\n",
      "           1       0.82      0.56      0.66      5706\n",
      "           2       0.43      0.63      0.51      2154\n",
      "           3       0.07      0.23      0.11       160\n",
      "\n",
      "    accuracy                           0.57      8541\n",
      "   macro avg       0.40      0.49      0.41      8541\n",
      "weighted avg       0.68      0.57      0.60      8541\n",
      "\n",
      "EPOCH  45 : train loss 0.597, val loss 0.944, val accuracy 0.563, and val rmse 0.739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.56      0.38       521\n",
      "           1       0.83      0.53      0.65      5706\n",
      "           2       0.42      0.68      0.52      2154\n",
      "           3       0.07      0.18      0.10       160\n",
      "\n",
      "    accuracy                           0.56      8541\n",
      "   macro avg       0.40      0.49      0.41      8541\n",
      "weighted avg       0.68      0.56      0.59      8541\n",
      "\n",
      "EPOCH  50 : train loss 0.571, val loss 0.939, val accuracy 0.584, and val rmse 0.721\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.53      0.39       521\n",
      "           1       0.82      0.59      0.68      5706\n",
      "           2       0.43      0.62      0.51      2154\n",
      "           3       0.08      0.23      0.12       160\n",
      "\n",
      "    accuracy                           0.58      8541\n",
      "   macro avg       0.41      0.49      0.43      8541\n",
      "weighted avg       0.68      0.58      0.61      8541\n",
      "\n",
      "EPOCH  55 : train loss 0.544, val loss 0.963, val accuracy 0.576, and val rmse 0.729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.61      0.38       521\n",
      "           1       0.81      0.57      0.67      5706\n",
      "           2       0.45      0.62      0.52      2154\n",
      "           3       0.08      0.21      0.11       160\n",
      "\n",
      "    accuracy                           0.58      8541\n",
      "   macro avg       0.40      0.50      0.42      8541\n",
      "weighted avg       0.67      0.58      0.60      8541\n",
      "\n",
      "EPOCH  60 : train loss 0.541, val loss 0.968, val accuracy 0.575, and val rmse 0.736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.53      0.38       521\n",
      "           1       0.82      0.57      0.67      5706\n",
      "           2       0.43      0.62      0.50      2154\n",
      "           3       0.08      0.24      0.12       160\n",
      "\n",
      "    accuracy                           0.58      8541\n",
      "   macro avg       0.41      0.49      0.42      8541\n",
      "weighted avg       0.67      0.58      0.60      8541\n",
      "\n",
      "EPOCH  65 : train loss 0.504, val loss 0.971, val accuracy 0.589, and val rmse 0.726\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.55      0.37       521\n",
      "           1       0.81      0.60      0.69      5706\n",
      "           2       0.45      0.59      0.51      2154\n",
      "           3       0.07      0.20      0.10       160\n",
      "\n",
      "    accuracy                           0.59      8541\n",
      "   macro avg       0.40      0.49      0.42      8541\n",
      "weighted avg       0.67      0.59      0.62      8541\n",
      "\n",
      "EPOCH  70 : train loss 0.499, val loss 0.996, val accuracy 0.586, and val rmse 0.725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.61      0.39       521\n",
      "           1       0.81      0.59      0.68      5706\n",
      "           2       0.45      0.60      0.52      2154\n",
      "           3       0.07      0.19      0.11       160\n",
      "\n",
      "    accuracy                           0.59      8541\n",
      "   macro avg       0.40      0.50      0.42      8541\n",
      "weighted avg       0.67      0.59      0.61      8541\n",
      "\n",
      "EPOCH  75 : train loss 0.480, val loss 0.969, val accuracy 0.600, and val rmse 0.709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.55      0.39       521\n",
      "           1       0.81      0.61      0.70      5706\n",
      "           2       0.46      0.61      0.52      2154\n",
      "           3       0.08      0.21      0.11       160\n",
      "\n",
      "    accuracy                           0.60      8541\n",
      "   macro avg       0.41      0.49      0.43      8541\n",
      "weighted avg       0.68      0.60      0.62      8541\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  80 : train loss 0.483, val loss 0.977, val accuracy 0.597, and val rmse 0.709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.53      0.39       521\n",
      "           1       0.80      0.62      0.70      5706\n",
      "           2       0.45      0.59      0.51      2154\n",
      "           3       0.07      0.18      0.10       160\n",
      "\n",
      "    accuracy                           0.60      8541\n",
      "   macro avg       0.41      0.48      0.42      8541\n",
      "weighted avg       0.67      0.60      0.62      8541\n",
      "\n",
      "EPOCH  85 : train loss 0.475, val loss 0.980, val accuracy 0.597, and val rmse 0.705\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.52      0.39       521\n",
      "           1       0.81      0.60      0.69      5706\n",
      "           2       0.45      0.63      0.52      2154\n",
      "           3       0.07      0.19      0.11       160\n",
      "\n",
      "    accuracy                           0.60      8541\n",
      "   macro avg       0.41      0.49      0.43      8541\n",
      "weighted avg       0.68      0.60      0.62      8541\n",
      "\n",
      "EPOCH  90 : train loss 0.462, val loss 1.013, val accuracy 0.596, and val rmse 0.715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.56      0.39       521\n",
      "           1       0.82      0.61      0.70      5706\n",
      "           2       0.45      0.61      0.52      2154\n",
      "           3       0.07      0.19      0.10       160\n",
      "\n",
      "    accuracy                           0.60      8541\n",
      "   macro avg       0.41      0.49      0.43      8541\n",
      "weighted avg       0.68      0.60      0.62      8541\n",
      "\n",
      "EPOCH  95 : train loss 0.445, val loss 0.994, val accuracy 0.610, and val rmse 0.694\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.43      0.40       521\n",
      "           1       0.82      0.62      0.71      5706\n",
      "           2       0.44      0.65      0.53      2154\n",
      "           3       0.07      0.19      0.11       160\n",
      "\n",
      "    accuracy                           0.61      8541\n",
      "   macro avg       0.43      0.48      0.43      8541\n",
      "weighted avg       0.68      0.61      0.63      8541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM (num_layers=3), hidden_dim=50 GloVe embeddings emb_size=50, no stop words (train + test), N=800, own sampler (batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0 : train loss 1.280, val loss 1.283, val accuracy 0.409, and val rmse 0.915\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.42      0.24       521\n",
      "           1       0.82      0.29      0.43      5706\n",
      "           2       0.34      0.75      0.47      2154\n",
      "           3       0.02      0.06      0.03       160\n",
      "\n",
      "    accuracy                           0.41      8541\n",
      "   macro avg       0.34      0.38      0.29      8541\n",
      "weighted avg       0.65      0.41      0.42      8541\n",
      "\n",
      "EPOCH  5 : train loss 1.089, val loss 1.117, val accuracy 0.455, and val rmse 1.047\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.33      0.29       521\n",
      "           1       0.80      0.48      0.60      5706\n",
      "           2       0.40      0.40      0.40      2154\n",
      "           3       0.04      0.51      0.07       160\n",
      "\n",
      "    accuracy                           0.45      8541\n",
      "   macro avg       0.37      0.43      0.34      8541\n",
      "weighted avg       0.65      0.45      0.52      8541\n",
      "\n",
      "EPOCH  10 : train loss 1.005, val loss 1.128, val accuracy 0.429, and val rmse 1.008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.55      0.28       521\n",
      "           1       0.80      0.44      0.57      5706\n",
      "           2       0.39      0.37      0.38      2154\n",
      "           3       0.05      0.57      0.09       160\n",
      "\n",
      "    accuracy                           0.43      8541\n",
      "   macro avg       0.36      0.48      0.33      8541\n",
      "weighted avg       0.64      0.43      0.49      8541\n",
      "\n",
      "EPOCH  15 : train loss 0.869, val loss 1.165, val accuracy 0.415, and val rmse 1.021\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.60      0.31       521\n",
      "           1       0.82      0.42      0.55      5706\n",
      "           2       0.37      0.35      0.36      2154\n",
      "           3       0.05      0.61      0.08       160\n",
      "\n",
      "    accuracy                           0.41      8541\n",
      "   macro avg       0.36      0.49      0.33      8541\n",
      "weighted avg       0.65      0.41      0.48      8541\n",
      "\n",
      "EPOCH  20 : train loss 0.795, val loss 1.052, val accuracy 0.465, and val rmse 0.890\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.60      0.33       521\n",
      "           1       0.81      0.44      0.57      5706\n",
      "           2       0.38      0.50      0.43      2154\n",
      "           3       0.05      0.38      0.09       160\n",
      "\n",
      "    accuracy                           0.47      8541\n",
      "   macro avg       0.37      0.48      0.35      8541\n",
      "weighted avg       0.65      0.47      0.51      8541\n",
      "\n",
      "EPOCH  25 : train loss 0.745, val loss 0.976, val accuracy 0.541, and val rmse 0.791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.46      0.38       521\n",
      "           1       0.82      0.54      0.65      5706\n",
      "           2       0.39      0.60      0.47      2154\n",
      "           3       0.05      0.24      0.09       160\n",
      "\n",
      "    accuracy                           0.54      8541\n",
      "   macro avg       0.39      0.46      0.40      8541\n",
      "weighted avg       0.67      0.54      0.58      8541\n",
      "\n",
      "EPOCH  30 : train loss 0.692, val loss 0.936, val accuracy 0.550, and val rmse 0.752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.56      0.35       521\n",
      "           1       0.81      0.54      0.65      5706\n",
      "           2       0.41      0.62      0.49      2154\n",
      "           3       0.06      0.17      0.09       160\n",
      "\n",
      "    accuracy                           0.55      8541\n",
      "   macro avg       0.39      0.47      0.40      8541\n",
      "weighted avg       0.66      0.55      0.58      8541\n",
      "\n",
      "EPOCH  35 : train loss 0.639, val loss 0.991, val accuracy 0.556, and val rmse 0.792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.54      0.35       521\n",
      "           1       0.80      0.60      0.69      5706\n",
      "           2       0.42      0.46      0.44      2154\n",
      "           3       0.06      0.29      0.09       160\n",
      "\n",
      "    accuracy                           0.56      8541\n",
      "   macro avg       0.39      0.47      0.39      8541\n",
      "weighted avg       0.66      0.56      0.59      8541\n",
      "\n",
      "EPOCH  40 : train loss 0.612, val loss 1.065, val accuracy 0.507, and val rmse 0.837\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.67      0.35       521\n",
      "           1       0.83      0.48      0.61      5706\n",
      "           2       0.41      0.55      0.47      2154\n",
      "           3       0.05      0.27      0.09       160\n",
      "\n",
      "    accuracy                           0.51      8541\n",
      "   macro avg       0.38      0.49      0.38      8541\n",
      "weighted avg       0.67      0.51      0.55      8541\n",
      "\n",
      "EPOCH  45 : train loss 0.602, val loss 0.962, val accuracy 0.562, and val rmse 0.759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.53      0.38       521\n",
      "           1       0.82      0.56      0.66      5706\n",
      "           2       0.42      0.60      0.49      2154\n",
      "           3       0.05      0.20      0.08       160\n",
      "\n",
      "    accuracy                           0.56      8541\n",
      "   macro avg       0.40      0.47      0.41      8541\n",
      "weighted avg       0.67      0.56      0.59      8541\n",
      "\n",
      "EPOCH  50 : train loss 0.567, val loss 0.968, val accuracy 0.579, and val rmse 0.738\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.53      0.39       521\n",
      "           1       0.82      0.58      0.68      5706\n",
      "           2       0.43      0.62      0.51      2154\n",
      "           3       0.06      0.20      0.09       160\n",
      "\n",
      "    accuracy                           0.58      8541\n",
      "   macro avg       0.41      0.48      0.42      8541\n",
      "weighted avg       0.68      0.58      0.61      8541\n",
      "\n",
      "EPOCH  55 : train loss 0.545, val loss 0.954, val accuracy 0.581, and val rmse 0.736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.53      0.40       521\n",
      "           1       0.83      0.58      0.68      5706\n",
      "           2       0.43      0.63      0.51      2154\n",
      "           3       0.05      0.18      0.08       160\n",
      "\n",
      "    accuracy                           0.58      8541\n",
      "   macro avg       0.41      0.48      0.42      8541\n",
      "weighted avg       0.68      0.58      0.61      8541\n",
      "\n",
      "EPOCH  60 : train loss 0.519, val loss 0.989, val accuracy 0.569, and val rmse 0.739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.54      0.39       521\n",
      "           1       0.83      0.55      0.66      5706\n",
      "           2       0.42      0.66      0.52      2154\n",
      "           3       0.06      0.19      0.09       160\n",
      "\n",
      "    accuracy                           0.57      8541\n",
      "   macro avg       0.40      0.48      0.41      8541\n",
      "weighted avg       0.68      0.57      0.60      8541\n",
      "\n",
      "EPOCH  65 : train loss 0.517, val loss 0.987, val accuracy 0.563, and val rmse 0.741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.49      0.38       521\n",
      "           1       0.82      0.55      0.66      5706\n",
      "           2       0.41      0.65      0.50      2154\n",
      "           3       0.07      0.23      0.11       160\n",
      "\n",
      "    accuracy                           0.56      8541\n",
      "   macro avg       0.40      0.48      0.41      8541\n",
      "weighted avg       0.67      0.56      0.59      8541\n",
      "\n",
      "EPOCH  70 : train loss 0.483, val loss 1.029, val accuracy 0.562, and val rmse 0.756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.49      0.40       521\n",
      "           1       0.84      0.55      0.67      5706\n",
      "           2       0.41      0.62      0.49      2154\n",
      "           3       0.05      0.23      0.09       160\n",
      "\n",
      "    accuracy                           0.56      8541\n",
      "   macro avg       0.41      0.48      0.41      8541\n",
      "weighted avg       0.68      0.56      0.60      8541\n",
      "\n",
      "EPOCH  75 : train loss 0.461, val loss 1.092, val accuracy 0.546, and val rmse 0.762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.47      0.40       521\n",
      "           1       0.85      0.50      0.63      5706\n",
      "           2       0.39      0.71      0.50      2154\n",
      "           3       0.06      0.22      0.09       160\n",
      "\n",
      "    accuracy                           0.55      8541\n",
      "   macro avg       0.41      0.47      0.41      8541\n",
      "weighted avg       0.69      0.55      0.57      8541\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  80 : train loss 0.451, val loss 1.010, val accuracy 0.579, and val rmse 0.732\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.52      0.40       521\n",
      "           1       0.84      0.57      0.68      5706\n",
      "           2       0.43      0.65      0.51      2154\n",
      "           3       0.06      0.22      0.10       160\n",
      "\n",
      "    accuracy                           0.58      8541\n",
      "   macro avg       0.41      0.49      0.42      8541\n",
      "weighted avg       0.69      0.58      0.61      8541\n",
      "\n",
      "EPOCH  85 : train loss 0.442, val loss 0.946, val accuracy 0.626, and val rmse 0.670\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.48      0.39       521\n",
      "           1       0.82      0.65      0.73      5706\n",
      "           2       0.47      0.62      0.53      2154\n",
      "           3       0.08      0.19      0.11       160\n",
      "\n",
      "    accuracy                           0.63      8541\n",
      "   macro avg       0.43      0.49      0.44      8541\n",
      "weighted avg       0.69      0.63      0.65      8541\n",
      "\n",
      "EPOCH  90 : train loss 0.430, val loss 0.970, val accuracy 0.617, and val rmse 0.686\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.48      0.40       521\n",
      "           1       0.82      0.63      0.72      5706\n",
      "           2       0.46      0.64      0.54      2154\n",
      "           3       0.07      0.17      0.10       160\n",
      "\n",
      "    accuracy                           0.62      8541\n",
      "   macro avg       0.42      0.48      0.44      8541\n",
      "weighted avg       0.69      0.62      0.64      8541\n",
      "\n",
      "EPOCH  95 : train loss 0.393, val loss 1.008, val accuracy 0.612, and val rmse 0.692\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.53      0.39       521\n",
      "           1       0.83      0.61      0.70      5706\n",
      "           2       0.46      0.66      0.54      2154\n",
      "           3       0.08      0.18      0.11       160\n",
      "\n",
      "    accuracy                           0.61      8541\n",
      "   macro avg       0.42      0.50      0.44      8541\n",
      "weighted avg       0.69      0.61      0.63      8541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM (content+text) (num_layers=1), hidden_dim=50 GloVe embeddings emb_size=50, no stop words (train + test), N=1000, own sampler 1.2*(1/class_3) (batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0 : train loss 1.306, val loss 1.208, val accuracy 0.470, and val rmse 0.869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.25      0.23       521\n",
      "           1       0.76      0.45      0.56      5706\n",
      "           2       0.33      0.60      0.42      2154\n",
      "           3       0.05      0.18      0.07       160\n",
      "\n",
      "    accuracy                           0.47      8541\n",
      "   macro avg       0.34      0.37      0.32      8541\n",
      "weighted avg       0.60      0.47      0.50      8541\n",
      "\n",
      "EPOCH  5 : train loss 1.117, val loss 1.220, val accuracy 0.377, and val rmse 1.104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.39      0.31       521\n",
      "           1       0.82      0.36      0.50      5706\n",
      "           2       0.31      0.41      0.35      2154\n",
      "           3       0.04      0.57      0.07       160\n",
      "\n",
      "    accuracy                           0.38      8541\n",
      "   macro avg       0.36      0.43      0.31      8541\n",
      "weighted avg       0.64      0.38      0.44      8541\n",
      "\n",
      "EPOCH  10 : train loss 1.025, val loss 1.222, val accuracy 0.353, and val rmse 1.157\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.46      0.30       521\n",
      "           1       0.81      0.36      0.50      5706\n",
      "           2       0.31      0.28      0.29      2154\n",
      "           3       0.04      0.66      0.07       160\n",
      "\n",
      "    accuracy                           0.35      8541\n",
      "   macro avg       0.35      0.44      0.29      8541\n",
      "weighted avg       0.63      0.35      0.43      8541\n",
      "\n",
      "EPOCH  15 : train loss 0.947, val loss 1.140, val accuracy 0.439, and val rmse 1.015\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.42      0.35       521\n",
      "           1       0.83      0.45      0.58      5706\n",
      "           2       0.34      0.40      0.37      2154\n",
      "           3       0.04      0.57      0.08       160\n",
      "\n",
      "    accuracy                           0.44      8541\n",
      "   macro avg       0.38      0.46      0.35      8541\n",
      "weighted avg       0.66      0.44      0.50      8541\n",
      "\n",
      "EPOCH  20 : train loss 0.852, val loss 1.057, val accuracy 0.488, and val rmse 0.905\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.48      0.35       521\n",
      "           1       0.82      0.48      0.60      5706\n",
      "           2       0.38      0.52      0.44      2154\n",
      "           3       0.05      0.43      0.09       160\n",
      "\n",
      "    accuracy                           0.49      8541\n",
      "   macro avg       0.38      0.48      0.37      8541\n",
      "weighted avg       0.66      0.49      0.54      8541\n",
      "\n",
      "EPOCH  25 : train loss 0.795, val loss 1.022, val accuracy 0.509, and val rmse 0.847\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.51      0.34       521\n",
      "           1       0.81      0.51      0.62      5706\n",
      "           2       0.39      0.53      0.45      2154\n",
      "           3       0.06      0.36      0.10       160\n",
      "\n",
      "    accuracy                           0.51      8541\n",
      "   macro avg       0.38      0.48      0.38      8541\n",
      "weighted avg       0.66      0.51      0.55      8541\n",
      "\n",
      "EPOCH  30 : train loss 0.762, val loss 1.068, val accuracy 0.501, and val rmse 0.861\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.52      0.35       521\n",
      "           1       0.82      0.50      0.62      5706\n",
      "           2       0.39      0.50      0.44      2154\n",
      "           3       0.05      0.41      0.10       160\n",
      "\n",
      "    accuracy                           0.50      8541\n",
      "   macro avg       0.38      0.48      0.38      8541\n",
      "weighted avg       0.66      0.50      0.55      8541\n",
      "\n",
      "EPOCH  35 : train loss 0.716, val loss 1.043, val accuracy 0.529, and val rmse 0.832\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.55      0.36       521\n",
      "           1       0.81      0.54      0.65      5706\n",
      "           2       0.42      0.51      0.46      2154\n",
      "           3       0.06      0.38      0.10       160\n",
      "\n",
      "    accuracy                           0.53      8541\n",
      "   macro avg       0.39      0.50      0.39      8541\n",
      "weighted avg       0.66      0.53      0.57      8541\n",
      "\n",
      "EPOCH  40 : train loss 0.708, val loss 1.035, val accuracy 0.517, and val rmse 0.831\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.59      0.36       521\n",
      "           1       0.82      0.51      0.62      5706\n",
      "           2       0.40      0.54      0.46      2154\n",
      "           3       0.06      0.34      0.10       160\n",
      "\n",
      "    accuracy                           0.52      8541\n",
      "   macro avg       0.38      0.49      0.39      8541\n",
      "weighted avg       0.67      0.52      0.56      8541\n",
      "\n",
      "EPOCH  45 : train loss 0.822, val loss 1.085, val accuracy 0.500, and val rmse 0.868\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.51      0.33       521\n",
      "           1       0.82      0.48      0.60      5706\n",
      "           2       0.39      0.56      0.46      2154\n",
      "           3       0.05      0.34      0.09       160\n",
      "\n",
      "    accuracy                           0.50      8541\n",
      "   macro avg       0.38      0.47      0.37      8541\n",
      "weighted avg       0.66      0.50      0.54      8541\n",
      "\n",
      "EPOCH  50 : train loss 0.672, val loss 0.961, val accuracy 0.562, and val rmse 0.755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.53      0.37       521\n",
      "           1       0.81      0.56      0.66      5706\n",
      "           2       0.43      0.60      0.50      2154\n",
      "           3       0.08      0.29      0.12       160\n",
      "\n",
      "    accuracy                           0.56      8541\n",
      "   macro avg       0.40      0.49      0.41      8541\n",
      "weighted avg       0.67      0.56      0.59      8541\n",
      "\n",
      "EPOCH  55 : train loss 0.653, val loss 0.972, val accuracy 0.553, and val rmse 0.758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.46      0.37       521\n",
      "           1       0.82      0.53      0.65      5706\n",
      "           2       0.40      0.65      0.50      2154\n",
      "           3       0.07      0.24      0.11       160\n",
      "\n",
      "    accuracy                           0.55      8541\n",
      "   macro avg       0.40      0.47      0.41      8541\n",
      "weighted avg       0.67      0.55      0.58      8541\n",
      "\n",
      "EPOCH  60 : train loss 0.636, val loss 1.057, val accuracy 0.519, and val rmse 0.821\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.48      0.37       521\n",
      "           1       0.83      0.50      0.63      5706\n",
      "           2       0.38      0.58      0.46      2154\n",
      "           3       0.06      0.36      0.10       160\n",
      "\n",
      "    accuracy                           0.52      8541\n",
      "   macro avg       0.39      0.48      0.39      8541\n",
      "weighted avg       0.67      0.52      0.56      8541\n",
      "\n",
      "EPOCH  65 : train loss 0.631, val loss 0.960, val accuracy 0.571, and val rmse 0.750\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.54      0.36       521\n",
      "           1       0.80      0.59      0.68      5706\n",
      "           2       0.44      0.56      0.49      2154\n",
      "           3       0.06      0.24      0.10       160\n",
      "\n",
      "    accuracy                           0.57      8541\n",
      "   macro avg       0.39      0.48      0.41      8541\n",
      "weighted avg       0.66      0.57      0.60      8541\n",
      "\n",
      "EPOCH  70 : train loss 0.613, val loss 0.970, val accuracy 0.567, and val rmse 0.745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.55      0.38       521\n",
      "           1       0.82      0.56      0.66      5706\n",
      "           2       0.43      0.61      0.50      2154\n",
      "           3       0.08      0.29      0.12       160\n",
      "\n",
      "    accuracy                           0.57      8541\n",
      "   macro avg       0.40      0.50      0.42      8541\n",
      "weighted avg       0.67      0.57      0.60      8541\n",
      "\n",
      "EPOCH  75 : train loss 0.608, val loss 0.951, val accuracy 0.576, and val rmse 0.725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.59      0.36       521\n",
      "           1       0.80      0.58      0.68      5706\n",
      "           2       0.45      0.58      0.51      2154\n",
      "           3       0.08      0.21      0.11       160\n",
      "\n",
      "    accuracy                           0.58      8541\n",
      "   macro avg       0.40      0.49      0.41      8541\n",
      "weighted avg       0.67      0.58      0.60      8541\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  80 : train loss 0.598, val loss 1.068, val accuracy 0.539, and val rmse 0.794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.56      0.37       521\n",
      "           1       0.83      0.53      0.65      5706\n",
      "           2       0.41      0.57      0.48      2154\n",
      "           3       0.07      0.36      0.11       160\n",
      "\n",
      "    accuracy                           0.54      8541\n",
      "   macro avg       0.40      0.50      0.40      8541\n",
      "weighted avg       0.67      0.54      0.58      8541\n",
      "\n",
      "EPOCH  85 : train loss 0.580, val loss 1.001, val accuracy 0.553, and val rmse 0.750\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.56      0.37       521\n",
      "           1       0.82      0.53      0.64      5706\n",
      "           2       0.42      0.63      0.50      2154\n",
      "           3       0.08      0.25      0.12       160\n",
      "\n",
      "    accuracy                           0.55      8541\n",
      "   macro avg       0.40      0.49      0.41      8541\n",
      "weighted avg       0.67      0.55      0.58      8541\n",
      "\n",
      "EPOCH  90 : train loss 0.579, val loss 1.064, val accuracy 0.518, and val rmse 0.790\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.60      0.36       521\n",
      "           1       0.84      0.46      0.59      5706\n",
      "           2       0.40      0.68      0.50      2154\n",
      "           3       0.07      0.25      0.11       160\n",
      "\n",
      "    accuracy                           0.52      8541\n",
      "   macro avg       0.39      0.49      0.39      8541\n",
      "weighted avg       0.68      0.52      0.55      8541\n",
      "\n",
      "EPOCH  95 : train loss 0.574, val loss 0.970, val accuracy 0.569, and val rmse 0.734\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.56      0.38       521\n",
      "           1       0.81      0.56      0.66      5706\n",
      "           2       0.43      0.62      0.51      2154\n",
      "           3       0.08      0.24      0.12       160\n",
      "\n",
      "    accuracy                           0.57      8541\n",
      "   macro avg       0.40      0.50      0.42      8541\n",
      "weighted avg       0.67      0.57      0.60      8541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM (content+text) (num_layers=1), hidden_dim=50 GloVe embeddings emb_size=50, no stop words (train + test), N=1000, own sampler 1.5*(1/class_3) (batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0 : train loss 1.291, val loss 1.337, val accuracy 0.202, and val rmse 1.554\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.16      0.17       521\n",
      "           1       0.79      0.25      0.38      5706\n",
      "           2       0.32      0.03      0.05      2154\n",
      "           3       0.02      0.89      0.05       160\n",
      "\n",
      "    accuracy                           0.20      8541\n",
      "   macro avg       0.33      0.33      0.16      8541\n",
      "weighted avg       0.62      0.20      0.28      8541\n",
      "\n",
      "EPOCH  5 : train loss 1.129, val loss 1.247, val accuracy 0.333, and val rmse 1.259\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.39      0.26       521\n",
      "           1       0.80      0.39      0.52      5706\n",
      "           2       0.31      0.14      0.19      2154\n",
      "           3       0.03      0.76      0.06       160\n",
      "\n",
      "    accuracy                           0.33      8541\n",
      "   macro avg       0.33      0.42      0.26      8541\n",
      "weighted avg       0.62      0.33      0.41      8541\n",
      "\n",
      "EPOCH  10 : train loss 1.036, val loss 1.278, val accuracy 0.351, and val rmse 1.215\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.38      0.31       521\n",
      "           1       0.82      0.40      0.54      5706\n",
      "           2       0.28      0.18      0.22      2154\n",
      "           3       0.03      0.77      0.07       160\n",
      "\n",
      "    accuracy                           0.35      8541\n",
      "   macro avg       0.35      0.43      0.28      8541\n",
      "weighted avg       0.63      0.35      0.43      8541\n",
      "\n",
      "EPOCH  15 : train loss 0.955, val loss 1.111, val accuracy 0.438, and val rmse 1.009\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.48      0.32       521\n",
      "           1       0.81      0.47      0.60      5706\n",
      "           2       0.34      0.33      0.33      2154\n",
      "           3       0.04      0.58      0.08       160\n",
      "\n",
      "    accuracy                           0.44      8541\n",
      "   macro avg       0.36      0.46      0.33      8541\n",
      "weighted avg       0.64      0.44      0.50      8541\n",
      "\n",
      "EPOCH  20 : train loss 0.884, val loss 1.207, val accuracy 0.408, and val rmse 1.066\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.51      0.34       521\n",
      "           1       0.83      0.42      0.56      5706\n",
      "           2       0.33      0.33      0.33      2154\n",
      "           3       0.04      0.59      0.07       160\n",
      "\n",
      "    accuracy                           0.41      8541\n",
      "   macro avg       0.36      0.46      0.33      8541\n",
      "weighted avg       0.65      0.41      0.48      8541\n",
      "\n",
      "EPOCH  25 : train loss 0.806, val loss 1.037, val accuracy 0.505, and val rmse 0.869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.48      0.35       521\n",
      "           1       0.80      0.53      0.64      5706\n",
      "           2       0.38      0.46      0.41      2154\n",
      "           3       0.05      0.39      0.09       160\n",
      "\n",
      "    accuracy                           0.50      8541\n",
      "   macro avg       0.38      0.46      0.37      8541\n",
      "weighted avg       0.65      0.50      0.55      8541\n",
      "\n",
      "EPOCH  30 : train loss 0.759, val loss 1.070, val accuracy 0.481, and val rmse 0.898\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.56      0.34       521\n",
      "           1       0.80      0.49      0.61      5706\n",
      "           2       0.38      0.45      0.41      2154\n",
      "           3       0.04      0.34      0.08       160\n",
      "\n",
      "    accuracy                           0.48      8541\n",
      "   macro avg       0.36      0.46      0.36      8541\n",
      "weighted avg       0.64      0.48      0.53      8541\n",
      "\n",
      "EPOCH  35 : train loss 0.730, val loss 1.083, val accuracy 0.468, and val rmse 0.887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.56      0.35       521\n",
      "           1       0.81      0.44      0.57      5706\n",
      "           2       0.36      0.53      0.43      2154\n",
      "           3       0.04      0.31      0.08       160\n",
      "\n",
      "    accuracy                           0.47      8541\n",
      "   macro avg       0.37      0.46      0.36      8541\n",
      "weighted avg       0.65      0.47      0.51      8541\n",
      "\n",
      "EPOCH  40 : train loss 0.691, val loss 1.086, val accuracy 0.491, and val rmse 0.873\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.56      0.35       521\n",
      "           1       0.82      0.48      0.61      5706\n",
      "           2       0.38      0.51      0.44      2154\n",
      "           3       0.05      0.33      0.08       160\n",
      "\n",
      "    accuracy                           0.49      8541\n",
      "   macro avg       0.38      0.47      0.37      8541\n",
      "weighted avg       0.66      0.49      0.54      8541\n",
      "\n",
      "EPOCH  45 : train loss 0.658, val loss 1.026, val accuracy 0.524, and val rmse 0.819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.55      0.36       521\n",
      "           1       0.82      0.51      0.63      5706\n",
      "           2       0.40      0.57      0.47      2154\n",
      "           3       0.05      0.28      0.09       160\n",
      "\n",
      "    accuracy                           0.52      8541\n",
      "   macro avg       0.39      0.48      0.39      8541\n",
      "weighted avg       0.66      0.52      0.56      8541\n",
      "\n",
      "EPOCH  50 : train loss 0.658, val loss 1.015, val accuracy 0.523, and val rmse 0.812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.53      0.36       521\n",
      "           1       0.83      0.49      0.62      5706\n",
      "           2       0.40      0.63      0.49      2154\n",
      "           3       0.06      0.28      0.09       160\n",
      "\n",
      "    accuracy                           0.52      8541\n",
      "   macro avg       0.39      0.48      0.39      8541\n",
      "weighted avg       0.67      0.52      0.56      8541\n",
      "\n",
      "EPOCH  55 : train loss 0.627, val loss 1.096, val accuracy 0.506, and val rmse 0.841\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.57      0.35       521\n",
      "           1       0.82      0.48      0.61      5706\n",
      "           2       0.39      0.56      0.46      2154\n",
      "           3       0.06      0.33      0.10       160\n",
      "\n",
      "    accuracy                           0.51      8541\n",
      "   macro avg       0.38      0.48      0.38      8541\n",
      "weighted avg       0.67      0.51      0.55      8541\n",
      "\n",
      "EPOCH  60 : train loss 0.622, val loss 1.037, val accuracy 0.527, and val rmse 0.800\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.56      0.35       521\n",
      "           1       0.82      0.51      0.63      5706\n",
      "           2       0.40      0.59      0.48      2154\n",
      "           3       0.06      0.27      0.10       160\n",
      "\n",
      "    accuracy                           0.53      8541\n",
      "   macro avg       0.38      0.48      0.39      8541\n",
      "weighted avg       0.66      0.53      0.56      8541\n",
      "\n",
      "EPOCH  65 : train loss 0.603, val loss 1.019, val accuracy 0.547, and val rmse 0.770\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.57      0.34       521\n",
      "           1       0.82      0.53      0.65      5706\n",
      "           2       0.43      0.60      0.50      2154\n",
      "           3       0.06      0.21      0.10       160\n",
      "\n",
      "    accuracy                           0.55      8541\n",
      "   macro avg       0.39      0.48      0.40      8541\n",
      "weighted avg       0.67      0.55      0.58      8541\n",
      "\n",
      "EPOCH  70 : train loss 0.589, val loss 1.013, val accuracy 0.546, and val rmse 0.776\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.49      0.37       521\n",
      "           1       0.82      0.53      0.65      5706\n",
      "           2       0.40      0.62      0.49      2154\n",
      "           3       0.06      0.23      0.09       160\n",
      "\n",
      "    accuracy                           0.55      8541\n",
      "   macro avg       0.39      0.47      0.40      8541\n",
      "weighted avg       0.67      0.55      0.58      8541\n",
      "\n",
      "EPOCH  75 : train loss 0.590, val loss 1.006, val accuracy 0.557, and val rmse 0.767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.53      0.37       521\n",
      "           1       0.82      0.55      0.66      5706\n",
      "           2       0.42      0.61      0.50      2154\n",
      "           3       0.06      0.24      0.10       160\n",
      "\n",
      "    accuracy                           0.56      8541\n",
      "   macro avg       0.40      0.48      0.41      8541\n",
      "weighted avg       0.67      0.56      0.59      8541\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  80 : train loss 0.569, val loss 1.016, val accuracy 0.544, and val rmse 0.768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.53      0.37       521\n",
      "           1       0.82      0.52      0.64      5706\n",
      "           2       0.41      0.64      0.50      2154\n",
      "           3       0.06      0.24      0.10       160\n",
      "\n",
      "    accuracy                           0.54      8541\n",
      "   macro avg       0.39      0.48      0.40      8541\n",
      "weighted avg       0.67      0.54      0.57      8541\n",
      "\n",
      "EPOCH  85 : train loss 0.580, val loss 1.015, val accuracy 0.541, and val rmse 0.759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.54      0.36       521\n",
      "           1       0.83      0.51      0.63      5706\n",
      "           2       0.40      0.66      0.50      2154\n",
      "           3       0.07      0.23      0.11       160\n",
      "\n",
      "    accuracy                           0.54      8541\n",
      "   macro avg       0.39      0.48      0.40      8541\n",
      "weighted avg       0.67      0.54      0.57      8541\n",
      "\n",
      "EPOCH  90 : train loss 0.558, val loss 1.022, val accuracy 0.552, and val rmse 0.764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.52      0.38       521\n",
      "           1       0.83      0.53      0.65      5706\n",
      "           2       0.41      0.65      0.50      2154\n",
      "           3       0.05      0.19      0.08       160\n",
      "\n",
      "    accuracy                           0.55      8541\n",
      "   macro avg       0.40      0.47      0.40      8541\n",
      "weighted avg       0.68      0.55      0.58      8541\n",
      "\n",
      "EPOCH  95 : train loss 0.550, val loss 1.007, val accuracy 0.554, and val rmse 0.745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.60      0.37       521\n",
      "           1       0.82      0.53      0.65      5706\n",
      "           2       0.42      0.62      0.50      2154\n",
      "           3       0.06      0.17      0.09       160\n",
      "\n",
      "    accuracy                           0.55      8541\n",
      "   macro avg       0.39      0.48      0.40      8541\n",
      "weighted avg       0.67      0.55      0.58      8541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM (content+text) (num_layers=1), hidden_dim=50 GloVe embeddings emb_size=50, no stop words (train + test), N=1000, own sampler 1.3*(1/class_3) (batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0 : train loss 1.317, val loss 1.358, val accuracy 0.240, and val rmse 1.525\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.02      0.03       521\n",
      "           1       0.77      0.33      0.46      5706\n",
      "           2       0.27      0.02      0.03      2154\n",
      "           3       0.02      0.91      0.05       160\n",
      "\n",
      "    accuracy                           0.24      8541\n",
      "   macro avg       0.33      0.32      0.14      8541\n",
      "weighted avg       0.60      0.24      0.32      8541\n",
      "\n",
      "EPOCH  5 : train loss 1.140, val loss 1.303, val accuracy 0.277, and val rmse 1.291\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.44      0.28       521\n",
      "           1       0.81      0.26      0.39      5706\n",
      "           2       0.29      0.26      0.27      2154\n",
      "           3       0.03      0.69      0.06       160\n",
      "\n",
      "    accuracy                           0.28      8541\n",
      "   macro avg       0.33      0.41      0.25      8541\n",
      "weighted avg       0.63      0.28      0.35      8541\n",
      "\n",
      "EPOCH  10 : train loss 1.082, val loss 1.232, val accuracy 0.348, and val rmse 1.214\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.48      0.28       521\n",
      "           1       0.80      0.40      0.53      5706\n",
      "           2       0.32      0.14      0.20      2154\n",
      "           3       0.03      0.74      0.07       160\n",
      "\n",
      "    accuracy                           0.35      8541\n",
      "   macro avg       0.34      0.44      0.27      8541\n",
      "weighted avg       0.63      0.35      0.43      8541\n",
      "\n",
      "EPOCH  15 : train loss 1.018, val loss 1.103, val accuracy 0.447, and val rmse 1.031\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.33      0.30       521\n",
      "           1       0.79      0.51      0.62      5706\n",
      "           2       0.33      0.30      0.32      2154\n",
      "           3       0.04      0.59      0.08       160\n",
      "\n",
      "    accuracy                           0.45      8541\n",
      "   macro avg       0.36      0.43      0.33      8541\n",
      "weighted avg       0.63      0.45      0.51      8541\n",
      "\n",
      "EPOCH  20 : train loss 0.950, val loss 1.289, val accuracy 0.350, and val rmse 1.163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33       521\n",
      "           1       0.83      0.35      0.49      5706\n",
      "           2       0.29      0.31      0.30      2154\n",
      "           3       0.04      0.68      0.07       160\n",
      "\n",
      "    accuracy                           0.35      8541\n",
      "   macro avg       0.36      0.43      0.30      8541\n",
      "weighted avg       0.64      0.35      0.43      8541\n",
      "\n",
      "EPOCH  25 : train loss 0.885, val loss 1.184, val accuracy 0.429, and val rmse 1.028\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.34       521\n",
      "           1       0.82      0.45      0.58      5706\n",
      "           2       0.32      0.37      0.35      2154\n",
      "           3       0.04      0.61      0.08       160\n",
      "\n",
      "    accuracy                           0.43      8541\n",
      "   macro avg       0.37      0.46      0.34      8541\n",
      "weighted avg       0.65      0.43      0.50      8541\n",
      "\n",
      "EPOCH  30 : train loss 0.851, val loss 1.121, val accuracy 0.470, and val rmse 0.959\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.54      0.33       521\n",
      "           1       0.80      0.51      0.62      5706\n",
      "           2       0.38      0.35      0.36      2154\n",
      "           3       0.05      0.54      0.09       160\n",
      "\n",
      "    accuracy                           0.47      8541\n",
      "   macro avg       0.37      0.48      0.35      8541\n",
      "weighted avg       0.65      0.47      0.53      8541\n",
      "\n",
      "EPOCH  35 : train loss 0.789, val loss 1.015, val accuracy 0.513, and val rmse 0.853\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.48      0.36       521\n",
      "           1       0.81      0.51      0.63      5706\n",
      "           2       0.38      0.52      0.44      2154\n",
      "           3       0.06      0.43      0.11       160\n",
      "\n",
      "    accuracy                           0.51      8541\n",
      "   macro avg       0.39      0.49      0.38      8541\n",
      "weighted avg       0.66      0.51      0.56      8541\n",
      "\n",
      "EPOCH  40 : train loss 0.754, val loss 1.074, val accuracy 0.487, and val rmse 0.872\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.62      0.33       521\n",
      "           1       0.81      0.48      0.60      5706\n",
      "           2       0.39      0.49      0.44      2154\n",
      "           3       0.06      0.42      0.11       160\n",
      "\n",
      "    accuracy                           0.49      8541\n",
      "   macro avg       0.37      0.50      0.37      8541\n",
      "weighted avg       0.66      0.49      0.53      8541\n",
      "\n",
      "EPOCH  45 : train loss 0.728, val loss 1.086, val accuracy 0.498, and val rmse 0.879\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.50      0.36       521\n",
      "           1       0.82      0.49      0.61      5706\n",
      "           2       0.38      0.52      0.44      2154\n",
      "           3       0.06      0.46      0.10       160\n",
      "\n",
      "    accuracy                           0.50      8541\n",
      "   macro avg       0.38      0.49      0.38      8541\n",
      "weighted avg       0.66      0.50      0.54      8541\n",
      "\n",
      "EPOCH  50 : train loss 0.700, val loss 0.998, val accuracy 0.531, and val rmse 0.802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.54      0.36       521\n",
      "           1       0.80      0.53      0.64      5706\n",
      "           2       0.40      0.53      0.45      2154\n",
      "           3       0.07      0.34      0.12       160\n",
      "\n",
      "    accuracy                           0.53      8541\n",
      "   macro avg       0.38      0.49      0.39      8541\n",
      "weighted avg       0.65      0.53      0.57      8541\n",
      "\n",
      "EPOCH  55 : train loss 0.681, val loss 0.994, val accuracy 0.530, and val rmse 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.59      0.34       521\n",
      "           1       0.81      0.51      0.63      5706\n",
      "           2       0.41      0.57      0.48      2154\n",
      "           3       0.08      0.33      0.13       160\n",
      "\n",
      "    accuracy                           0.53      8541\n",
      "   macro avg       0.39      0.50      0.39      8541\n",
      "weighted avg       0.66      0.53      0.56      8541\n",
      "\n",
      "EPOCH  60 : train loss 0.643, val loss 0.951, val accuracy 0.560, and val rmse 0.751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.53      0.37       521\n",
      "           1       0.81      0.55      0.66      5706\n",
      "           2       0.41      0.61      0.49      2154\n",
      "           3       0.09      0.28      0.13       160\n",
      "\n",
      "    accuracy                           0.56      8541\n",
      "   macro avg       0.40      0.49      0.41      8541\n",
      "weighted avg       0.66      0.56      0.59      8541\n",
      "\n",
      "EPOCH  65 : train loss 0.645, val loss 1.015, val accuracy 0.538, and val rmse 0.801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.52      0.37       521\n",
      "           1       0.82      0.53      0.65      5706\n",
      "           2       0.40      0.57      0.47      2154\n",
      "           3       0.07      0.34      0.11       160\n",
      "\n",
      "    accuracy                           0.54      8541\n",
      "   macro avg       0.39      0.49      0.40      8541\n",
      "weighted avg       0.67      0.54      0.57      8541\n",
      "\n",
      "EPOCH  70 : train loss 0.618, val loss 1.025, val accuracy 0.534, and val rmse 0.784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.55      0.38       521\n",
      "           1       0.83      0.50      0.62      5706\n",
      "           2       0.40      0.64      0.49      2154\n",
      "           3       0.07      0.29      0.12       160\n",
      "\n",
      "    accuracy                           0.53      8541\n",
      "   macro avg       0.40      0.50      0.40      8541\n",
      "weighted avg       0.67      0.53      0.57      8541\n",
      "\n",
      "EPOCH  75 : train loss 0.611, val loss 1.052, val accuracy 0.531, and val rmse 0.797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.64      0.34       521\n",
      "           1       0.82      0.51      0.63      5706\n",
      "           2       0.42      0.58      0.49      2154\n",
      "           3       0.08      0.31      0.12       160\n",
      "\n",
      "    accuracy                           0.53      8541\n",
      "   macro avg       0.39      0.51      0.40      8541\n",
      "weighted avg       0.67      0.53      0.57      8541\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  80 : train loss 0.607, val loss 1.052, val accuracy 0.525, and val rmse 0.795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.60      0.36       521\n",
      "           1       0.82      0.50      0.62      5706\n",
      "           2       0.40      0.60      0.48      2154\n",
      "           3       0.07      0.31      0.11       160\n",
      "\n",
      "    accuracy                           0.52      8541\n",
      "   macro avg       0.39      0.50      0.39      8541\n",
      "weighted avg       0.67      0.52      0.56      8541\n",
      "\n",
      "EPOCH  85 : train loss 0.581, val loss 0.997, val accuracy 0.545, and val rmse 0.759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.48      0.37       521\n",
      "           1       0.83      0.50      0.63      5706\n",
      "           2       0.40      0.69      0.51      2154\n",
      "           3       0.09      0.27      0.13       160\n",
      "\n",
      "    accuracy                           0.54      8541\n",
      "   macro avg       0.40      0.49      0.41      8541\n",
      "weighted avg       0.68      0.54      0.57      8541\n",
      "\n",
      "EPOCH  90 : train loss 0.583, val loss 1.068, val accuracy 0.529, and val rmse 0.804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.53      0.36       521\n",
      "           1       0.83      0.50      0.63      5706\n",
      "           2       0.40      0.61      0.49      2154\n",
      "           3       0.07      0.33      0.11       160\n",
      "\n",
      "    accuracy                           0.53      8541\n",
      "   macro avg       0.39      0.49      0.40      8541\n",
      "weighted avg       0.67      0.53      0.56      8541\n",
      "\n",
      "EPOCH  95 : train loss 0.572, val loss 1.063, val accuracy 0.529, and val rmse 0.792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.58      0.37       521\n",
      "           1       0.83      0.50      0.62      5706\n",
      "           2       0.40      0.61      0.48      2154\n",
      "           3       0.07      0.33      0.12       160\n",
      "\n",
      "    accuracy                           0.53      8541\n",
      "   macro avg       0.39      0.51      0.40      8541\n",
      "weighted avg       0.67      0.53      0.56      8541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM (content+text) (num_layers=1), hidden_dim=50 GloVe embeddings emb_size=50, no stop words (train + test), N=1500, own sampler (1/class_3) (batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0 : train loss 1.345, val loss 1.311, val accuracy 0.245, and val rmse 1.515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       521\n",
      "           1       0.76      0.32      0.46      5706\n",
      "           2       0.26      0.05      0.08      2154\n",
      "           3       0.02      0.84      0.05       160\n",
      "\n",
      "    accuracy                           0.25      8541\n",
      "   macro avg       0.26      0.30      0.15      8541\n",
      "weighted avg       0.57      0.25      0.33      8541\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programs\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  5 : train loss 1.167, val loss 1.229, val accuracy 0.327, and val rmse 1.170\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.48      0.25       521\n",
      "           1       0.79      0.31      0.44      5706\n",
      "           2       0.32      0.33      0.32      2154\n",
      "           3       0.03      0.56      0.06       160\n",
      "\n",
      "    accuracy                           0.33      8541\n",
      "   macro avg       0.33      0.42      0.27      8541\n",
      "weighted avg       0.62      0.33      0.39      8541\n",
      "\n",
      "EPOCH  10 : train loss 1.110, val loss 1.208, val accuracy 0.353, and val rmse 1.122\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.43      0.29       521\n",
      "           1       0.82      0.34      0.48      5706\n",
      "           2       0.29      0.36      0.32      2154\n",
      "           3       0.04      0.57      0.07       160\n",
      "\n",
      "    accuracy                           0.35      8541\n",
      "   macro avg       0.34      0.43      0.29      8541\n",
      "weighted avg       0.64      0.35      0.42      8541\n",
      "\n",
      "EPOCH  15 : train loss 1.045, val loss 1.090, val accuracy 0.475, and val rmse 0.947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.48      0.32       521\n",
      "           1       0.80      0.53      0.63      5706\n",
      "           2       0.35      0.34      0.34      2154\n",
      "           3       0.05      0.47      0.08       160\n",
      "\n",
      "    accuracy                           0.47      8541\n",
      "   macro avg       0.36      0.45      0.35      8541\n",
      "weighted avg       0.64      0.47      0.53      8541\n",
      "\n",
      "EPOCH  20 : train loss 1.000, val loss 1.113, val accuracy 0.438, and val rmse 0.977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.41      0.32       521\n",
      "           1       0.81      0.44      0.57      5706\n",
      "           2       0.32      0.43      0.37      2154\n",
      "           3       0.05      0.51      0.09       160\n",
      "\n",
      "    accuracy                           0.44      8541\n",
      "   macro avg       0.36      0.45      0.34      8541\n",
      "weighted avg       0.64      0.44      0.50      8541\n",
      "\n",
      "EPOCH  25 : train loss 0.955, val loss 1.009, val accuracy 0.502, and val rmse 0.863\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.47      0.36       521\n",
      "           1       0.81      0.51      0.62      5706\n",
      "           2       0.36      0.50      0.42      2154\n",
      "           3       0.06      0.39      0.10       160\n",
      "\n",
      "    accuracy                           0.50      8541\n",
      "   macro avg       0.38      0.47      0.37      8541\n",
      "weighted avg       0.65      0.50      0.55      8541\n",
      "\n",
      "EPOCH  30 : train loss 0.912, val loss 1.102, val accuracy 0.455, and val rmse 0.966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.42      0.34       521\n",
      "           1       0.83      0.45      0.59      5706\n",
      "           2       0.34      0.47      0.40      2154\n",
      "           3       0.05      0.52      0.09       160\n",
      "\n",
      "    accuracy                           0.46      8541\n",
      "   macro avg       0.38      0.46      0.35      8541\n",
      "weighted avg       0.66      0.46      0.51      8541\n",
      "\n",
      "EPOCH  35 : train loss 0.860, val loss 0.998, val accuracy 0.506, and val rmse 0.834\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.53      0.35       521\n",
      "           1       0.81      0.50      0.62      5706\n",
      "           2       0.38      0.53      0.44      2154\n",
      "           3       0.07      0.36      0.11       160\n",
      "\n",
      "    accuracy                           0.51      8541\n",
      "   macro avg       0.38      0.48      0.38      8541\n",
      "weighted avg       0.65      0.51      0.55      8541\n",
      "\n",
      "EPOCH  40 : train loss 0.841, val loss 1.102, val accuracy 0.453, and val rmse 0.923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.56      0.35       521\n",
      "           1       0.82      0.42      0.55      5706\n",
      "           2       0.35      0.52      0.42      2154\n",
      "           3       0.05      0.40      0.09       160\n",
      "\n",
      "    accuracy                           0.45      8541\n",
      "   macro avg       0.37      0.47      0.35      8541\n",
      "weighted avg       0.65      0.45      0.50      8541\n",
      "\n",
      "EPOCH  45 : train loss 0.799, val loss 1.088, val accuracy 0.468, and val rmse 0.883\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.54      0.37       521\n",
      "           1       0.83      0.42      0.56      5706\n",
      "           2       0.35      0.58      0.44      2154\n",
      "           3       0.06      0.39      0.10       160\n",
      "\n",
      "    accuracy                           0.47      8541\n",
      "   macro avg       0.38      0.48      0.37      8541\n",
      "weighted avg       0.66      0.47      0.51      8541\n",
      "\n",
      "EPOCH  50 : train loss 0.779, val loss 1.015, val accuracy 0.509, and val rmse 0.827\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.51      0.37       521\n",
      "           1       0.82      0.48      0.61      5706\n",
      "           2       0.37      0.59      0.45      2154\n",
      "           3       0.07      0.35      0.11       160\n",
      "\n",
      "    accuracy                           0.51      8541\n",
      "   macro avg       0.39      0.48      0.39      8541\n",
      "weighted avg       0.66      0.51      0.55      8541\n",
      "\n",
      "EPOCH  55 : train loss 0.751, val loss 1.057, val accuracy 0.488, and val rmse 0.849\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.53      0.37       521\n",
      "           1       0.82      0.44      0.57      5706\n",
      "           2       0.36      0.62      0.46      2154\n",
      "           3       0.06      0.31      0.10       160\n",
      "\n",
      "    accuracy                           0.49      8541\n",
      "   macro avg       0.38      0.48      0.37      8541\n",
      "weighted avg       0.66      0.49      0.52      8541\n",
      "\n",
      "EPOCH  60 : train loss 0.738, val loss 1.134, val accuracy 0.466, and val rmse 0.876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.61      0.34       521\n",
      "           1       0.83      0.41      0.55      5706\n",
      "           2       0.37      0.58      0.45      2154\n",
      "           3       0.06      0.36      0.10       160\n",
      "\n",
      "    accuracy                           0.47      8541\n",
      "   macro avg       0.37      0.49      0.36      8541\n",
      "weighted avg       0.66      0.47      0.51      8541\n",
      "\n",
      "EPOCH  65 : train loss 0.719, val loss 1.026, val accuracy 0.513, and val rmse 0.807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.57      0.34       521\n",
      "           1       0.82      0.48      0.60      5706\n",
      "           2       0.39      0.61      0.48      2154\n",
      "           3       0.08      0.31      0.13       160\n",
      "\n",
      "    accuracy                           0.51      8541\n",
      "   macro avg       0.38      0.49      0.39      8541\n",
      "weighted avg       0.66      0.51      0.55      8541\n",
      "\n",
      "EPOCH  70 : train loss 0.699, val loss 0.986, val accuracy 0.536, and val rmse 0.779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.54      0.38       521\n",
      "           1       0.82      0.51      0.63      5706\n",
      "           2       0.39      0.63      0.48      2154\n",
      "           3       0.07      0.26      0.11       160\n",
      "\n",
      "    accuracy                           0.54      8541\n",
      "   macro avg       0.39      0.48      0.40      8541\n",
      "weighted avg       0.66      0.54      0.57      8541\n",
      "\n",
      "EPOCH  75 : train loss 0.700, val loss 0.986, val accuracy 0.537, and val rmse 0.772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.57      0.34       521\n",
      "           1       0.80      0.52      0.63      5706\n",
      "           2       0.41      0.59      0.49      2154\n",
      "           3       0.08      0.25      0.12       160\n",
      "\n",
      "    accuracy                           0.54      8541\n",
      "   macro avg       0.38      0.48      0.39      8541\n",
      "weighted avg       0.65      0.54      0.57      8541\n",
      "\n",
      "EPOCH  80 : train loss 0.698, val loss 1.030, val accuracy 0.511, and val rmse 0.800\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.62      0.33       521\n",
      "           1       0.81      0.47      0.60      5706\n",
      "           2       0.40      0.60      0.48      2154\n",
      "           3       0.08      0.29      0.13       160\n",
      "\n",
      "    accuracy                           0.51      8541\n",
      "   macro avg       0.38      0.50      0.38      8541\n",
      "weighted avg       0.66      0.51      0.54      8541\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  85 : train loss 0.666, val loss 1.025, val accuracy 0.528, and val rmse 0.793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.59      0.36       521\n",
      "           1       0.81      0.51      0.62      5706\n",
      "           2       0.40      0.59      0.48      2154\n",
      "           3       0.08      0.31      0.12       160\n",
      "\n",
      "    accuracy                           0.53      8541\n",
      "   macro avg       0.39      0.50      0.40      8541\n",
      "weighted avg       0.66      0.53      0.56      8541\n",
      "\n",
      "EPOCH  90 : train loss 0.654, val loss 1.080, val accuracy 0.494, and val rmse 0.826\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.60      0.35       521\n",
      "           1       0.83      0.43      0.57      5706\n",
      "           2       0.39      0.65      0.48      2154\n",
      "           3       0.07      0.31      0.11       160\n",
      "\n",
      "    accuracy                           0.49      8541\n",
      "   macro avg       0.38      0.50      0.38      8541\n",
      "weighted avg       0.67      0.49      0.53      8541\n",
      "\n",
      "EPOCH  95 : train loss 0.646, val loss 1.009, val accuracy 0.534, and val rmse 0.773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.60      0.34       521\n",
      "           1       0.81      0.51      0.62      5706\n",
      "           2       0.41      0.62      0.50      2154\n",
      "           3       0.09      0.26      0.13       160\n",
      "\n",
      "    accuracy                           0.53      8541\n",
      "   macro avg       0.39      0.49      0.40      8541\n",
      "weighted avg       0.66      0.53      0.56      8541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM (content+text) (num_layers=1), hidden_dim=100 GloVe embeddings emb_size=100, no stop words (train + test), N=800, own sampler (1/class_3) (batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0 : train loss 1.321, val loss 1.257, val accuracy 0.490, and val rmse 0.822\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.05      0.08       521\n",
      "           1       0.75      0.48      0.59      5706\n",
      "           2       0.32      0.65      0.43      2154\n",
      "           3       0.05      0.12      0.07       160\n",
      "\n",
      "    accuracy                           0.49      8541\n",
      "   macro avg       0.34      0.32      0.29      8541\n",
      "weighted avg       0.59      0.49      0.50      8541\n",
      "\n",
      "EPOCH  5 : train loss 1.106, val loss 1.140, val accuracy 0.418, and val rmse 1.061\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.46      0.28       521\n",
      "           1       0.80      0.46      0.58      5706\n",
      "           2       0.34      0.30      0.32      2154\n",
      "           3       0.04      0.54      0.07       160\n",
      "\n",
      "    accuracy                           0.42      8541\n",
      "   macro avg       0.35      0.44      0.31      8541\n",
      "weighted avg       0.63      0.42      0.49      8541\n",
      "\n",
      "EPOCH  10 : train loss 1.012, val loss 1.056, val accuracy 0.463, and val rmse 0.924\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.56      0.28       521\n",
      "           1       0.80      0.47      0.59      5706\n",
      "           2       0.38      0.43      0.40      2154\n",
      "           3       0.05      0.35      0.08       160\n",
      "\n",
      "    accuracy                           0.46      8541\n",
      "   macro avg       0.35      0.45      0.34      8541\n",
      "weighted avg       0.64      0.46      0.52      8541\n",
      "\n",
      "EPOCH  15 : train loss 0.904, val loss 1.020, val accuracy 0.488, and val rmse 0.876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.55      0.31       521\n",
      "           1       0.81      0.48      0.60      5706\n",
      "           2       0.38      0.51      0.44      2154\n",
      "           3       0.06      0.34      0.09       160\n",
      "\n",
      "    accuracy                           0.49      8541\n",
      "   macro avg       0.37      0.47      0.36      8541\n",
      "weighted avg       0.65      0.49      0.53      8541\n",
      "\n",
      "EPOCH  20 : train loss 0.801, val loss 1.099, val accuracy 0.459, and val rmse 0.922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.54      0.35       521\n",
      "           1       0.81      0.43      0.56      5706\n",
      "           2       0.36      0.52      0.43      2154\n",
      "           3       0.05      0.41      0.09       160\n",
      "\n",
      "    accuracy                           0.46      8541\n",
      "   macro avg       0.37      0.47      0.36      8541\n",
      "weighted avg       0.65      0.46      0.51      8541\n",
      "\n",
      "EPOCH  25 : train loss 0.717, val loss 0.980, val accuracy 0.537, and val rmse 0.801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.49      0.38       521\n",
      "           1       0.81      0.54      0.65      5706\n",
      "           2       0.39      0.57      0.46      2154\n",
      "           3       0.05      0.29      0.09       160\n",
      "\n",
      "    accuracy                           0.54      8541\n",
      "   macro avg       0.39      0.47      0.39      8541\n",
      "weighted avg       0.66      0.54      0.57      8541\n",
      "\n",
      "EPOCH  30 : train loss 0.639, val loss 1.060, val accuracy 0.497, and val rmse 0.823\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.59      0.35       521\n",
      "           1       0.83      0.44      0.58      5706\n",
      "           2       0.38      0.63      0.48      2154\n",
      "           3       0.06      0.26      0.09       160\n",
      "\n",
      "    accuracy                           0.50      8541\n",
      "   macro avg       0.38      0.48      0.38      8541\n",
      "weighted avg       0.67      0.50      0.53      8541\n",
      "\n",
      "EPOCH  35 : train loss 0.620, val loss 0.996, val accuracy 0.550, and val rmse 0.778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.52      0.41       521\n",
      "           1       0.82      0.53      0.65      5706\n",
      "           2       0.40      0.63      0.49      2154\n",
      "           3       0.06      0.24      0.09       160\n",
      "\n",
      "    accuracy                           0.55      8541\n",
      "   macro avg       0.40      0.48      0.41      8541\n",
      "weighted avg       0.67      0.55      0.58      8541\n",
      "\n",
      "EPOCH  40 : train loss 0.585, val loss 0.950, val accuracy 0.579, and val rmse 0.730\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.60      0.37       521\n",
      "           1       0.80      0.59      0.68      5706\n",
      "           2       0.44      0.57      0.50      2154\n",
      "           3       0.08      0.21      0.11       160\n",
      "\n",
      "    accuracy                           0.58      8541\n",
      "   macro avg       0.40      0.49      0.42      8541\n",
      "weighted avg       0.67      0.58      0.61      8541\n",
      "\n",
      "EPOCH  45 : train loss 0.541, val loss 0.990, val accuracy 0.571, and val rmse 0.732\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.64      0.36       521\n",
      "           1       0.81      0.57      0.67      5706\n",
      "           2       0.45      0.60      0.52      2154\n",
      "           3       0.08      0.18      0.11       160\n",
      "\n",
      "    accuracy                           0.57      8541\n",
      "   macro avg       0.40      0.50      0.41      8541\n",
      "weighted avg       0.67      0.57      0.60      8541\n",
      "\n",
      "EPOCH  50 : train loss 0.533, val loss 0.964, val accuracy 0.591, and val rmse 0.721\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.57      0.40       521\n",
      "           1       0.81      0.60      0.69      5706\n",
      "           2       0.45      0.59      0.51      2154\n",
      "           3       0.07      0.21      0.10       160\n",
      "\n",
      "    accuracy                           0.59      8541\n",
      "   macro avg       0.41      0.49      0.43      8541\n",
      "weighted avg       0.68      0.59      0.62      8541\n",
      "\n",
      "EPOCH  55 : train loss 0.501, val loss 0.993, val accuracy 0.570, and val rmse 0.730\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.56      0.39       521\n",
      "           1       0.83      0.54      0.66      5706\n",
      "           2       0.43      0.68      0.53      2154\n",
      "           3       0.06      0.16      0.09       160\n",
      "\n",
      "    accuracy                           0.57      8541\n",
      "   macro avg       0.40      0.49      0.41      8541\n",
      "weighted avg       0.68      0.57      0.60      8541\n",
      "\n",
      "EPOCH  60 : train loss 0.469, val loss 0.930, val accuracy 0.624, and val rmse 0.673\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.49      0.41       521\n",
      "           1       0.81      0.65      0.72      5706\n",
      "           2       0.47      0.62      0.53      2154\n",
      "           3       0.09      0.19      0.12       160\n",
      "\n",
      "    accuracy                           0.62      8541\n",
      "   macro avg       0.43      0.49      0.44      8541\n",
      "weighted avg       0.68      0.62      0.64      8541\n",
      "\n",
      "EPOCH  65 : train loss 0.453, val loss 0.962, val accuracy 0.612, and val rmse 0.681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.56      0.41       521\n",
      "           1       0.81      0.62      0.71      5706\n",
      "           2       0.46      0.63      0.53      2154\n",
      "           3       0.09      0.18      0.12       160\n",
      "\n",
      "    accuracy                           0.61      8541\n",
      "   macro avg       0.42      0.50      0.44      8541\n",
      "weighted avg       0.68      0.61      0.63      8541\n",
      "\n",
      "EPOCH  70 : train loss 0.441, val loss 0.967, val accuracy 0.610, and val rmse 0.677\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.53      0.40       521\n",
      "           1       0.81      0.61      0.70      5706\n",
      "           2       0.45      0.66      0.54      2154\n",
      "           3       0.08      0.14      0.10       160\n",
      "\n",
      "    accuracy                           0.61      8541\n",
      "   macro avg       0.42      0.48      0.43      8541\n",
      "weighted avg       0.68      0.61      0.63      8541\n",
      "\n",
      "EPOCH  75 : train loss 0.421, val loss 1.003, val accuracy 0.600, and val rmse 0.705\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.50      0.40       521\n",
      "           1       0.82      0.61      0.70      5706\n",
      "           2       0.45      0.64      0.52      2154\n",
      "           3       0.06      0.19      0.10       160\n",
      "\n",
      "    accuracy                           0.60      8541\n",
      "   macro avg       0.42      0.48      0.43      8541\n",
      "weighted avg       0.68      0.60      0.62      8541\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  80 : train loss 0.419, val loss 0.978, val accuracy 0.632, and val rmse 0.668\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.50      0.41       521\n",
      "           1       0.81      0.66      0.73      5706\n",
      "           2       0.48      0.61      0.54      2154\n",
      "           3       0.08      0.16      0.11       160\n",
      "\n",
      "    accuracy                           0.63      8541\n",
      "   macro avg       0.43      0.49      0.44      8541\n",
      "weighted avg       0.68      0.63      0.65      8541\n",
      "\n",
      "EPOCH  85 : train loss 0.404, val loss 1.027, val accuracy 0.609, and val rmse 0.695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.47      0.40       521\n",
      "           1       0.82      0.62      0.71      5706\n",
      "           2       0.45      0.64      0.53      2154\n",
      "           3       0.07      0.21      0.11       160\n",
      "\n",
      "    accuracy                           0.61      8541\n",
      "   macro avg       0.42      0.49      0.44      8541\n",
      "weighted avg       0.69      0.61      0.63      8541\n",
      "\n",
      "EPOCH  90 : train loss 0.395, val loss 1.020, val accuracy 0.606, and val rmse 0.682\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.48      0.41       521\n",
      "           1       0.83      0.59      0.69      5706\n",
      "           2       0.44      0.71      0.54      2154\n",
      "           3       0.08      0.15      0.10       160\n",
      "\n",
      "    accuracy                           0.61      8541\n",
      "   macro avg       0.43      0.48      0.44      8541\n",
      "weighted avg       0.69      0.61      0.63      8541\n",
      "\n",
      "EPOCH  95 : train loss 0.373, val loss 1.008, val accuracy 0.637, and val rmse 0.655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.48      0.39       521\n",
      "           1       0.81      0.67      0.73      5706\n",
      "           2       0.48      0.62      0.54      2154\n",
      "           3       0.08      0.16      0.11       160\n",
      "\n",
      "    accuracy                           0.64      8541\n",
      "   macro avg       0.43      0.48      0.45      8541\n",
      "weighted avg       0.69      0.64      0.65      8541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM (content+title) (num_layers=1), hidden_dim=75 GloVe embeddings emb_size=200, no stop words (train + test), N=600, own sampler  1.5 *(1/class_3) (batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0 : train loss 1.226, val loss 1.182, val accuracy 0.253, and val rmse 1.416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.40      0.25       521\n",
      "           1       0.77      0.31      0.45      5706\n",
      "           2       0.42      0.01      0.01      2154\n",
      "           3       0.03      0.88      0.05       160\n",
      "\n",
      "    accuracy                           0.25      8541\n",
      "   macro avg       0.35      0.40      0.19      8541\n",
      "weighted avg       0.63      0.25      0.32      8541\n",
      "\n",
      "EPOCH  5 : train loss 0.876, val loss 1.232, val accuracy 0.474, and val rmse 0.955\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.49      0.33       521\n",
      "           1       0.80      0.51      0.62      5706\n",
      "           2       0.38      0.37      0.37      2154\n",
      "           3       0.05      0.50      0.08       160\n",
      "\n",
      "    accuracy                           0.47      8541\n",
      "   macro avg       0.37      0.47      0.35      8541\n",
      "weighted avg       0.64      0.47      0.53      8541\n",
      "\n",
      "EPOCH  10 : train loss 0.656, val loss 1.683, val accuracy 0.547, and val rmse 0.791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.50      0.38       521\n",
      "           1       0.81      0.56      0.66      5706\n",
      "           2       0.40      0.56      0.47      2154\n",
      "           3       0.06      0.29      0.09       160\n",
      "\n",
      "    accuracy                           0.55      8541\n",
      "   macro avg       0.40      0.48      0.40      8541\n",
      "weighted avg       0.66      0.55      0.58      8541\n",
      "\n",
      "EPOCH  15 : train loss 0.546, val loss 1.914, val accuracy 0.576, and val rmse 0.740\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.57      0.37       521\n",
      "           1       0.80      0.59      0.68      5706\n",
      "           2       0.45      0.56      0.50      2154\n",
      "           3       0.07      0.23      0.10       160\n",
      "\n",
      "    accuracy                           0.58      8541\n",
      "   macro avg       0.40      0.49      0.41      8541\n",
      "weighted avg       0.67      0.58      0.61      8541\n",
      "\n",
      "EPOCH  20 : train loss 0.469, val loss 2.078, val accuracy 0.591, and val rmse 0.723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.50      0.40       521\n",
      "           1       0.82      0.59      0.69      5706\n",
      "           2       0.44      0.63      0.52      2154\n",
      "           3       0.07      0.22      0.10       160\n",
      "\n",
      "    accuracy                           0.59      8541\n",
      "   macro avg       0.41      0.49      0.43      8541\n",
      "weighted avg       0.68      0.59      0.62      8541\n",
      "\n",
      "EPOCH  25 : train loss 0.410, val loss 2.331, val accuracy 0.602, and val rmse 0.717\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.55      0.38       521\n",
      "           1       0.82      0.61      0.70      5706\n",
      "           2       0.48      0.61      0.54      2154\n",
      "           3       0.06      0.20      0.09       160\n",
      "\n",
      "    accuracy                           0.60      8541\n",
      "   macro avg       0.41      0.49      0.43      8541\n",
      "weighted avg       0.69      0.60      0.63      8541\n",
      "\n",
      "EPOCH  30 : train loss 0.394, val loss 2.631, val accuracy 0.613, and val rmse 0.679\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.48      0.39       521\n",
      "           1       0.82      0.62      0.71      5706\n",
      "           2       0.46      0.66      0.54      2154\n",
      "           3       0.07      0.15      0.10       160\n",
      "\n",
      "    accuracy                           0.61      8541\n",
      "   macro avg       0.42      0.48      0.43      8541\n",
      "weighted avg       0.68      0.61      0.63      8541\n",
      "\n",
      "EPOCH  35 : train loss 0.353, val loss 2.803, val accuracy 0.635, and val rmse 0.661\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.47      0.39       521\n",
      "           1       0.81      0.67      0.73      5706\n",
      "           2       0.49      0.62      0.55      2154\n",
      "           3       0.08      0.18      0.11       160\n",
      "\n",
      "    accuracy                           0.64      8541\n",
      "   macro avg       0.43      0.49      0.45      8541\n",
      "weighted avg       0.69      0.64      0.65      8541\n",
      "\n",
      "EPOCH  40 : train loss 0.339, val loss 2.633, val accuracy 0.621, and val rmse 0.687\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.45      0.39       521\n",
      "           1       0.82      0.65      0.72      5706\n",
      "           2       0.47      0.63      0.54      2154\n",
      "           3       0.06      0.19      0.10       160\n",
      "\n",
      "    accuracy                           0.62      8541\n",
      "   macro avg       0.42      0.48      0.44      8541\n",
      "weighted avg       0.69      0.62      0.64      8541\n",
      "\n",
      "EPOCH  45 : train loss 0.307, val loss 3.006, val accuracy 0.623, and val rmse 0.670\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.45      0.39       521\n",
      "           1       0.82      0.64      0.72      5706\n",
      "           2       0.47      0.66      0.55      2154\n",
      "           3       0.07      0.16      0.10       160\n",
      "\n",
      "    accuracy                           0.62      8541\n",
      "   macro avg       0.42      0.48      0.44      8541\n",
      "weighted avg       0.69      0.62      0.64      8541\n",
      "\n",
      "EPOCH  50 : train loss 0.303, val loss 2.801, val accuracy 0.643, and val rmse 0.665\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.43      0.39       521\n",
      "           1       0.81      0.69      0.75      5706\n",
      "           2       0.49      0.59      0.54      2154\n",
      "           3       0.06      0.17      0.09       160\n",
      "\n",
      "    accuracy                           0.64      8541\n",
      "   macro avg       0.43      0.47      0.44      8541\n",
      "weighted avg       0.69      0.64      0.66      8541\n",
      "\n",
      "EPOCH  55 : train loss 0.287, val loss 2.924, val accuracy 0.632, and val rmse 0.671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.45      0.39       521\n",
      "           1       0.82      0.66      0.73      5706\n",
      "           2       0.48      0.63      0.54      2154\n",
      "           3       0.07      0.17      0.10       160\n",
      "\n",
      "    accuracy                           0.63      8541\n",
      "   macro avg       0.43      0.48      0.44      8541\n",
      "weighted avg       0.69      0.63      0.65      8541\n",
      "\n",
      "EPOCH  60 : train loss 0.281, val loss 3.042, val accuracy 0.637, and val rmse 0.659\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.46      0.39       521\n",
      "           1       0.81      0.68      0.74      5706\n",
      "           2       0.49      0.61      0.54      2154\n",
      "           3       0.07      0.17      0.10       160\n",
      "\n",
      "    accuracy                           0.64      8541\n",
      "   macro avg       0.43      0.48      0.44      8541\n",
      "weighted avg       0.69      0.64      0.66      8541\n",
      "\n",
      "EPOCH  65 : train loss 0.275, val loss 3.283, val accuracy 0.626, and val rmse 0.663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.45      0.38       521\n",
      "           1       0.82      0.64      0.72      5706\n",
      "           2       0.47      0.66      0.55      2154\n",
      "           3       0.07      0.15      0.10       160\n",
      "\n",
      "    accuracy                           0.63      8541\n",
      "   macro avg       0.42      0.48      0.44      8541\n",
      "weighted avg       0.69      0.63      0.64      8541\n",
      "\n",
      "EPOCH  70 : train loss 0.263, val loss 3.204, val accuracy 0.630, and val rmse 0.663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.46      0.39       521\n",
      "           1       0.82      0.66      0.73      5706\n",
      "           2       0.48      0.64      0.55      2154\n",
      "           3       0.07      0.16      0.10       160\n",
      "\n",
      "    accuracy                           0.63      8541\n",
      "   macro avg       0.43      0.48      0.44      8541\n",
      "weighted avg       0.69      0.63      0.65      8541\n",
      "\n",
      "EPOCH  75 : train loss 0.250, val loss 3.588, val accuracy 0.636, and val rmse 0.652\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.45      0.40       521\n",
      "           1       0.82      0.66      0.73      5706\n",
      "           2       0.48      0.66      0.55      2154\n",
      "           3       0.07      0.14      0.09       160\n",
      "\n",
      "    accuracy                           0.64      8541\n",
      "   macro avg       0.43      0.48      0.44      8541\n",
      "weighted avg       0.69      0.64      0.65      8541\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  80 : train loss 0.252, val loss 3.432, val accuracy 0.638, and val rmse 0.652\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.45      0.39       521\n",
      "           1       0.81      0.67      0.74      5706\n",
      "           2       0.49      0.63      0.55      2154\n",
      "           3       0.06      0.12      0.08       160\n",
      "\n",
      "    accuracy                           0.64      8541\n",
      "   macro avg       0.42      0.47      0.44      8541\n",
      "weighted avg       0.69      0.64      0.65      8541\n",
      "\n",
      "EPOCH  85 : train loss 0.254, val loss 3.294, val accuracy 0.643, and val rmse 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.43      0.39       521\n",
      "           1       0.81      0.69      0.74      5706\n",
      "           2       0.49      0.61      0.54      2154\n",
      "           3       0.07      0.16      0.10       160\n",
      "\n",
      "    accuracy                           0.64      8541\n",
      "   macro avg       0.43      0.47      0.44      8541\n",
      "weighted avg       0.69      0.64      0.66      8541\n",
      "\n",
      "EPOCH  90 : train loss 0.246, val loss 3.376, val accuracy 0.641, and val rmse 0.655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.44      0.38       521\n",
      "           1       0.81      0.68      0.74      5706\n",
      "           2       0.49      0.61      0.54      2154\n",
      "           3       0.08      0.16      0.10       160\n",
      "\n",
      "    accuracy                           0.64      8541\n",
      "   macro avg       0.43      0.47      0.44      8541\n",
      "weighted avg       0.68      0.64      0.66      8541\n",
      "\n",
      "EPOCH  95 : train loss 0.227, val loss 3.576, val accuracy 0.636, and val rmse 0.655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.43      0.37       521\n",
      "           1       0.80      0.68      0.73      5706\n",
      "           2       0.48      0.61      0.54      2154\n",
      "           3       0.08      0.15      0.10       160\n",
      "\n",
      "    accuracy                           0.64      8541\n",
      "   macro avg       0.42      0.47      0.44      8541\n",
      "weighted avg       0.68      0.64      0.65      8541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM (content) (num_layers=2), hidden_dim=50 GloVe embeddings emb_size=200, no stop words (train + test), N=600, (batch_size=64) w/ random synonym insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0 : train loss 1.094, val loss 1.147, val accuracy 0.481, and val rmse 1.035\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.69      0.66      2560\n",
      "           1       0.53      0.28      0.36      2560\n",
      "           2       0.36      0.49      0.42      2560\n",
      "           3       0.46      0.46      0.46      2560\n",
      "\n",
      "    accuracy                           0.48     10240\n",
      "   macro avg       0.49      0.48      0.47     10240\n",
      "weighted avg       0.49      0.48      0.47     10240\n",
      "\n",
      "EPOCH  5 : train loss 0.492, val loss 1.962, val accuracy 0.506, and val rmse 0.883\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.65      0.69      2560\n",
      "           1       0.44      0.59      0.50      2560\n",
      "           2       0.39      0.57      0.47      2560\n",
      "           3       0.65      0.21      0.32      2560\n",
      "\n",
      "    accuracy                           0.51     10240\n",
      "   macro avg       0.56      0.51      0.50     10240\n",
      "weighted avg       0.56      0.51      0.50     10240\n",
      "\n",
      "EPOCH  10 : train loss 0.368, val loss 2.359, val accuracy 0.507, and val rmse 0.858\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.62      0.68      2560\n",
      "           1       0.47      0.57      0.52      2560\n",
      "           2       0.39      0.66      0.49      2560\n",
      "           3       0.63      0.19      0.29      2560\n",
      "\n",
      "    accuracy                           0.51     10240\n",
      "   macro avg       0.57      0.51      0.49     10240\n",
      "weighted avg       0.57      0.51      0.49     10240\n",
      "\n",
      "EPOCH  15 : train loss 0.295, val loss 2.391, val accuracy 0.512, and val rmse 0.835\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.59      0.68      2560\n",
      "           1       0.48      0.56      0.51      2560\n",
      "           2       0.39      0.67      0.49      2560\n",
      "           3       0.63      0.23      0.33      2560\n",
      "\n",
      "    accuracy                           0.51     10240\n",
      "   macro avg       0.57      0.51      0.50     10240\n",
      "weighted avg       0.57      0.51      0.50     10240\n",
      "\n",
      "EPOCH  20 : train loss 0.248, val loss 2.722, val accuracy 0.506, and val rmse 0.859\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.57      0.66      2560\n",
      "           1       0.44      0.72      0.55      2560\n",
      "           2       0.40      0.54      0.46      2560\n",
      "           3       0.65      0.20      0.31      2560\n",
      "\n",
      "    accuracy                           0.51     10240\n",
      "   macro avg       0.57      0.51      0.49     10240\n",
      "weighted avg       0.57      0.51      0.49     10240\n",
      "\n",
      "EPOCH  25 : train loss 0.218, val loss 2.833, val accuracy 0.504, and val rmse 0.846\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.51      0.63      2560\n",
      "           1       0.46      0.66      0.54      2560\n",
      "           2       0.40      0.65      0.50      2560\n",
      "           3       0.62      0.20      0.30      2560\n",
      "\n",
      "    accuracy                           0.50     10240\n",
      "   macro avg       0.58      0.50      0.49     10240\n",
      "weighted avg       0.58      0.50      0.49     10240\n",
      "\n",
      "EPOCH  30 : train loss 0.194, val loss 2.879, val accuracy 0.507, and val rmse 0.868\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.56      0.66      2560\n",
      "           1       0.45      0.68      0.54      2560\n",
      "           2       0.40      0.60      0.48      2560\n",
      "           3       0.61      0.19      0.29      2560\n",
      "\n",
      "    accuracy                           0.51     10240\n",
      "   macro avg       0.57      0.51      0.49     10240\n",
      "weighted avg       0.57      0.51      0.49     10240\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-b6bbceada84a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-26-a41a3ed29eee>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;31m#loss = criterion(y_pred, y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0msum_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM (content + title) (num_layers=2), hidden_dim=50 GloVe embeddings emb_size=50, no stop words (train + test), N=600, (batch_size=64) w/ random synonym insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0 : train loss 1.194, val loss 1.188, val accuracy 0.454, and val rmse 1.197\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.74      0.63      2560\n",
      "           1       0.51      0.18      0.26      2560\n",
      "           2       0.32      0.16      0.21      2560\n",
      "           3       0.41      0.74      0.53      2560\n",
      "\n",
      "    accuracy                           0.45     10240\n",
      "   macro avg       0.45      0.45      0.41     10240\n",
      "weighted avg       0.45      0.45      0.41     10240\n",
      "\n",
      "EPOCH  5 : train loss 0.694, val loss 1.626, val accuracy 0.488, and val rmse 0.998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.69      0.66      2560\n",
      "           1       0.42      0.50      0.46      2560\n",
      "           2       0.40      0.51      0.45      2560\n",
      "           3       0.59      0.25      0.35      2560\n",
      "\n",
      "    accuracy                           0.49     10240\n",
      "   macro avg       0.51      0.49      0.48     10240\n",
      "weighted avg       0.51      0.49      0.48     10240\n",
      "\n",
      "EPOCH  10 : train loss 0.541, val loss 1.932, val accuracy 0.485, and val rmse 0.920\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.58      0.64      2560\n",
      "           1       0.44      0.51      0.47      2560\n",
      "           2       0.39      0.66      0.49      2560\n",
      "           3       0.57      0.18      0.28      2560\n",
      "\n",
      "    accuracy                           0.49     10240\n",
      "   macro avg       0.53      0.49      0.47     10240\n",
      "weighted avg       0.53      0.49      0.47     10240\n",
      "\n",
      "EPOCH  15 : train loss 0.450, val loss 2.319, val accuracy 0.475, and val rmse 0.913\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.53      0.62      2560\n",
      "           1       0.40      0.64      0.49      2560\n",
      "           2       0.40      0.58      0.47      2560\n",
      "           3       0.62      0.15      0.25      2560\n",
      "\n",
      "    accuracy                           0.47     10240\n",
      "   macro avg       0.55      0.47      0.46     10240\n",
      "weighted avg       0.55      0.47      0.46     10240\n",
      "\n",
      "EPOCH  20 : train loss 0.402, val loss 2.298, val accuracy 0.490, and val rmse 0.890\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.56      0.64      2560\n",
      "           1       0.43      0.57      0.49      2560\n",
      "           2       0.39      0.63      0.48      2560\n",
      "           3       0.59      0.20      0.30      2560\n",
      "\n",
      "    accuracy                           0.49     10240\n",
      "   macro avg       0.54      0.49      0.48     10240\n",
      "weighted avg       0.54      0.49      0.48     10240\n",
      "\n",
      "EPOCH  25 : train loss 0.363, val loss 2.467, val accuracy 0.498, and val rmse 0.893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.60      0.66      2560\n",
      "           1       0.45      0.56      0.50      2560\n",
      "           2       0.40      0.66      0.50      2560\n",
      "           3       0.59      0.17      0.27      2560\n",
      "\n",
      "    accuracy                           0.50     10240\n",
      "   macro avg       0.55      0.50      0.48     10240\n",
      "weighted avg       0.55      0.50      0.48     10240\n",
      "\n",
      "EPOCH  30 : train loss 0.331, val loss 2.503, val accuracy 0.493, and val rmse 0.910\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.56      0.64      2560\n",
      "           1       0.43      0.61      0.50      2560\n",
      "           2       0.40      0.61      0.48      2560\n",
      "           3       0.61      0.20      0.30      2560\n",
      "\n",
      "    accuracy                           0.49     10240\n",
      "   macro avg       0.55      0.49      0.48     10240\n",
      "weighted avg       0.55      0.49      0.48     10240\n",
      "\n",
      "EPOCH  35 : train loss 0.309, val loss 2.578, val accuracy 0.491, and val rmse 0.881\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.54      0.64      2560\n",
      "           1       0.43      0.59      0.50      2560\n",
      "           2       0.40      0.64      0.49      2560\n",
      "           3       0.59      0.20      0.29      2560\n",
      "\n",
      "    accuracy                           0.49     10240\n",
      "   macro avg       0.55      0.49      0.48     10240\n",
      "weighted avg       0.55      0.49      0.48     10240\n",
      "\n",
      "EPOCH  40 : train loss 0.286, val loss 2.860, val accuracy 0.473, and val rmse 0.903\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.49      0.60      2560\n",
      "           1       0.40      0.64      0.50      2560\n",
      "           2       0.40      0.60      0.48      2560\n",
      "           3       0.59      0.16      0.25      2560\n",
      "\n",
      "    accuracy                           0.47     10240\n",
      "   macro avg       0.54      0.47      0.46     10240\n",
      "weighted avg       0.54      0.47      0.46     10240\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-b6bbceada84a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-23-a41a3ed29eee>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0msum_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_rmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m5\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"EPOCH \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\": train loss %.3f, val loss %.3f, val accuracy %.3f, and val rmse %.3f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msum_loss\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_rmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-a41a3ed29eee>\u001b[0m in \u001b[0;36mvalidation_metrics\u001b[1;34m(model, valid_dl)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[1;31m#loss = criterion(y_hat, y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-eac30f823119>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, l)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mht\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mct\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mht\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 570\u001b[1;33m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    571\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM (content + title) (num_layers=2), hidden_dim=50 GloVe embeddings emb_size=50, no stop words (train + test), N=800, (batch_size=128) w/ random synonym insertion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0 : train loss 1.219, val loss 1.187, val accuracy 0.433, and val rmse 1.203\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.55      0.57      2560\n",
      "           1       0.39      0.39      0.39      2560\n",
      "           2       0.31      0.10      0.15      2560\n",
      "           3       0.39      0.70      0.50      2560\n",
      "\n",
      "    accuracy                           0.43     10240\n",
      "   macro avg       0.42      0.43      0.40     10240\n",
      "weighted avg       0.42      0.43      0.40     10240\n",
      "\n",
      "EPOCH  5 : train loss 0.751, val loss 1.385, val accuracy 0.511, and val rmse 0.941\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.72      0.69      2560\n",
      "           1       0.46      0.40      0.43      2560\n",
      "           2       0.39      0.57      0.46      2560\n",
      "           3       0.60      0.34      0.44      2560\n",
      "\n",
      "    accuracy                           0.51     10240\n",
      "   macro avg       0.53      0.51      0.51     10240\n",
      "weighted avg       0.53      0.51      0.51     10240\n",
      "\n",
      "EPOCH  10 : train loss 0.579, val loss 1.634, val accuracy 0.505, and val rmse 0.884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.68      0.71      2560\n",
      "           1       0.46      0.45      0.45      2560\n",
      "           2       0.39      0.67      0.49      2560\n",
      "           3       0.59      0.22      0.32      2560\n",
      "\n",
      "    accuracy                           0.50     10240\n",
      "   macro avg       0.54      0.50      0.49     10240\n",
      "weighted avg       0.54      0.50      0.49     10240\n",
      "\n",
      "EPOCH  15 : train loss 0.495, val loss 1.896, val accuracy 0.499, and val rmse 0.890\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.62      0.68      2560\n",
      "           1       0.44      0.52      0.47      2560\n",
      "           2       0.39      0.65      0.49      2560\n",
      "           3       0.60      0.20      0.30      2560\n",
      "\n",
      "    accuracy                           0.50     10240\n",
      "   macro avg       0.55      0.50      0.49     10240\n",
      "weighted avg       0.55      0.50      0.49     10240\n",
      "\n",
      "EPOCH  20 : train loss 0.441, val loss 1.963, val accuracy 0.512, and val rmse 0.889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.66      0.70      2560\n",
      "           1       0.44      0.56      0.49      2560\n",
      "           2       0.41      0.61      0.49      2560\n",
      "           3       0.65      0.22      0.32      2560\n",
      "\n",
      "    accuracy                           0.51     10240\n",
      "   macro avg       0.56      0.51      0.50     10240\n",
      "weighted avg       0.56      0.51      0.50     10240\n",
      "\n",
      "EPOCH  25 : train loss 0.399, val loss 2.126, val accuracy 0.497, and val rmse 0.878\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.57      0.66      2560\n",
      "           1       0.43      0.62      0.51      2560\n",
      "           2       0.39      0.58      0.47      2560\n",
      "           3       0.63      0.22      0.32      2560\n",
      "\n",
      "    accuracy                           0.50     10240\n",
      "   macro avg       0.56      0.50      0.49     10240\n",
      "weighted avg       0.56      0.50      0.49     10240\n",
      "\n",
      "EPOCH  30 : train loss 0.369, val loss 2.173, val accuracy 0.498, and val rmse 0.873\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.54      0.64      2560\n",
      "           1       0.43      0.60      0.50      2560\n",
      "           2       0.40      0.63      0.49      2560\n",
      "           3       0.61      0.23      0.33      2560\n",
      "\n",
      "    accuracy                           0.50     10240\n",
      "   macro avg       0.56      0.50      0.49     10240\n",
      "weighted avg       0.56      0.50      0.49     10240\n",
      "\n",
      "EPOCH  35 : train loss 0.345, val loss 2.276, val accuracy 0.510, and val rmse 0.878\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.64      0.69      2560\n",
      "           1       0.46      0.59      0.52      2560\n",
      "           2       0.40      0.63      0.49      2560\n",
      "           3       0.63      0.18      0.28      2560\n",
      "\n",
      "    accuracy                           0.51     10240\n",
      "   macro avg       0.56      0.51      0.49     10240\n",
      "weighted avg       0.56      0.51      0.49     10240\n",
      "\n",
      "EPOCH  40 : train loss 0.325, val loss 2.409, val accuracy 0.493, and val rmse 0.877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.53      0.63      2560\n",
      "           1       0.45      0.59      0.51      2560\n",
      "           2       0.39      0.66      0.49      2560\n",
      "           3       0.62      0.19      0.30      2560\n",
      "\n",
      "    accuracy                           0.49     10240\n",
      "   macro avg       0.56      0.49      0.48     10240\n",
      "weighted avg       0.56      0.49      0.48     10240\n",
      "\n",
      "EPOCH  45 : train loss 0.302, val loss 2.489, val accuracy 0.499, and val rmse 0.877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.55      0.65      2560\n",
      "           1       0.43      0.64      0.52      2560\n",
      "           2       0.40      0.60      0.48      2560\n",
      "           3       0.61      0.21      0.31      2560\n",
      "\n",
      "    accuracy                           0.50     10240\n",
      "   macro avg       0.56      0.50      0.49     10240\n",
      "weighted avg       0.56      0.50      0.49     10240\n",
      "\n",
      "EPOCH  50 : train loss 0.286, val loss 2.607, val accuracy 0.492, and val rmse 0.889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.56      0.65      2560\n",
      "           1       0.44      0.58      0.50      2560\n",
      "           2       0.40      0.66      0.49      2560\n",
      "           3       0.56      0.18      0.27      2560\n",
      "\n",
      "    accuracy                           0.49     10240\n",
      "   macro avg       0.55      0.49      0.48     10240\n",
      "weighted avg       0.55      0.49      0.48     10240\n",
      "\n",
      "EPOCH  55 : train loss 0.278, val loss 2.633, val accuracy 0.496, and val rmse 0.857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.53      0.64      2560\n",
      "           1       0.45      0.60      0.52      2560\n",
      "           2       0.39      0.68      0.50      2560\n",
      "           3       0.59      0.18      0.27      2560\n",
      "\n",
      "    accuracy                           0.50     10240\n",
      "   macro avg       0.56      0.50      0.48     10240\n",
      "weighted avg       0.56      0.50      0.48     10240\n",
      "\n",
      "EPOCH  60 : train loss 0.258, val loss 2.709, val accuracy 0.492, and val rmse 0.894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.53      0.64      2560\n",
      "           1       0.41      0.71      0.52      2560\n",
      "           2       0.41      0.53      0.46      2560\n",
      "           3       0.63      0.20      0.30      2560\n",
      "\n",
      "    accuracy                           0.49     10240\n",
      "   macro avg       0.56      0.49      0.48     10240\n",
      "weighted avg       0.56      0.49      0.48     10240\n",
      "\n",
      "EPOCH  65 : train loss 0.250, val loss 2.841, val accuracy 0.486, and val rmse 0.889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.50      0.62      2560\n",
      "           1       0.42      0.69      0.52      2560\n",
      "           2       0.40      0.57      0.47      2560\n",
      "           3       0.60      0.18      0.28      2560\n",
      "\n",
      "    accuracy                           0.49     10240\n",
      "   macro avg       0.55      0.49      0.47     10240\n",
      "weighted avg       0.55      0.49      0.47     10240\n",
      "\n",
      "EPOCH  70 : train loss 0.246, val loss 2.890, val accuracy 0.490, and val rmse 0.881\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.52      0.63      2560\n",
      "           1       0.42      0.68      0.51      2560\n",
      "           2       0.40      0.58      0.48      2560\n",
      "           3       0.63      0.19      0.29      2560\n",
      "\n",
      "    accuracy                           0.49     10240\n",
      "   macro avg       0.56      0.49      0.48     10240\n",
      "weighted avg       0.56      0.49      0.48     10240\n",
      "\n",
      "EPOCH  75 : train loss 0.236, val loss 2.779, val accuracy 0.489, and val rmse 0.872\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.52      0.63      2560\n",
      "           1       0.43      0.65      0.52      2560\n",
      "           2       0.39      0.60      0.48      2560\n",
      "           3       0.60      0.19      0.29      2560\n",
      "\n",
      "    accuracy                           0.49     10240\n",
      "   macro avg       0.56      0.49      0.48     10240\n",
      "weighted avg       0.56      0.49      0.48     10240\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  80 : train loss 0.227, val loss 2.893, val accuracy 0.491, and val rmse 0.894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.52      0.64      2560\n",
      "           1       0.41      0.69      0.52      2560\n",
      "           2       0.41      0.57      0.48      2560\n",
      "           3       0.59      0.18      0.28      2560\n",
      "\n",
      "    accuracy                           0.49     10240\n",
      "   macro avg       0.56      0.49      0.48     10240\n",
      "weighted avg       0.56      0.49      0.48     10240\n",
      "\n",
      "EPOCH  85 : train loss 0.224, val loss 2.908, val accuracy 0.489, and val rmse 0.882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.51      0.63      2560\n",
      "           1       0.42      0.68      0.52      2560\n",
      "           2       0.41      0.59      0.48      2560\n",
      "           3       0.60      0.18      0.27      2560\n",
      "\n",
      "    accuracy                           0.49     10240\n",
      "   macro avg       0.56      0.49      0.47     10240\n",
      "weighted avg       0.56      0.49      0.47     10240\n",
      "\n",
      "EPOCH  90 : train loss 0.217, val loss 2.990, val accuracy 0.494, and val rmse 0.869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.56      0.66      2560\n",
      "           1       0.43      0.65      0.52      2560\n",
      "           2       0.39      0.61      0.48      2560\n",
      "           3       0.60      0.16      0.26      2560\n",
      "\n",
      "    accuracy                           0.49     10240\n",
      "   macro avg       0.56      0.49      0.48     10240\n",
      "weighted avg       0.56      0.49      0.48     10240\n",
      "\n",
      "EPOCH  95 : train loss 0.207, val loss 2.976, val accuracy 0.494, and val rmse 0.875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.52      0.63      2560\n",
      "           1       0.43      0.66      0.52      2560\n",
      "           2       0.40      0.61      0.49      2560\n",
      "           3       0.62      0.18      0.28      2560\n",
      "\n",
      "    accuracy                           0.49     10240\n",
      "   macro avg       0.56      0.49      0.48     10240\n",
      "weighted avg       0.56      0.49      0.48     10240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM (content + title) (num_layers=2), hidden_dim=50 GloVe embeddings emb_size=50, no stop words (train + test), N=1000, (batch_size=100) w/ random synonym insertion (on content + title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0 : train loss 1.201, val loss 1.173, val accuracy 0.448, and val rmse 1.124\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.62      0.61      2560\n",
      "           1       0.41      0.31      0.35      2560\n",
      "           2       0.33      0.29      0.31      2560\n",
      "           3       0.42      0.57      0.49      2560\n",
      "\n",
      "    accuracy                           0.45     10240\n",
      "   macro avg       0.44      0.45      0.44     10240\n",
      "weighted avg       0.44      0.45      0.44     10240\n",
      "\n",
      "EPOCH  5 : train loss 0.750, val loss 1.416, val accuracy 0.507, and val rmse 1.000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.79      0.69      2560\n",
      "           1       0.49      0.35      0.41      2560\n",
      "           2       0.40      0.55      0.47      2560\n",
      "           3       0.54      0.33      0.41      2560\n",
      "\n",
      "    accuracy                           0.51     10240\n",
      "   macro avg       0.51      0.51      0.49     10240\n",
      "weighted avg       0.51      0.51      0.49     10240\n",
      "\n",
      "EPOCH  10 : train loss 0.591, val loss 1.672, val accuracy 0.510, and val rmse 0.920\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.69      0.70      2560\n",
      "           1       0.52      0.39      0.44      2560\n",
      "           2       0.39      0.68      0.49      2560\n",
      "           3       0.56      0.28      0.37      2560\n",
      "\n",
      "    accuracy                           0.51     10240\n",
      "   macro avg       0.54      0.51      0.50     10240\n",
      "weighted avg       0.54      0.51      0.50     10240\n",
      "\n",
      "EPOCH  15 : train loss 0.495, val loss 1.981, val accuracy 0.510, and val rmse 0.906\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.69      0.71      2560\n",
      "           1       0.44      0.55      0.49      2560\n",
      "           2       0.41      0.61      0.49      2560\n",
      "           3       0.60      0.19      0.29      2560\n",
      "\n",
      "    accuracy                           0.51     10240\n",
      "   macro avg       0.54      0.51      0.49     10240\n",
      "weighted avg       0.54      0.51      0.49     10240\n",
      "\n",
      "EPOCH  20 : train loss 0.450, val loss 2.031, val accuracy 0.512, and val rmse 0.907\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.67      0.70      2560\n",
      "           1       0.43      0.60      0.50      2560\n",
      "           2       0.42      0.55      0.48      2560\n",
      "           3       0.58      0.23      0.33      2560\n",
      "\n",
      "    accuracy                           0.51     10240\n",
      "   macro avg       0.54      0.51      0.50     10240\n",
      "weighted avg       0.54      0.51      0.50     10240\n",
      "\n",
      "EPOCH  25 : train loss 0.402, val loss 2.322, val accuracy 0.500, and val rmse 0.903\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.64      0.69      2560\n",
      "           1       0.41      0.62      0.49      2560\n",
      "           2       0.42      0.56      0.48      2560\n",
      "           3       0.63      0.18      0.28      2560\n",
      "\n",
      "    accuracy                           0.50     10240\n",
      "   macro avg       0.55      0.50      0.48     10240\n",
      "weighted avg       0.55      0.50      0.48     10240\n",
      "\n",
      "EPOCH  30 : train loss 0.370, val loss 2.328, val accuracy 0.501, and val rmse 0.886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.60      0.67      2560\n",
      "           1       0.42      0.61      0.49      2560\n",
      "           2       0.42      0.60      0.49      2560\n",
      "           3       0.59      0.20      0.30      2560\n",
      "\n",
      "    accuracy                           0.50     10240\n",
      "   macro avg       0.55      0.50      0.49     10240\n",
      "weighted avg       0.55      0.50      0.49     10240\n",
      "\n",
      "EPOCH  35 : train loss 0.346, val loss 2.448, val accuracy 0.481, and val rmse 0.892\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.53      0.63      2560\n",
      "           1       0.43      0.56      0.49      2560\n",
      "           2       0.39      0.66      0.49      2560\n",
      "           3       0.57      0.17      0.27      2560\n",
      "\n",
      "    accuracy                           0.48     10240\n",
      "   macro avg       0.54      0.48      0.47     10240\n",
      "weighted avg       0.54      0.48      0.47     10240\n",
      "\n",
      "EPOCH  40 : train loss 0.329, val loss 2.568, val accuracy 0.490, and val rmse 0.914\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.58      0.65      2560\n",
      "           1       0.41      0.65      0.50      2560\n",
      "           2       0.41      0.57      0.48      2560\n",
      "           3       0.62      0.16      0.25      2560\n",
      "\n",
      "    accuracy                           0.49     10240\n",
      "   macro avg       0.55      0.49      0.47     10240\n",
      "weighted avg       0.55      0.49      0.47     10240\n",
      "\n",
      "EPOCH  45 : train loss 0.312, val loss 2.506, val accuracy 0.495, and val rmse 0.885\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.56      0.65      2560\n",
      "           1       0.41      0.65      0.50      2560\n",
      "           2       0.41      0.58      0.48      2560\n",
      "           3       0.61      0.20      0.30      2560\n",
      "\n",
      "    accuracy                           0.49     10240\n",
      "   macro avg       0.55      0.49      0.48     10240\n",
      "weighted avg       0.55      0.49      0.48     10240\n",
      "\n",
      "EPOCH  50 : train loss 0.288, val loss 2.602, val accuracy 0.492, and val rmse 0.878\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.51      0.62      2560\n",
      "           1       0.43      0.61      0.50      2560\n",
      "           2       0.40      0.64      0.49      2560\n",
      "           3       0.60      0.20      0.30      2560\n",
      "\n",
      "    accuracy                           0.49     10240\n",
      "   macro avg       0.55      0.49      0.48     10240\n",
      "weighted avg       0.55      0.49      0.48     10240\n",
      "\n",
      "EPOCH  55 : train loss 0.274, val loss 2.658, val accuracy 0.493, and val rmse 0.891\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.57      0.66      2560\n",
      "           1       0.41      0.65      0.51      2560\n",
      "           2       0.41      0.57      0.48      2560\n",
      "           3       0.61      0.17      0.27      2560\n",
      "\n",
      "    accuracy                           0.49     10240\n",
      "   macro avg       0.55      0.49      0.48     10240\n",
      "weighted avg       0.55      0.49      0.48     10240\n",
      "\n",
      "EPOCH  60 : train loss 0.268, val loss 2.718, val accuracy 0.488, and val rmse 0.872\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.49      0.61      2560\n",
      "           1       0.43      0.63      0.51      2560\n",
      "           2       0.39      0.63      0.49      2560\n",
      "           3       0.60      0.20      0.30      2560\n",
      "\n",
      "    accuracy                           0.49     10240\n",
      "   macro avg       0.56      0.49      0.48     10240\n",
      "weighted avg       0.56      0.49      0.48     10240\n",
      "\n",
      "EPOCH  65 : train loss 0.258, val loss 2.863, val accuracy 0.491, and val rmse 0.876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.53      0.64      2560\n",
      "           1       0.43      0.64      0.51      2560\n",
      "           2       0.40      0.61      0.48      2560\n",
      "           3       0.62      0.18      0.28      2560\n",
      "\n",
      "    accuracy                           0.49     10240\n",
      "   macro avg       0.56      0.49      0.48     10240\n",
      "weighted avg       0.56      0.49      0.48     10240\n",
      "\n",
      "EPOCH  70 : train loss 0.239, val loss 2.869, val accuracy 0.482, and val rmse 0.875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.49      0.61      2560\n",
      "           1       0.42      0.65      0.51      2560\n",
      "           2       0.39      0.60      0.48      2560\n",
      "           3       0.62      0.19      0.29      2560\n",
      "\n",
      "    accuracy                           0.48     10240\n",
      "   macro avg       0.56      0.48      0.47     10240\n",
      "weighted avg       0.56      0.48      0.47     10240\n",
      "\n",
      "EPOCH  75 : train loss 0.235, val loss 3.088, val accuracy 0.470, and val rmse 0.921\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.46      0.58      2560\n",
      "           1       0.39      0.72      0.51      2560\n",
      "           2       0.41      0.54      0.47      2560\n",
      "           3       0.63      0.15      0.25      2560\n",
      "\n",
      "    accuracy                           0.47     10240\n",
      "   macro avg       0.55      0.47      0.45     10240\n",
      "weighted avg       0.55      0.47      0.45     10240\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  80 : train loss 0.230, val loss 2.692, val accuracy 0.495, and val rmse 0.907\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.56      0.65      2560\n",
      "           1       0.41      0.67      0.51      2560\n",
      "           2       0.41      0.53      0.46      2560\n",
      "           3       0.61      0.22      0.32      2560\n",
      "\n",
      "    accuracy                           0.49     10240\n",
      "   macro avg       0.55      0.49      0.49     10240\n",
      "weighted avg       0.55      0.49      0.49     10240\n",
      "\n",
      "EPOCH  85 : train loss 0.225, val loss 2.954, val accuracy 0.488, and val rmse 0.887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.53      0.64      2560\n",
      "           1       0.41      0.68      0.51      2560\n",
      "           2       0.40      0.55      0.47      2560\n",
      "           3       0.63      0.19      0.29      2560\n",
      "\n",
      "    accuracy                           0.49     10240\n",
      "   macro avg       0.56      0.49      0.48     10240\n",
      "weighted avg       0.56      0.49      0.48     10240\n",
      "\n",
      "EPOCH  90 : train loss 0.227, val loss 2.877, val accuracy 0.480, and val rmse 0.929\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.59      0.66      2560\n",
      "           1       0.39      0.64      0.48      2560\n",
      "           2       0.41      0.51      0.45      2560\n",
      "           3       0.61      0.17      0.27      2560\n",
      "\n",
      "    accuracy                           0.48     10240\n",
      "   macro avg       0.54      0.48      0.47     10240\n",
      "weighted avg       0.54      0.48      0.47     10240\n",
      "\n",
      "EPOCH  95 : train loss 0.214, val loss 2.912, val accuracy 0.491, and val rmse 0.873\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.52      0.63      2560\n",
      "           1       0.42      0.64      0.51      2560\n",
      "           2       0.40      0.59      0.48      2560\n",
      "           3       0.62      0.21      0.32      2560\n",
      "\n",
      "    accuracy                           0.49     10240\n",
      "   macro avg       0.56      0.49      0.48     10240\n",
      "weighted avg       0.56      0.49      0.48     10240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM (content + title) (num_layers=2), hidden_dim=50 GloVe embeddings emb_size=50, no stop words (train + test), N=650, (batch_size=1000) w/ random synonym insertion (on content + title) alpha=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0 : train loss 1.345, val loss 1.277, val accuracy 0.379, and val rmse 1.459\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.63      0.56      2560\n",
      "           1       0.34      0.08      0.13      2560\n",
      "           2       0.27      0.02      0.04      2560\n",
      "           3       0.32      0.78      0.46      2560\n",
      "\n",
      "    accuracy                           0.38     10240\n",
      "   macro avg       0.36      0.38      0.30     10240\n",
      "weighted avg       0.36      0.38      0.30     10240\n",
      "\n",
      "EPOCH  5 : train loss 1.146, val loss 1.177, val accuracy 0.464, and val rmse 1.195\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.60      0.60      2560\n",
      "           1       0.47      0.38      0.42      2560\n",
      "           2       0.32      0.15      0.20      2560\n",
      "           3       0.42      0.73      0.53      2560\n",
      "\n",
      "    accuracy                           0.46     10240\n",
      "   macro avg       0.46      0.46      0.44     10240\n",
      "weighted avg       0.46      0.46      0.44     10240\n",
      "\n",
      "EPOCH  10 : train loss 1.062, val loss 1.118, val accuracy 0.486, and val rmse 1.068\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.55      0.60      2560\n",
      "           1       0.49      0.47      0.48      2560\n",
      "           2       0.35      0.35      0.35      2560\n",
      "           3       0.48      0.57      0.52      2560\n",
      "\n",
      "    accuracy                           0.49     10240\n",
      "   macro avg       0.49      0.49      0.49     10240\n",
      "weighted avg       0.49      0.49      0.49     10240\n",
      "\n",
      "EPOCH  15 : train loss 0.966, val loss 1.092, val accuracy 0.500, and val rmse 1.001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.64      2560\n",
      "           1       0.47      0.60      0.53      2560\n",
      "           2       0.34      0.32      0.33      2560\n",
      "           3       0.54      0.46      0.49      2560\n",
      "\n",
      "    accuracy                           0.50     10240\n",
      "   macro avg       0.50      0.50      0.50     10240\n",
      "weighted avg       0.50      0.50      0.50     10240\n",
      "\n",
      "EPOCH  20 : train loss 0.864, val loss 1.151, val accuracy 0.509, and val rmse 0.956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.56      0.65      2560\n",
      "           1       0.46      0.78      0.58      2560\n",
      "           2       0.35      0.33      0.34      2560\n",
      "           3       0.57      0.36      0.44      2560\n",
      "\n",
      "    accuracy                           0.51     10240\n",
      "   macro avg       0.54      0.51      0.50     10240\n",
      "weighted avg       0.54      0.51      0.50     10240\n",
      "\n",
      "EPOCH  25 : train loss 0.771, val loss 1.343, val accuracy 0.461, and val rmse 0.972\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.40      0.53      2560\n",
      "           1       0.38      0.90      0.54      2560\n",
      "           2       0.38      0.29      0.33      2560\n",
      "           3       0.63      0.26      0.37      2560\n",
      "\n",
      "    accuracy                           0.46     10240\n",
      "   macro avg       0.55      0.46      0.44     10240\n",
      "weighted avg       0.55      0.46      0.44     10240\n",
      "\n",
      "EPOCH  30 : train loss 0.689, val loss 1.299, val accuracy 0.513, and val rmse 0.935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.55      0.65      2560\n",
      "           1       0.45      0.87      0.60      2560\n",
      "           2       0.38      0.38      0.38      2560\n",
      "           3       0.66      0.24      0.36      2560\n",
      "\n",
      "    accuracy                           0.51     10240\n",
      "   macro avg       0.57      0.51      0.50     10240\n",
      "weighted avg       0.57      0.51      0.50     10240\n",
      "\n",
      "EPOCH  35 : train loss 0.680, val loss 1.332, val accuracy 0.511, and val rmse 0.931\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.49      0.62      2560\n",
      "           1       0.45      0.90      0.60      2560\n",
      "           2       0.39      0.40      0.40      2560\n",
      "           3       0.68      0.25      0.37      2560\n",
      "\n",
      "    accuracy                           0.51     10240\n",
      "   macro avg       0.58      0.51      0.49     10240\n",
      "weighted avg       0.58      0.51      0.49     10240\n",
      "\n",
      "EPOCH  40 : train loss 0.599, val loss 1.203, val accuracy 0.572, and val rmse 0.905\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.62      0.70      2560\n",
      "           1       0.53      0.84      0.65      2560\n",
      "           2       0.42      0.41      0.42      2560\n",
      "           3       0.63      0.42      0.50      2560\n",
      "\n",
      "    accuracy                           0.57     10240\n",
      "   macro avg       0.59      0.57      0.57     10240\n",
      "weighted avg       0.59      0.57      0.57     10240\n",
      "\n",
      "EPOCH  45 : train loss 0.569, val loss 1.337, val accuracy 0.547, and val rmse 0.954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.63      0.67      2560\n",
      "           1       0.51      0.86      0.64      2560\n",
      "           2       0.41      0.42      0.41      2560\n",
      "           3       0.69      0.28      0.39      2560\n",
      "\n",
      "    accuracy                           0.55     10240\n",
      "   macro avg       0.58      0.55      0.53     10240\n",
      "weighted avg       0.58      0.55      0.53     10240\n",
      "\n",
      "EPOCH  50 : train loss 0.533, val loss 1.560, val accuracy 0.514, and val rmse 0.924\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.53      0.65      2560\n",
      "           1       0.43      0.93      0.59      2560\n",
      "           2       0.41      0.38      0.39      2560\n",
      "           3       0.73      0.21      0.33      2560\n",
      "\n",
      "    accuracy                           0.51     10240\n",
      "   macro avg       0.60      0.51      0.49     10240\n",
      "weighted avg       0.60      0.51      0.49     10240\n",
      "\n",
      "EPOCH  55 : train loss 0.497, val loss 1.495, val accuracy 0.539, and val rmse 0.882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.53      0.65      2560\n",
      "           1       0.50      0.90      0.64      2560\n",
      "           2       0.40      0.50      0.45      2560\n",
      "           3       0.71      0.23      0.35      2560\n",
      "\n",
      "    accuracy                           0.54     10240\n",
      "   macro avg       0.61      0.54      0.52     10240\n",
      "weighted avg       0.61      0.54      0.52     10240\n",
      "\n",
      "EPOCH  60 : train loss 0.470, val loss 1.377, val accuracy 0.569, and val rmse 0.877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.60      0.70      2560\n",
      "           1       0.53      0.88      0.66      2560\n",
      "           2       0.42      0.47      0.44      2560\n",
      "           3       0.66      0.32      0.43      2560\n",
      "\n",
      "    accuracy                           0.57     10240\n",
      "   macro avg       0.61      0.57      0.56     10240\n",
      "weighted avg       0.61      0.57      0.56     10240\n",
      "\n",
      "EPOCH  65 : train loss 0.439, val loss 1.504, val accuracy 0.567, and val rmse 0.873\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.59      0.70      2560\n",
      "           1       0.53      0.89      0.67      2560\n",
      "           2       0.41      0.51      0.46      2560\n",
      "           3       0.67      0.29      0.40      2560\n",
      "\n",
      "    accuracy                           0.57     10240\n",
      "   macro avg       0.62      0.57      0.55     10240\n",
      "weighted avg       0.62      0.57      0.55     10240\n",
      "\n",
      "EPOCH  70 : train loss 0.425, val loss 1.366, val accuracy 0.602, and val rmse 0.864\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.71      0.75      2560\n",
      "           1       0.60      0.87      0.71      2560\n",
      "           2       0.43      0.49      0.46      2560\n",
      "           3       0.67      0.34      0.45      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.62      0.60      0.59     10240\n",
      "weighted avg       0.62      0.60      0.59     10240\n",
      "\n",
      "EPOCH  75 : train loss 0.406, val loss 1.554, val accuracy 0.571, and val rmse 0.872\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.60      0.70      2560\n",
      "           1       0.56      0.88      0.68      2560\n",
      "           2       0.41      0.54      0.47      2560\n",
      "           3       0.68      0.26      0.37      2560\n",
      "\n",
      "    accuracy                           0.57     10240\n",
      "   macro avg       0.62      0.57      0.56     10240\n",
      "weighted avg       0.62      0.57      0.56     10240\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  80 : train loss 0.391, val loss 1.558, val accuracy 0.566, and val rmse 0.868\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.60      0.70      2560\n",
      "           1       0.52      0.91      0.66      2560\n",
      "           2       0.42      0.46      0.44      2560\n",
      "           3       0.67      0.30      0.41      2560\n",
      "\n",
      "    accuracy                           0.57     10240\n",
      "   macro avg       0.61      0.57      0.55     10240\n",
      "weighted avg       0.61      0.57      0.55     10240\n",
      "\n",
      "EPOCH  85 : train loss 0.385, val loss 1.671, val accuracy 0.563, and val rmse 0.867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.64      0.72      2560\n",
      "           1       0.52      0.91      0.67      2560\n",
      "           2       0.41      0.48      0.44      2560\n",
      "           3       0.69      0.22      0.34      2560\n",
      "\n",
      "    accuracy                           0.56     10240\n",
      "   macro avg       0.62      0.56      0.54     10240\n",
      "weighted avg       0.62      0.56      0.54     10240\n",
      "\n",
      "EPOCH  90 : train loss 0.366, val loss 1.585, val accuracy 0.583, and val rmse 0.840\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.62      0.72      2560\n",
      "           1       0.57      0.88      0.69      2560\n",
      "           2       0.42      0.54      0.47      2560\n",
      "           3       0.66      0.29      0.40      2560\n",
      "\n",
      "    accuracy                           0.58     10240\n",
      "   macro avg       0.63      0.58      0.57     10240\n",
      "weighted avg       0.63      0.58      0.57     10240\n",
      "\n",
      "EPOCH  95 : train loss 0.364, val loss 1.751, val accuracy 0.560, and val rmse 0.936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.70      0.72      2560\n",
      "           1       0.52      0.90      0.66      2560\n",
      "           2       0.42      0.43      0.43      2560\n",
      "           3       0.70      0.21      0.32      2560\n",
      "\n",
      "    accuracy                           0.56     10240\n",
      "   macro avg       0.60      0.56      0.53     10240\n",
      "weighted avg       0.60      0.56      0.53     10240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM (content + title) (num_layers=2), hidden_dim=100 GloVe embeddings emb_size=100, no stop words (train + test), N=650, (batch_size=500) w/ random synonym insertion (on content + title) alpha=0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0 : train loss 1.244, val loss 1.203, val accuracy 0.444, and val rmse 1.261\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.58      0.57      2560\n",
      "           1       0.47      0.37      0.41      2560\n",
      "           2       0.29      0.07      0.11      2560\n",
      "           3       0.39      0.76      0.52      2560\n",
      "\n",
      "    accuracy                           0.44     10240\n",
      "   macro avg       0.43      0.44      0.40     10240\n",
      "weighted avg       0.43      0.44      0.40     10240\n",
      "\n",
      "EPOCH  5 : train loss 0.778, val loss 1.004, val accuracy 0.587, and val rmse 0.937\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72      2560\n",
      "           1       0.64      0.74      0.69      2560\n",
      "           2       0.40      0.41      0.41      2560\n",
      "           3       0.60      0.45      0.52      2560\n",
      "\n",
      "    accuracy                           0.59     10240\n",
      "   macro avg       0.59      0.59      0.58     10240\n",
      "weighted avg       0.59      0.59      0.58     10240\n",
      "\n",
      "EPOCH  10 : train loss 0.547, val loss 1.196, val accuracy 0.596, and val rmse 0.870\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.75      2560\n",
      "           1       0.66      0.83      0.73      2560\n",
      "           2       0.41      0.53      0.46      2560\n",
      "           3       0.61      0.27      0.38      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.61      0.60      0.58     10240\n",
      "weighted avg       0.61      0.60      0.58     10240\n",
      "\n",
      "EPOCH  15 : train loss 0.736, val loss 1.366, val accuracy 0.493, and val rmse 1.032\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.71      0.66      2560\n",
      "           1       0.42      0.56      0.48      2560\n",
      "           2       0.39      0.32      0.35      2560\n",
      "           3       0.54      0.39      0.45      2560\n",
      "\n",
      "    accuracy                           0.49     10240\n",
      "   macro avg       0.49      0.49      0.49     10240\n",
      "weighted avg       0.49      0.49      0.49     10240\n",
      "\n",
      "EPOCH  20 : train loss 0.519, val loss 1.191, val accuracy 0.592, and val rmse 0.870\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.67      0.74      2560\n",
      "           1       0.67      0.77      0.72      2560\n",
      "           2       0.39      0.55      0.46      2560\n",
      "           3       0.59      0.38      0.46      2560\n",
      "\n",
      "    accuracy                           0.59     10240\n",
      "   macro avg       0.62      0.59      0.59     10240\n",
      "weighted avg       0.62      0.59      0.59     10240\n",
      "\n",
      "EPOCH  25 : train loss 0.413, val loss 1.420, val accuracy 0.599, and val rmse 0.844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.71      0.76      2560\n",
      "           1       0.65      0.85      0.74      2560\n",
      "           2       0.41      0.59      0.48      2560\n",
      "           3       0.65      0.24      0.35      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.63      0.60      0.58     10240\n",
      "weighted avg       0.63      0.60      0.58     10240\n",
      "\n",
      "EPOCH  30 : train loss 0.359, val loss 1.512, val accuracy 0.602, and val rmse 0.843\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.76      2560\n",
      "           1       0.67      0.86      0.75      2560\n",
      "           2       0.40      0.58      0.48      2560\n",
      "           3       0.62      0.25      0.36      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.63      0.60      0.59     10240\n",
      "weighted avg       0.63      0.60      0.59     10240\n",
      "\n",
      "EPOCH  35 : train loss 0.330, val loss 1.586, val accuracy 0.602, and val rmse 0.825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.69      0.76      2560\n",
      "           1       0.67      0.86      0.75      2560\n",
      "           2       0.41      0.61      0.49      2560\n",
      "           3       0.63      0.25      0.36      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.64      0.60      0.59     10240\n",
      "weighted avg       0.64      0.60      0.59     10240\n",
      "\n",
      "EPOCH  40 : train loss 0.302, val loss 1.660, val accuracy 0.604, and val rmse 0.832\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.76      0.78      2560\n",
      "           1       0.67      0.84      0.75      2560\n",
      "           2       0.40      0.58      0.47      2560\n",
      "           3       0.64      0.24      0.35      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.63      0.60      0.59     10240\n",
      "weighted avg       0.63      0.60      0.59     10240\n",
      "\n",
      "EPOCH  45 : train loss 0.273, val loss 1.623, val accuracy 0.598, and val rmse 0.838\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.61      0.73      2560\n",
      "           1       0.67      0.85      0.75      2560\n",
      "           2       0.40      0.58      0.47      2560\n",
      "           3       0.60      0.34      0.44      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.64      0.60      0.60     10240\n",
      "weighted avg       0.64      0.60      0.60     10240\n",
      "\n",
      "EPOCH  50 : train loss 0.269, val loss 1.800, val accuracy 0.602, and val rmse 0.818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.67      0.75      2560\n",
      "           1       0.68      0.86      0.76      2560\n",
      "           2       0.40      0.63      0.49      2560\n",
      "           3       0.64      0.25      0.35      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.64      0.60      0.59     10240\n",
      "weighted avg       0.64      0.60      0.59     10240\n",
      "\n",
      "EPOCH  55 : train loss 0.243, val loss 1.762, val accuracy 0.602, and val rmse 0.818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      2560\n",
      "           1       0.70      0.78      0.74      2560\n",
      "           2       0.40      0.63      0.49      2560\n",
      "           3       0.62      0.26      0.36      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.63      0.60      0.59     10240\n",
      "weighted avg       0.63      0.60      0.59     10240\n",
      "\n",
      "EPOCH  60 : train loss 0.214, val loss 2.127, val accuracy 0.568, and val rmse 0.832\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.65      0.73      2560\n",
      "           1       0.58      0.82      0.68      2560\n",
      "           2       0.41      0.61      0.49      2560\n",
      "           3       0.66      0.18      0.29      2560\n",
      "\n",
      "    accuracy                           0.57     10240\n",
      "   macro avg       0.62      0.57      0.55     10240\n",
      "weighted avg       0.62      0.57      0.55     10240\n",
      "\n",
      "EPOCH  65 : train loss 0.192, val loss 2.211, val accuracy 0.597, and val rmse 0.806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.67      0.76      2560\n",
      "           1       0.69      0.83      0.75      2560\n",
      "           2       0.40      0.69      0.51      2560\n",
      "           3       0.67      0.19      0.30      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.65      0.60      0.58     10240\n",
      "weighted avg       0.65      0.60      0.58     10240\n",
      "\n",
      "EPOCH  70 : train loss 0.186, val loss 2.159, val accuracy 0.601, and val rmse 0.830\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.73      0.77      2560\n",
      "           1       0.68      0.87      0.76      2560\n",
      "           2       0.41      0.64      0.50      2560\n",
      "           3       0.68      0.17      0.27      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.64      0.60      0.57     10240\n",
      "weighted avg       0.64      0.60      0.57     10240\n",
      "\n",
      "EPOCH  75 : train loss 0.160, val loss 2.304, val accuracy 0.585, and val rmse 0.823\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.66      0.74      2560\n",
      "           1       0.64      0.82      0.72      2560\n",
      "           2       0.41      0.65      0.50      2560\n",
      "           3       0.66      0.21      0.32      2560\n",
      "\n",
      "    accuracy                           0.59     10240\n",
      "   macro avg       0.63      0.59      0.57     10240\n",
      "weighted avg       0.63      0.59      0.57     10240\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  80 : train loss 0.160, val loss 2.262, val accuracy 0.588, and val rmse 0.818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.71      0.76      2560\n",
      "           1       0.71      0.72      0.71      2560\n",
      "           2       0.40      0.73      0.51      2560\n",
      "           3       0.66      0.19      0.30      2560\n",
      "\n",
      "    accuracy                           0.59     10240\n",
      "   macro avg       0.65      0.59      0.57     10240\n",
      "weighted avg       0.65      0.59      0.57     10240\n",
      "\n",
      "EPOCH  85 : train loss 0.142, val loss 2.154, val accuracy 0.595, and val rmse 0.820\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.69      0.76      2560\n",
      "           1       0.70      0.76      0.73      2560\n",
      "           2       0.40      0.68      0.51      2560\n",
      "           3       0.62      0.25      0.35      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.64      0.60      0.59     10240\n",
      "weighted avg       0.64      0.60      0.59     10240\n",
      "\n",
      "EPOCH  90 : train loss 0.127, val loss 2.215, val accuracy 0.605, and val rmse 0.808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.72      0.78      2560\n",
      "           1       0.70      0.81      0.75      2560\n",
      "           2       0.41      0.66      0.51      2560\n",
      "           3       0.63      0.23      0.34      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.65      0.60      0.59     10240\n",
      "weighted avg       0.65      0.60      0.59     10240\n",
      "\n",
      "EPOCH  95 : train loss 0.123, val loss 2.341, val accuracy 0.601, and val rmse 0.808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.74      0.78      2560\n",
      "           1       0.68      0.82      0.74      2560\n",
      "           2       0.41      0.64      0.50      2560\n",
      "           3       0.66      0.20      0.30      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.64      0.60      0.58     10240\n",
      "weighted avg       0.64      0.60      0.58     10240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM (content + title) (num_layers=2), hidden_dim=100 GloVe embeddings emb_size=100, no stop words (train + test), N=650, (batch_size=500) w/ random synonym insertion (on content + title) alpha=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0 : train loss 1.229, val loss 1.151, val accuracy 0.483, and val rmse 1.178\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.51      0.58      2560\n",
      "           1       0.54      0.51      0.52      2560\n",
      "           2       0.31      0.19      0.23      2560\n",
      "           3       0.43      0.72      0.54      2560\n",
      "\n",
      "    accuracy                           0.48     10240\n",
      "   macro avg       0.49      0.48      0.47     10240\n",
      "weighted avg       0.49      0.48      0.47     10240\n",
      "\n",
      "EPOCH  5 : train loss 0.902, val loss 1.225, val accuracy 0.446, and val rmse 0.999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.33      0.45      2560\n",
      "           1       0.39      0.70      0.50      2560\n",
      "           2       0.37      0.44      0.40      2560\n",
      "           3       0.54      0.32      0.41      2560\n",
      "\n",
      "    accuracy                           0.45     10240\n",
      "   macro avg       0.51      0.45      0.44     10240\n",
      "weighted avg       0.51      0.45      0.44     10240\n",
      "\n",
      "EPOCH  10 : train loss 0.740, val loss 1.125, val accuracy 0.553, and val rmse 0.924\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.70      0.71      2560\n",
      "           1       0.55      0.79      0.65      2560\n",
      "           2       0.38      0.41      0.39      2560\n",
      "           3       0.60      0.32      0.41      2560\n",
      "\n",
      "    accuracy                           0.55     10240\n",
      "   macro avg       0.56      0.55      0.54     10240\n",
      "weighted avg       0.56      0.55      0.54     10240\n",
      "\n",
      "EPOCH  15 : train loss 0.527, val loss 1.271, val accuracy 0.588, and val rmse 0.858\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.69      0.75      2560\n",
      "           1       0.59      0.85      0.70      2560\n",
      "           2       0.41      0.50      0.45      2560\n",
      "           3       0.63      0.30      0.41      2560\n",
      "\n",
      "    accuracy                           0.59     10240\n",
      "   macro avg       0.61      0.59      0.58     10240\n",
      "weighted avg       0.61      0.59      0.58     10240\n",
      "\n",
      "EPOCH  20 : train loss 0.455, val loss 1.398, val accuracy 0.598, and val rmse 0.852\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.67      0.74      2560\n",
      "           1       0.61      0.91      0.73      2560\n",
      "           2       0.42      0.51      0.46      2560\n",
      "           3       0.64      0.30      0.41      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.62      0.60      0.58     10240\n",
      "weighted avg       0.62      0.60      0.58     10240\n",
      "\n",
      "EPOCH  25 : train loss 0.403, val loss 1.378, val accuracy 0.609, and val rmse 0.875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      2560\n",
      "           1       0.65      0.91      0.76      2560\n",
      "           2       0.41      0.49      0.45      2560\n",
      "           3       0.62      0.30      0.41      2560\n",
      "\n",
      "    accuracy                           0.61     10240\n",
      "   macro avg       0.62      0.61      0.59     10240\n",
      "weighted avg       0.62      0.61      0.59     10240\n",
      "\n",
      "EPOCH  30 : train loss 0.501, val loss 1.497, val accuracy 0.572, and val rmse 0.867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.75      2560\n",
      "           1       0.62      0.75      0.68      2560\n",
      "           2       0.39      0.61      0.48      2560\n",
      "           3       0.64      0.20      0.31      2560\n",
      "\n",
      "    accuracy                           0.57     10240\n",
      "   macro avg       0.61      0.57      0.55     10240\n",
      "weighted avg       0.61      0.57      0.55     10240\n",
      "\n",
      "EPOCH  35 : train loss 0.349, val loss 1.583, val accuracy 0.612, and val rmse 0.831\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.72      0.77      2560\n",
      "           1       0.65      0.88      0.75      2560\n",
      "           2       0.42      0.56      0.48      2560\n",
      "           3       0.65      0.28      0.39      2560\n",
      "\n",
      "    accuracy                           0.61     10240\n",
      "   macro avg       0.64      0.61      0.60     10240\n",
      "weighted avg       0.64      0.61      0.60     10240\n",
      "\n",
      "EPOCH  40 : train loss 0.361, val loss 1.466, val accuracy 0.606, and val rmse 0.840\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.74      0.77      2560\n",
      "           1       0.66      0.84      0.74      2560\n",
      "           2       0.41      0.56      0.47      2560\n",
      "           3       0.63      0.29      0.39      2560\n",
      "\n",
      "    accuracy                           0.61     10240\n",
      "   macro avg       0.63      0.61      0.59     10240\n",
      "weighted avg       0.63      0.61      0.59     10240\n",
      "\n",
      "EPOCH  45 : train loss 0.305, val loss 1.676, val accuracy 0.600, and val rmse 0.830\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.69      0.75      2560\n",
      "           1       0.70      0.80      0.75      2560\n",
      "           2       0.39      0.64      0.49      2560\n",
      "           3       0.64      0.28      0.39      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.64      0.60      0.59     10240\n",
      "weighted avg       0.64      0.60      0.59     10240\n",
      "\n",
      "EPOCH  50 : train loss 0.280, val loss 1.781, val accuracy 0.589, and val rmse 0.837\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.69      0.76      2560\n",
      "           1       0.63      0.83      0.71      2560\n",
      "           2       0.41      0.61      0.49      2560\n",
      "           3       0.66      0.22      0.33      2560\n",
      "\n",
      "    accuracy                           0.59     10240\n",
      "   macro avg       0.63      0.59      0.57     10240\n",
      "weighted avg       0.63      0.59      0.57     10240\n",
      "\n",
      "EPOCH  55 : train loss 0.270, val loss 1.636, val accuracy 0.605, and val rmse 0.831\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.70      0.76      2560\n",
      "           1       0.67      0.85      0.75      2560\n",
      "           2       0.40      0.58      0.48      2560\n",
      "           3       0.63      0.29      0.39      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.64      0.60      0.60     10240\n",
      "weighted avg       0.64      0.60      0.60     10240\n",
      "\n",
      "EPOCH  60 : train loss 0.250, val loss 1.846, val accuracy 0.599, and val rmse 0.841\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.76      0.78      2560\n",
      "           1       0.67      0.82      0.74      2560\n",
      "           2       0.40      0.60      0.48      2560\n",
      "           3       0.66      0.22      0.33      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.63      0.60      0.58     10240\n",
      "weighted avg       0.63      0.60      0.58     10240\n",
      "\n",
      "EPOCH  65 : train loss 0.215, val loss 1.908, val accuracy 0.609, and val rmse 0.834\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78      2560\n",
      "           1       0.68      0.85      0.75      2560\n",
      "           2       0.41      0.60      0.49      2560\n",
      "           3       0.66      0.24      0.35      2560\n",
      "\n",
      "    accuracy                           0.61     10240\n",
      "   macro avg       0.64      0.61      0.59     10240\n",
      "weighted avg       0.64      0.61      0.59     10240\n",
      "\n",
      "EPOCH  70 : train loss 0.192, val loss 2.036, val accuracy 0.593, and val rmse 0.823\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.68      0.76      2560\n",
      "           1       0.69      0.80      0.74      2560\n",
      "           2       0.39      0.67      0.50      2560\n",
      "           3       0.65      0.22      0.33      2560\n",
      "\n",
      "    accuracy                           0.59     10240\n",
      "   macro avg       0.65      0.59      0.58     10240\n",
      "weighted avg       0.65      0.59      0.58     10240\n",
      "\n",
      "EPOCH  75 : train loss 0.181, val loss 2.117, val accuracy 0.592, and val rmse 0.825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.69      0.76      2560\n",
      "           1       0.70      0.79      0.74      2560\n",
      "           2       0.39      0.67      0.50      2560\n",
      "           3       0.64      0.22      0.32      2560\n",
      "\n",
      "    accuracy                           0.59     10240\n",
      "   macro avg       0.65      0.59      0.58     10240\n",
      "weighted avg       0.65      0.59      0.58     10240\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  80 : train loss 0.229, val loss 1.886, val accuracy 0.602, and val rmse 0.812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.68      0.76      2560\n",
      "           1       0.67      0.82      0.73      2560\n",
      "           2       0.40      0.61      0.49      2560\n",
      "           3       0.63      0.30      0.41      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.64      0.60      0.60     10240\n",
      "weighted avg       0.64      0.60      0.60     10240\n",
      "\n",
      "EPOCH  85 : train loss 0.156, val loss 2.141, val accuracy 0.598, and val rmse 0.811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.67      0.76      2560\n",
      "           1       0.65      0.83      0.73      2560\n",
      "           2       0.40      0.63      0.49      2560\n",
      "           3       0.66      0.26      0.37      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.65      0.60      0.59     10240\n",
      "weighted avg       0.65      0.60      0.59     10240\n",
      "\n",
      "EPOCH  90 : train loss 0.144, val loss 2.282, val accuracy 0.589, and val rmse 0.823\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.63      0.74      2560\n",
      "           1       0.66      0.84      0.74      2560\n",
      "           2       0.39      0.64      0.49      2560\n",
      "           3       0.65      0.24      0.35      2560\n",
      "\n",
      "    accuracy                           0.59     10240\n",
      "   macro avg       0.65      0.59      0.58     10240\n",
      "weighted avg       0.65      0.59      0.58     10240\n",
      "\n",
      "EPOCH  95 : train loss 0.136, val loss 2.191, val accuracy 0.602, and val rmse 0.817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.68      0.76      2560\n",
      "           1       0.70      0.79      0.74      2560\n",
      "           2       0.40      0.69      0.51      2560\n",
      "           3       0.66      0.25      0.36      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.66      0.60      0.59     10240\n",
      "weighted avg       0.66      0.60      0.59     10240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM (content + title) (num_layers=2), hidden_dim=100 GloVe embeddings emb_size=100, no stop words (train + test), N=600, (batch_size=600) w/ random synonym insertion (on content + title) alpha=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0 : train loss 1.251, val loss 1.183, val accuracy 0.461, and val rmse 1.203\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.52      0.55      2560\n",
      "           1       0.47      0.49      0.48      2560\n",
      "           2       0.35      0.20      0.25      2560\n",
      "           3       0.42      0.64      0.51      2560\n",
      "\n",
      "    accuracy                           0.46     10240\n",
      "   macro avg       0.46      0.46      0.45     10240\n",
      "weighted avg       0.46      0.46      0.45     10240\n",
      "\n",
      "EPOCH  5 : train loss 0.880, val loss 1.050, val accuracy 0.543, and val rmse 0.990\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.72      0.68      2560\n",
      "           1       0.54      0.75      0.63      2560\n",
      "           2       0.38      0.35      0.37      2560\n",
      "           3       0.60      0.35      0.45      2560\n",
      "\n",
      "    accuracy                           0.54     10240\n",
      "   macro avg       0.54      0.54      0.53     10240\n",
      "weighted avg       0.54      0.54      0.53     10240\n",
      "\n",
      "EPOCH  10 : train loss 0.599, val loss 1.118, val accuracy 0.570, and val rmse 0.988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.54      0.65      2560\n",
      "           1       0.71      0.74      0.72      2560\n",
      "           2       0.33      0.31      0.32      2560\n",
      "           3       0.50      0.70      0.59      2560\n",
      "\n",
      "    accuracy                           0.57     10240\n",
      "   macro avg       0.59      0.57      0.57     10240\n",
      "weighted avg       0.59      0.57      0.57     10240\n",
      "\n",
      "EPOCH  15 : train loss 0.512, val loss 1.176, val accuracy 0.612, and val rmse 0.878\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.70      0.74      2560\n",
      "           1       0.63      0.89      0.74      2560\n",
      "           2       0.42      0.46      0.44      2560\n",
      "           3       0.65      0.39      0.49      2560\n",
      "\n",
      "    accuracy                           0.61     10240\n",
      "   macro avg       0.62      0.61      0.60     10240\n",
      "weighted avg       0.62      0.61      0.60     10240\n",
      "\n",
      "EPOCH  20 : train loss 0.442, val loss 1.195, val accuracy 0.585, and val rmse 0.923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.63      0.72      2560\n",
      "           1       0.64      0.76      0.69      2560\n",
      "           2       0.41      0.43      0.42      2560\n",
      "           3       0.51      0.53      0.52      2560\n",
      "\n",
      "    accuracy                           0.58     10240\n",
      "   macro avg       0.60      0.58      0.59     10240\n",
      "weighted avg       0.60      0.58      0.59     10240\n",
      "\n",
      "EPOCH  25 : train loss 0.904, val loss 1.098, val accuracy 0.552, and val rmse 1.080\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.60      0.63      2560\n",
      "           1       0.59      0.93      0.72      2560\n",
      "           2       0.34      0.25      0.29      2560\n",
      "           3       0.54      0.43      0.48      2560\n",
      "\n",
      "    accuracy                           0.55     10240\n",
      "   macro avg       0.53      0.55      0.53     10240\n",
      "weighted avg       0.53      0.55      0.53     10240\n",
      "\n",
      "EPOCH  30 : train loss 0.432, val loss 1.301, val accuracy 0.604, and val rmse 0.870\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.68      0.74      2560\n",
      "           1       0.65      0.88      0.74      2560\n",
      "           2       0.41      0.52      0.46      2560\n",
      "           3       0.62      0.33      0.43      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.62      0.60      0.60     10240\n",
      "weighted avg       0.62      0.60      0.60     10240\n",
      "\n",
      "EPOCH  35 : train loss 0.359, val loss 1.494, val accuracy 0.610, and val rmse 0.848\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.69      0.75      2560\n",
      "           1       0.68      0.85      0.76      2560\n",
      "           2       0.41      0.60      0.49      2560\n",
      "           3       0.64      0.29      0.40      2560\n",
      "\n",
      "    accuracy                           0.61     10240\n",
      "   macro avg       0.64      0.61      0.60     10240\n",
      "weighted avg       0.64      0.61      0.60     10240\n",
      "\n",
      "EPOCH  40 : train loss 0.340, val loss 1.728, val accuracy 0.590, and val rmse 0.843\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.66      0.74      2560\n",
      "           1       0.63      0.91      0.74      2560\n",
      "           2       0.40      0.59      0.47      2560\n",
      "           3       0.67      0.20      0.31      2560\n",
      "\n",
      "    accuracy                           0.59     10240\n",
      "   macro avg       0.64      0.59      0.57     10240\n",
      "weighted avg       0.64      0.59      0.57     10240\n",
      "\n",
      "EPOCH  45 : train loss 0.296, val loss 1.720, val accuracy 0.602, and val rmse 0.849\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      2560\n",
      "           1       0.70      0.79      0.74      2560\n",
      "           2       0.41      0.65      0.50      2560\n",
      "           3       0.65      0.24      0.35      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.64      0.60      0.59     10240\n",
      "weighted avg       0.64      0.60      0.59     10240\n",
      "\n",
      "EPOCH  50 : train loss 0.263, val loss 1.736, val accuracy 0.605, and val rmse 0.847\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77      2560\n",
      "           1       0.69      0.78      0.73      2560\n",
      "           2       0.42      0.63      0.50      2560\n",
      "           3       0.65      0.25      0.36      2560\n",
      "\n",
      "    accuracy                           0.61     10240\n",
      "   macro avg       0.63      0.61      0.59     10240\n",
      "weighted avg       0.63      0.61      0.59     10240\n",
      "\n",
      "EPOCH  55 : train loss 0.244, val loss 1.652, val accuracy 0.617, and val rmse 0.828\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      2560\n",
      "           1       0.70      0.80      0.75      2560\n",
      "           2       0.42      0.59      0.49      2560\n",
      "           3       0.65      0.33      0.44      2560\n",
      "\n",
      "    accuracy                           0.62     10240\n",
      "   macro avg       0.64      0.62      0.61     10240\n",
      "weighted avg       0.64      0.62      0.61     10240\n",
      "\n",
      "EPOCH  60 : train loss 0.223, val loss 1.877, val accuracy 0.605, and val rmse 0.861\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77      2560\n",
      "           1       0.68      0.80      0.73      2560\n",
      "           2       0.42      0.61      0.49      2560\n",
      "           3       0.66      0.24      0.35      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.63      0.60      0.59     10240\n",
      "weighted avg       0.63      0.60      0.59     10240\n",
      "\n",
      "EPOCH  65 : train loss 0.226, val loss 1.755, val accuracy 0.609, and val rmse 0.836\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77      2560\n",
      "           1       0.70      0.79      0.74      2560\n",
      "           2       0.41      0.59      0.49      2560\n",
      "           3       0.65      0.29      0.40      2560\n",
      "\n",
      "    accuracy                           0.61     10240\n",
      "   macro avg       0.63      0.61      0.60     10240\n",
      "weighted avg       0.63      0.61      0.60     10240\n",
      "\n",
      "EPOCH  70 : train loss 0.191, val loss 2.112, val accuracy 0.597, and val rmse 0.831\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.71      0.76      2560\n",
      "           1       0.66      0.85      0.74      2560\n",
      "           2       0.40      0.63      0.49      2560\n",
      "           3       0.68      0.20      0.31      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.64      0.60      0.58     10240\n",
      "weighted avg       0.64      0.60      0.58     10240\n",
      "\n",
      "EPOCH  75 : train loss 0.172, val loss 1.954, val accuracy 0.596, and val rmse 0.835\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.68      0.75      2560\n",
      "           1       0.69      0.76      0.72      2560\n",
      "           2       0.40      0.66      0.50      2560\n",
      "           3       0.64      0.28      0.40      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.64      0.60      0.59     10240\n",
      "weighted avg       0.64      0.60      0.59     10240\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  80 : train loss 0.167, val loss 2.088, val accuracy 0.604, and val rmse 0.828\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.73      0.77      2560\n",
      "           1       0.70      0.78      0.74      2560\n",
      "           2       0.41      0.66      0.50      2560\n",
      "           3       0.68      0.24      0.36      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.65      0.60      0.59     10240\n",
      "weighted avg       0.65      0.60      0.59     10240\n",
      "\n",
      "EPOCH  85 : train loss 0.153, val loss 2.185, val accuracy 0.597, and val rmse 0.837\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.75      0.78      2560\n",
      "           1       0.71      0.76      0.73      2560\n",
      "           2       0.40      0.66      0.50      2560\n",
      "           3       0.65      0.21      0.32      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.64      0.60      0.58     10240\n",
      "weighted avg       0.64      0.60      0.58     10240\n",
      "\n",
      "EPOCH  90 : train loss 0.155, val loss 2.024, val accuracy 0.605, and val rmse 0.833\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.70      0.76      2560\n",
      "           1       0.71      0.79      0.75      2560\n",
      "           2       0.40      0.64      0.49      2560\n",
      "           3       0.64      0.29      0.40      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.65      0.60      0.60     10240\n",
      "weighted avg       0.65      0.60      0.60     10240\n",
      "\n",
      "EPOCH  95 : train loss 0.125, val loss 2.341, val accuracy 0.601, and val rmse 0.834\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78      2560\n",
      "           1       0.70      0.78      0.74      2560\n",
      "           2       0.40      0.65      0.50      2560\n",
      "           3       0.68      0.22      0.34      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.65      0.60      0.59     10240\n",
      "weighted avg       0.65      0.60      0.59     10240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM (content + title) (num_layers=2), hidden_dim=100 GloVe embeddings emb_size=100, no stop words (train + test), N=600, (batch_size=600) w/ random synonym replacement (on content + title) alpha=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0 : train loss 1.251, val loss 1.188, val accuracy 0.449, and val rmse 1.241\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.61      0.60      2560\n",
      "           1       0.55      0.28      0.37      2560\n",
      "           2       0.30      0.20      0.24      2560\n",
      "           3       0.40      0.71      0.51      2560\n",
      "\n",
      "    accuracy                           0.45     10240\n",
      "   macro avg       0.46      0.45      0.43     10240\n",
      "weighted avg       0.46      0.45      0.43     10240\n",
      "\n",
      "EPOCH  5 : train loss 0.914, val loss 1.005, val accuracy 0.561, and val rmse 0.966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.62      0.66      2560\n",
      "           1       0.63      0.70      0.67      2560\n",
      "           2       0.34      0.29      0.31      2560\n",
      "           3       0.54      0.63      0.58      2560\n",
      "\n",
      "    accuracy                           0.56     10240\n",
      "   macro avg       0.56      0.56      0.56     10240\n",
      "weighted avg       0.56      0.56      0.56     10240\n",
      "\n",
      "EPOCH  10 : train loss 0.669, val loss 1.042, val accuracy 0.591, and val rmse 0.912\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.67      0.72      2560\n",
      "           1       0.57      0.92      0.70      2560\n",
      "           2       0.40      0.30      0.34      2560\n",
      "           3       0.61      0.47      0.53      2560\n",
      "\n",
      "    accuracy                           0.59     10240\n",
      "   macro avg       0.59      0.59      0.57     10240\n",
      "weighted avg       0.59      0.59      0.57     10240\n",
      "\n",
      "EPOCH  15 : train loss 0.542, val loss 1.187, val accuracy 0.567, and val rmse 0.859\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.55      0.68      2560\n",
      "           1       0.66      0.82      0.73      2560\n",
      "           2       0.37      0.63      0.47      2560\n",
      "           3       0.62      0.27      0.37      2560\n",
      "\n",
      "    accuracy                           0.57     10240\n",
      "   macro avg       0.63      0.57      0.56     10240\n",
      "weighted avg       0.63      0.57      0.56     10240\n",
      "\n",
      "EPOCH  20 : train loss 0.467, val loss 1.213, val accuracy 0.610, and val rmse 0.838\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.73      0.77      2560\n",
      "           1       0.67      0.85      0.75      2560\n",
      "           2       0.40      0.50      0.45      2560\n",
      "           3       0.60      0.35      0.45      2560\n",
      "\n",
      "    accuracy                           0.61     10240\n",
      "   macro avg       0.62      0.61      0.60     10240\n",
      "weighted avg       0.62      0.61      0.60     10240\n",
      "\n",
      "EPOCH  25 : train loss 0.389, val loss 1.394, val accuracy 0.601, and val rmse 0.819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.71      0.77      2560\n",
      "           1       0.68      0.82      0.75      2560\n",
      "           2       0.39      0.58      0.47      2560\n",
      "           3       0.61      0.29      0.39      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.63      0.60      0.59     10240\n",
      "weighted avg       0.63      0.60      0.59     10240\n",
      "\n",
      "EPOCH  30 : train loss 0.332, val loss 1.488, val accuracy 0.600, and val rmse 0.825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.69      0.77      2560\n",
      "           1       0.65      0.86      0.74      2560\n",
      "           2       0.40      0.54      0.46      2560\n",
      "           3       0.59      0.31      0.40      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.62      0.60      0.59     10240\n",
      "weighted avg       0.62      0.60      0.59     10240\n",
      "\n",
      "EPOCH  35 : train loss 0.309, val loss 1.599, val accuracy 0.594, and val rmse 0.827\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.68      0.76      2560\n",
      "           1       0.66      0.86      0.75      2560\n",
      "           2       0.39      0.58      0.47      2560\n",
      "           3       0.61      0.26      0.36      2560\n",
      "\n",
      "    accuracy                           0.59     10240\n",
      "   macro avg       0.63      0.59      0.58     10240\n",
      "weighted avg       0.63      0.59      0.58     10240\n",
      "\n",
      "EPOCH  40 : train loss 0.272, val loss 1.655, val accuracy 0.606, and val rmse 0.817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.79      2560\n",
      "           1       0.70      0.81      0.75      2560\n",
      "           2       0.40      0.60      0.48      2560\n",
      "           3       0.61      0.25      0.36      2560\n",
      "\n",
      "    accuracy                           0.61     10240\n",
      "   macro avg       0.63      0.61      0.59     10240\n",
      "weighted avg       0.63      0.61      0.59     10240\n",
      "\n",
      "EPOCH  45 : train loss 0.237, val loss 1.793, val accuracy 0.606, and val rmse 0.822\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.72      0.77      2560\n",
      "           1       0.68      0.84      0.75      2560\n",
      "           2       0.41      0.60      0.48      2560\n",
      "           3       0.63      0.26      0.37      2560\n",
      "\n",
      "    accuracy                           0.61     10240\n",
      "   macro avg       0.64      0.61      0.59     10240\n",
      "weighted avg       0.64      0.61      0.59     10240\n",
      "\n",
      "EPOCH  50 : train loss 0.220, val loss 1.826, val accuracy 0.586, and val rmse 0.826\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.65      0.74      2560\n",
      "           1       0.65      0.82      0.73      2560\n",
      "           2       0.39      0.61      0.48      2560\n",
      "           3       0.60      0.26      0.36      2560\n",
      "\n",
      "    accuracy                           0.59     10240\n",
      "   macro avg       0.63      0.59      0.58     10240\n",
      "weighted avg       0.63      0.59      0.58     10240\n",
      "\n",
      "EPOCH  55 : train loss 0.197, val loss 1.923, val accuracy 0.586, and val rmse 0.819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.69      0.77      2560\n",
      "           1       0.69      0.75      0.72      2560\n",
      "           2       0.39      0.68      0.50      2560\n",
      "           3       0.61      0.22      0.32      2560\n",
      "\n",
      "    accuracy                           0.59     10240\n",
      "   macro avg       0.64      0.59      0.58     10240\n",
      "weighted avg       0.64      0.59      0.58     10240\n",
      "\n",
      "EPOCH  60 : train loss 0.178, val loss 1.980, val accuracy 0.600, and val rmse 0.816\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.72      0.78      2560\n",
      "           1       0.71      0.79      0.74      2560\n",
      "           2       0.40      0.64      0.49      2560\n",
      "           3       0.61      0.25      0.35      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.64      0.60      0.59     10240\n",
      "weighted avg       0.64      0.60      0.59     10240\n",
      "\n",
      "EPOCH  65 : train loss 0.162, val loss 2.103, val accuracy 0.590, and val rmse 0.833\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.68      0.75      2560\n",
      "           1       0.65      0.84      0.73      2560\n",
      "           2       0.40      0.63      0.49      2560\n",
      "           3       0.65      0.21      0.32      2560\n",
      "\n",
      "    accuracy                           0.59     10240\n",
      "   macro avg       0.63      0.59      0.57     10240\n",
      "weighted avg       0.63      0.59      0.57     10240\n",
      "\n",
      "EPOCH  70 : train loss 0.150, val loss 2.330, val accuracy 0.586, and val rmse 0.849\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76      2560\n",
      "           1       0.66      0.83      0.74      2560\n",
      "           2       0.40      0.64      0.49      2560\n",
      "           3       0.66      0.15      0.24      2560\n",
      "\n",
      "    accuracy                           0.59     10240\n",
      "   macro avg       0.63      0.59      0.56     10240\n",
      "weighted avg       0.63      0.59      0.56     10240\n",
      "\n",
      "EPOCH  75 : train loss 0.135, val loss 2.143, val accuracy 0.595, and val rmse 0.819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.72      0.78      2560\n",
      "           1       0.71      0.76      0.74      2560\n",
      "           2       0.39      0.68      0.50      2560\n",
      "           3       0.63      0.22      0.33      2560\n",
      "\n",
      "    accuracy                           0.60     10240\n",
      "   macro avg       0.64      0.60      0.58     10240\n",
      "weighted avg       0.64      0.60      0.58     10240\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  80 : train loss 0.130, val loss 2.152, val accuracy 0.609, and val rmse 0.834\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.78      2560\n",
      "           1       0.69      0.83      0.75      2560\n",
      "           2       0.41      0.61      0.49      2560\n",
      "           3       0.63      0.23      0.33      2560\n",
      "\n",
      "    accuracy                           0.61     10240\n",
      "   macro avg       0.63      0.61      0.59     10240\n",
      "weighted avg       0.63      0.61      0.59     10240\n",
      "\n",
      "EPOCH  85 : train loss 0.117, val loss 2.248, val accuracy 0.591, and val rmse 0.825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.68      0.75      2560\n",
      "           1       0.67      0.79      0.73      2560\n",
      "           2       0.40      0.65      0.50      2560\n",
      "           3       0.63      0.24      0.35      2560\n",
      "\n",
      "    accuracy                           0.59     10240\n",
      "   macro avg       0.64      0.59      0.58     10240\n",
      "weighted avg       0.64      0.59      0.58     10240\n",
      "\n",
      "EPOCH  90 : train loss 0.113, val loss 2.207, val accuracy 0.589, and val rmse 0.828\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.68      0.75      2560\n",
      "           1       0.65      0.80      0.71      2560\n",
      "           2       0.40      0.61      0.49      2560\n",
      "           3       0.60      0.27      0.37      2560\n",
      "\n",
      "    accuracy                           0.59     10240\n",
      "   macro avg       0.63      0.59      0.58     10240\n",
      "weighted avg       0.63      0.59      0.58     10240\n",
      "\n",
      "EPOCH  95 : train loss 0.101, val loss 2.283, val accuracy 0.589, and val rmse 0.811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.70      0.76      2560\n",
      "           1       0.65      0.79      0.71      2560\n",
      "           2       0.40      0.64      0.49      2560\n",
      "           3       0.64      0.23      0.34      2560\n",
      "\n",
      "    accuracy                           0.59     10240\n",
      "   macro avg       0.63      0.59      0.58     10240\n",
      "weighted avg       0.63      0.59      0.58     10240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM (content + title) (num_layers=2), hidden_dim=50 GloVe embeddings emb_size=50, no stop words (train + test), N=600, (batch_size=500) w/ random synonym replacement (on content + title) alpha=0.5 (80/20 split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0 : train loss 1.292, val loss 1.219, val accuracy 0.443, and val rmse 1.255\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.61      0.59      1712\n",
      "           1       0.43      0.39      0.41      1712\n",
      "           2       0.34      0.20      0.25      1712\n",
      "           3       0.40      0.56      0.47      1712\n",
      "\n",
      "    accuracy                           0.44      6848\n",
      "   macro avg       0.43      0.44      0.43      6848\n",
      "weighted avg       0.43      0.44      0.43      6848\n",
      "\n",
      "EPOCH  5 : train loss 0.997, val loss 1.009, val accuracy 0.552, and val rmse 0.995\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66      1712\n",
      "           1       0.55      0.70      0.62      1712\n",
      "           2       0.38      0.28      0.33      1712\n",
      "           3       0.56      0.57      0.56      1712\n",
      "\n",
      "    accuracy                           0.55      6848\n",
      "   macro avg       0.54      0.55      0.54      6848\n",
      "weighted avg       0.54      0.55      0.54      6848\n",
      "\n",
      "EPOCH  10 : train loss 0.997, val loss 1.025, val accuracy 0.549, and val rmse 0.989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.70      0.69      1712\n",
      "           1       0.59      0.55      0.57      1712\n",
      "           2       0.37      0.27      0.31      1712\n",
      "           3       0.52      0.68      0.59      1712\n",
      "\n",
      "    accuracy                           0.55      6848\n",
      "   macro avg       0.54      0.55      0.54      6848\n",
      "weighted avg       0.54      0.55      0.54      6848\n",
      "\n",
      "EPOCH  15 : train loss 0.854, val loss 0.955, val accuracy 0.580, and val rmse 0.925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.69      0.72      1712\n",
      "           1       0.58      0.81      0.68      1712\n",
      "           2       0.36      0.25      0.30      1712\n",
      "           3       0.57      0.57      0.57      1712\n",
      "\n",
      "    accuracy                           0.58      6848\n",
      "   macro avg       0.57      0.58      0.57      6848\n",
      "weighted avg       0.57      0.58      0.57      6848\n",
      "\n",
      "EPOCH  20 : train loss 0.758, val loss 0.924, val accuracy 0.593, and val rmse 0.910\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.64      0.71      1712\n",
      "           1       0.57      0.91      0.70      1712\n",
      "           2       0.40      0.26      0.31      1712\n",
      "           3       0.59      0.56      0.57      1712\n",
      "\n",
      "    accuracy                           0.59      6848\n",
      "   macro avg       0.59      0.59      0.57      6848\n",
      "weighted avg       0.59      0.59      0.57      6848\n",
      "\n",
      "EPOCH  25 : train loss 0.726, val loss 1.055, val accuracy 0.567, and val rmse 0.913\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.63      0.70      1712\n",
      "           1       0.52      0.89      0.66      1712\n",
      "           2       0.41      0.34      0.37      1712\n",
      "           3       0.63      0.41      0.50      1712\n",
      "\n",
      "    accuracy                           0.57      6848\n",
      "   macro avg       0.59      0.57      0.56      6848\n",
      "weighted avg       0.59      0.57      0.56      6848\n",
      "\n",
      "EPOCH  30 : train loss 0.635, val loss 1.123, val accuracy 0.559, and val rmse 0.905\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.61      0.71      1712\n",
      "           1       0.48      0.96      0.64      1712\n",
      "           2       0.41      0.30      0.35      1712\n",
      "           3       0.68      0.37      0.48      1712\n",
      "\n",
      "    accuracy                           0.56      6848\n",
      "   macro avg       0.60      0.56      0.54      6848\n",
      "weighted avg       0.60      0.56      0.54      6848\n",
      "\n",
      "EPOCH  35 : train loss 0.595, val loss 1.086, val accuracy 0.594, and val rmse 0.899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.74      1712\n",
      "           1       0.56      0.90      0.69      1712\n",
      "           2       0.43      0.38      0.40      1712\n",
      "           3       0.67      0.36      0.47      1712\n",
      "\n",
      "    accuracy                           0.59      6848\n",
      "   macro avg       0.61      0.59      0.58      6848\n",
      "weighted avg       0.61      0.59      0.58      6848\n",
      "\n",
      "EPOCH  40 : train loss 0.536, val loss 1.112, val accuracy 0.595, and val rmse 0.861\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.65      0.74      1712\n",
      "           1       0.54      0.92      0.68      1712\n",
      "           2       0.43      0.39      0.41      1712\n",
      "           3       0.66      0.41      0.51      1712\n",
      "\n",
      "    accuracy                           0.59      6848\n",
      "   macro avg       0.62      0.59      0.59      6848\n",
      "weighted avg       0.62      0.59      0.59      6848\n",
      "\n",
      "EPOCH  45 : train loss 0.525, val loss 1.060, val accuracy 0.616, and val rmse 0.836\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.64      0.74      1712\n",
      "           1       0.62      0.86      0.72      1712\n",
      "           2       0.42      0.44      0.43      1712\n",
      "           3       0.62      0.52      0.56      1712\n",
      "\n",
      "    accuracy                           0.62      6848\n",
      "   macro avg       0.64      0.62      0.62      6848\n",
      "weighted avg       0.64      0.62      0.62      6848\n",
      "\n",
      "EPOCH  50 : train loss 0.467, val loss 1.205, val accuracy 0.591, and val rmse 0.839\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.59      0.71      1712\n",
      "           1       0.58      0.88      0.70      1712\n",
      "           2       0.41      0.50      0.45      1712\n",
      "           3       0.64      0.39      0.49      1712\n",
      "\n",
      "    accuracy                           0.59      6848\n",
      "   macro avg       0.63      0.59      0.59      6848\n",
      "weighted avg       0.63      0.59      0.59      6848\n",
      "\n",
      "EPOCH  55 : train loss 0.430, val loss 1.232, val accuracy 0.594, and val rmse 0.840\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.64      0.74      1712\n",
      "           1       0.56      0.91      0.70      1712\n",
      "           2       0.42      0.45      0.43      1712\n",
      "           3       0.65      0.38      0.47      1712\n",
      "\n",
      "    accuracy                           0.59      6848\n",
      "   macro avg       0.63      0.59      0.59      6848\n",
      "weighted avg       0.63      0.59      0.59      6848\n",
      "\n",
      "EPOCH  60 : train loss 0.402, val loss 1.515, val accuracy 0.551, and val rmse 0.875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.61      0.71      1712\n",
      "           1       0.50      0.92      0.64      1712\n",
      "           2       0.41      0.44      0.42      1712\n",
      "           3       0.67      0.24      0.35      1712\n",
      "\n",
      "    accuracy                           0.55      6848\n",
      "   macro avg       0.61      0.55      0.53      6848\n",
      "weighted avg       0.61      0.55      0.53      6848\n",
      "\n",
      "EPOCH  65 : train loss 0.386, val loss 1.576, val accuracy 0.565, and val rmse 0.875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.66      0.74      1712\n",
      "           1       0.51      0.93      0.66      1712\n",
      "           2       0.42      0.45      0.43      1712\n",
      "           3       0.68      0.22      0.33      1712\n",
      "\n",
      "    accuracy                           0.56      6848\n",
      "   macro avg       0.61      0.56      0.54      6848\n",
      "weighted avg       0.61      0.56      0.54      6848\n",
      "\n",
      "EPOCH  70 : train loss 0.365, val loss 1.323, val accuracy 0.609, and val rmse 0.809\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.69      0.77      1712\n",
      "           1       0.66      0.81      0.73      1712\n",
      "           2       0.41      0.60      0.49      1712\n",
      "           3       0.64      0.34      0.44      1712\n",
      "\n",
      "    accuracy                           0.61      6848\n",
      "   macro avg       0.64      0.61      0.61      6848\n",
      "weighted avg       0.64      0.61      0.61      6848\n",
      "\n",
      "EPOCH  75 : train loss 0.352, val loss 1.504, val accuracy 0.590, and val rmse 0.842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.65      0.74      1712\n",
      "           1       0.59      0.88      0.71      1712\n",
      "           2       0.42      0.55      0.47      1712\n",
      "           3       0.66      0.27      0.39      1712\n",
      "\n",
      "    accuracy                           0.59      6848\n",
      "   macro avg       0.63      0.59      0.58      6848\n",
      "weighted avg       0.63      0.59      0.58      6848\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  80 : train loss 0.335, val loss 1.814, val accuracy 0.576, and val rmse 0.896\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.75      1712\n",
      "           1       0.58      0.89      0.70      1712\n",
      "           2       0.41      0.51      0.45      1712\n",
      "           3       0.67      0.17      0.27      1712\n",
      "\n",
      "    accuracy                           0.58      6848\n",
      "   macro avg       0.61      0.58      0.54      6848\n",
      "weighted avg       0.61      0.58      0.54      6848\n",
      "\n",
      "EPOCH  85 : train loss 0.315, val loss 1.516, val accuracy 0.605, and val rmse 0.814\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.69      0.76      1712\n",
      "           1       0.65      0.83      0.73      1712\n",
      "           2       0.42      0.60      0.49      1712\n",
      "           3       0.63      0.31      0.41      1712\n",
      "\n",
      "    accuracy                           0.61      6848\n",
      "   macro avg       0.64      0.61      0.60      6848\n",
      "weighted avg       0.64      0.61      0.60      6848\n",
      "\n",
      "EPOCH  90 : train loss 0.304, val loss 1.511, val accuracy 0.596, and val rmse 0.819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.65      0.74      1712\n",
      "           1       0.62      0.84      0.71      1712\n",
      "           2       0.41      0.56      0.47      1712\n",
      "           3       0.63      0.33      0.44      1712\n",
      "\n",
      "    accuracy                           0.60      6848\n",
      "   macro avg       0.63      0.60      0.59      6848\n",
      "weighted avg       0.63      0.60      0.59      6848\n",
      "\n",
      "EPOCH  95 : train loss 0.288, val loss 1.641, val accuracy 0.592, and val rmse 0.822\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.66      0.75      1712\n",
      "           1       0.61      0.83      0.70      1712\n",
      "           2       0.41      0.59      0.49      1712\n",
      "           3       0.64      0.28      0.39      1712\n",
      "\n",
      "    accuracy                           0.59      6848\n",
      "   macro avg       0.63      0.59      0.58      6848\n",
      "weighted avg       0.63      0.59      0.58      6848\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM (content + title) (num_layers=2), hidden_dim=100 GloVe embeddings emb_size=200, no stop words (train + test), N=600, (batch_size=250) w/ random synonym replacement (on content + title) alpha=0.5 (80/20 split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0 : train loss 1.132, val loss 1.043, val accuracy 0.535, and val rmse 1.060\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.68      0.67      1712\n",
      "           1       0.63      0.49      0.55      1712\n",
      "           2       0.37      0.28      0.32      1712\n",
      "           3       0.48      0.69      0.57      1712\n",
      "\n",
      "    accuracy                           0.54      6848\n",
      "   macro avg       0.54      0.54      0.53      6848\n",
      "weighted avg       0.54      0.54      0.53      6848\n",
      "\n",
      "EPOCH  5 : train loss 0.633, val loss 1.094, val accuracy 0.580, and val rmse 0.903\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.64      0.70      1712\n",
      "           1       0.62      0.84      0.71      1712\n",
      "           2       0.39      0.43      0.41      1712\n",
      "           3       0.57      0.41      0.48      1712\n",
      "\n",
      "    accuracy                           0.58      6848\n",
      "   macro avg       0.59      0.58      0.58      6848\n",
      "weighted avg       0.59      0.58      0.58      6848\n",
      "\n",
      "EPOCH  10 : train loss 0.474, val loss 1.320, val accuracy 0.593, and val rmse 0.868\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76      1712\n",
      "           1       0.65      0.85      0.74      1712\n",
      "           2       0.40      0.51      0.45      1712\n",
      "           3       0.57      0.30      0.39      1712\n",
      "\n",
      "    accuracy                           0.59      6848\n",
      "   macro avg       0.61      0.59      0.58      6848\n",
      "weighted avg       0.61      0.59      0.58      6848\n",
      "\n",
      "EPOCH  15 : train loss 0.381, val loss 1.454, val accuracy 0.607, and val rmse 0.814\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.76      0.78      1712\n",
      "           1       0.69      0.81      0.74      1712\n",
      "           2       0.41      0.60      0.49      1712\n",
      "           3       0.63      0.26      0.37      1712\n",
      "\n",
      "    accuracy                           0.61      6848\n",
      "   macro avg       0.63      0.61      0.60      6848\n",
      "weighted avg       0.63      0.61      0.60      6848\n",
      "\n",
      "EPOCH  20 : train loss 0.304, val loss 1.602, val accuracy 0.598, and val rmse 0.823\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.69      0.76      1712\n",
      "           1       0.70      0.77      0.74      1712\n",
      "           2       0.40      0.63      0.49      1712\n",
      "           3       0.59      0.30      0.40      1712\n",
      "\n",
      "    accuracy                           0.60      6848\n",
      "   macro avg       0.64      0.60      0.60      6848\n",
      "weighted avg       0.64      0.60      0.60      6848\n",
      "\n",
      "EPOCH  25 : train loss 0.250, val loss 1.891, val accuracy 0.596, and val rmse 0.812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.69      0.76      1712\n",
      "           1       0.70      0.78      0.74      1712\n",
      "           2       0.40      0.65      0.50      1712\n",
      "           3       0.62      0.26      0.36      1712\n",
      "\n",
      "    accuracy                           0.60      6848\n",
      "   macro avg       0.64      0.60      0.59      6848\n",
      "weighted avg       0.64      0.60      0.59      6848\n",
      "\n",
      "EPOCH  30 : train loss 0.213, val loss 1.841, val accuracy 0.613, and val rmse 0.810\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.78      1712\n",
      "           1       0.70      0.82      0.76      1712\n",
      "           2       0.41      0.57      0.48      1712\n",
      "           3       0.64      0.28      0.39      1712\n",
      "\n",
      "    accuracy                           0.61      6848\n",
      "   macro avg       0.63      0.61      0.60      6848\n",
      "weighted avg       0.63      0.61      0.60      6848\n",
      "\n",
      "EPOCH  35 : train loss 0.188, val loss 1.867, val accuracy 0.591, and val rmse 0.826\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.66      0.75      1712\n",
      "           1       0.73      0.72      0.73      1712\n",
      "           2       0.39      0.67      0.49      1712\n",
      "           3       0.60      0.32      0.41      1712\n",
      "\n",
      "    accuracy                           0.59      6848\n",
      "   macro avg       0.65      0.59      0.60      6848\n",
      "weighted avg       0.65      0.59      0.60      6848\n",
      "\n",
      "EPOCH  40 : train loss 0.164, val loss 2.133, val accuracy 0.588, and val rmse 0.818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.63      0.74      1712\n",
      "           1       0.70      0.79      0.74      1712\n",
      "           2       0.38      0.66      0.49      1712\n",
      "           3       0.62      0.27      0.38      1712\n",
      "\n",
      "    accuracy                           0.59      6848\n",
      "   macro avg       0.65      0.59      0.59      6848\n",
      "weighted avg       0.65      0.59      0.59      6848\n",
      "\n",
      "EPOCH  45 : train loss 0.141, val loss 2.241, val accuracy 0.594, and val rmse 0.809\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.68      0.75      1712\n",
      "           1       0.69      0.81      0.74      1712\n",
      "           2       0.39      0.65      0.49      1712\n",
      "           3       0.64      0.23      0.34      1712\n",
      "\n",
      "    accuracy                           0.59      6848\n",
      "   macro avg       0.64      0.59      0.58      6848\n",
      "weighted avg       0.64      0.59      0.58      6848\n",
      "\n",
      "EPOCH  50 : train loss 0.125, val loss 2.429, val accuracy 0.599, and val rmse 0.802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.72      0.77      1712\n",
      "           1       0.70      0.80      0.74      1712\n",
      "           2       0.40      0.67      0.50      1712\n",
      "           3       0.66      0.21      0.31      1712\n",
      "\n",
      "    accuracy                           0.60      6848\n",
      "   macro avg       0.65      0.60      0.58      6848\n",
      "weighted avg       0.65      0.60      0.58      6848\n",
      "\n",
      "EPOCH  55 : train loss 0.113, val loss 2.332, val accuracy 0.598, and val rmse 0.811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.66      0.75      1712\n",
      "           1       0.69      0.79      0.74      1712\n",
      "           2       0.40      0.67      0.50      1712\n",
      "           3       0.64      0.28      0.39      1712\n",
      "\n",
      "    accuracy                           0.60      6848\n",
      "   macro avg       0.65      0.60      0.59      6848\n",
      "weighted avg       0.65      0.60      0.59      6848\n",
      "\n",
      "EPOCH  60 : train loss 0.104, val loss 2.586, val accuracy 0.575, and val rmse 0.825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.62      0.72      1712\n",
      "           1       0.64      0.81      0.72      1712\n",
      "           2       0.39      0.66      0.49      1712\n",
      "           3       0.62      0.21      0.32      1712\n",
      "\n",
      "    accuracy                           0.57      6848\n",
      "   macro avg       0.63      0.57      0.56      6848\n",
      "weighted avg       0.63      0.57      0.56      6848\n",
      "\n",
      "EPOCH  65 : train loss 0.094, val loss 2.412, val accuracy 0.597, and val rmse 0.815\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.68      0.76      1712\n",
      "           1       0.71      0.79      0.75      1712\n",
      "           2       0.40      0.68      0.50      1712\n",
      "           3       0.61      0.24      0.34      1712\n",
      "\n",
      "    accuracy                           0.60      6848\n",
      "   macro avg       0.64      0.60      0.59      6848\n",
      "weighted avg       0.64      0.60      0.59      6848\n",
      "\n",
      "EPOCH  70 : train loss 0.092, val loss 2.536, val accuracy 0.584, and val rmse 0.822\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.64      0.74      1712\n",
      "           1       0.70      0.78      0.74      1712\n",
      "           2       0.39      0.71      0.50      1712\n",
      "           3       0.64      0.21      0.31      1712\n",
      "\n",
      "    accuracy                           0.58      6848\n",
      "   macro avg       0.65      0.58      0.57      6848\n",
      "weighted avg       0.65      0.58      0.57      6848\n",
      "\n",
      "EPOCH  75 : train loss 0.088, val loss 2.713, val accuracy 0.587, and val rmse 0.812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.64      0.74      1712\n",
      "           1       0.70      0.78      0.74      1712\n",
      "           2       0.39      0.71      0.50      1712\n",
      "           3       0.64      0.23      0.33      1712\n",
      "\n",
      "    accuracy                           0.59      6848\n",
      "   macro avg       0.65      0.59      0.58      6848\n",
      "weighted avg       0.65      0.59      0.58      6848\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_INTERNAL_ERROR",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-b6bbceada84a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-a41a3ed29eee>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0msum_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_rmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m5\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"EPOCH \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\": train loss %.3f, val loss %.3f, val accuracy %.3f, and val rmse %.3f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msum_loss\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_rmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-a41a3ed29eee>\u001b[0m in \u001b[0;36mvalidation_metrics\u001b[1;34m(model, valid_dl)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[1;31m#loss = criterion(y_hat, y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-eac30f823119>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, l)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mht\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mct\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mht\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 570\u001b[1;33m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    571\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR"
     ]
    }
   ],
   "source": [
    "train_model(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM (content + title) (num_layers=2), hidden_dim=50 GloVe embeddings emb_size=50, no stop words (train + test), N=450, (batch_size=500) w/ random synonym replacement (on content + title) alpha=0.5 (80/20 split), 9000 points/class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0 : train loss 1.264, val loss 1.233, val accuracy 0.435, and val rmse 1.306\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.67      0.59      2247\n",
      "           1       0.62      0.09      0.15      2247\n",
      "           2       0.33      0.19      0.24      2247\n",
      "           3       0.39      0.79      0.52      2247\n",
      "\n",
      "    accuracy                           0.44      8988\n",
      "   macro avg       0.47      0.44      0.38      8988\n",
      "weighted avg       0.47      0.44      0.38      8988\n",
      "\n",
      "EPOCH  5 : train loss 1.040, val loss 1.261, val accuracy 0.389, and val rmse 1.149\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.65      0.60      2247\n",
      "           1       0.47      0.01      0.01      2247\n",
      "           2       0.30      0.71      0.42      2247\n",
      "           3       0.45      0.19      0.27      2247\n",
      "\n",
      "    accuracy                           0.39      8988\n",
      "   macro avg       0.44      0.39      0.32      8988\n",
      "weighted avg       0.44      0.39      0.32      8988\n",
      "\n",
      "EPOCH  10 : train loss 0.989, val loss 1.039, val accuracy 0.530, and val rmse 1.120\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.76      0.66      2247\n",
      "           1       0.58      0.63      0.61      2247\n",
      "           2       0.35      0.20      0.26      2247\n",
      "           3       0.51      0.53      0.52      2247\n",
      "\n",
      "    accuracy                           0.53      8988\n",
      "   macro avg       0.51      0.53      0.51      8988\n",
      "weighted avg       0.51      0.53      0.51      8988\n",
      "\n",
      "EPOCH  15 : train loss 0.821, val loss 0.944, val accuracy 0.601, and val rmse 1.021\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.81      0.71      2247\n",
      "           1       0.66      0.80      0.72      2247\n",
      "           2       0.41      0.22      0.29      2247\n",
      "           3       0.60      0.57      0.58      2247\n",
      "\n",
      "    accuracy                           0.60      8988\n",
      "   macro avg       0.57      0.60      0.58      8988\n",
      "weighted avg       0.57      0.60      0.58      8988\n",
      "\n",
      "EPOCH  20 : train loss 0.727, val loss 0.945, val accuracy 0.596, and val rmse 0.922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.51      0.63      2247\n",
      "           1       0.59      0.91      0.71      2247\n",
      "           2       0.42      0.31      0.35      2247\n",
      "           3       0.59      0.66      0.62      2247\n",
      "\n",
      "    accuracy                           0.60      8988\n",
      "   macro avg       0.61      0.60      0.58      8988\n",
      "weighted avg       0.61      0.60      0.58      8988\n",
      "\n",
      "EPOCH  25 : train loss 0.688, val loss 0.923, val accuracy 0.628, and val rmse 0.947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.78      0.74      2247\n",
      "           1       0.68      0.89      0.77      2247\n",
      "           2       0.43      0.33      0.38      2247\n",
      "           3       0.64      0.50      0.56      2247\n",
      "\n",
      "    accuracy                           0.63      8988\n",
      "   macro avg       0.61      0.63      0.61      8988\n",
      "weighted avg       0.61      0.63      0.61      8988\n",
      "\n",
      "EPOCH  30 : train loss 0.619, val loss 0.858, val accuracy 0.644, and val rmse 0.871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77      2247\n",
      "           1       0.69      0.90      0.78      2247\n",
      "           2       0.42      0.35      0.38      2247\n",
      "           3       0.63      0.57      0.60      2247\n",
      "\n",
      "    accuracy                           0.64      8988\n",
      "   macro avg       0.63      0.64      0.63      8988\n",
      "weighted avg       0.63      0.64      0.63      8988\n",
      "\n",
      "EPOCH  35 : train loss 0.568, val loss 0.905, val accuracy 0.649, and val rmse 0.884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.78      2247\n",
      "           1       0.70      0.88      0.78      2247\n",
      "           2       0.45      0.39      0.41      2247\n",
      "           3       0.64      0.55      0.59      2247\n",
      "\n",
      "    accuracy                           0.65      8988\n",
      "   macro avg       0.64      0.65      0.64      8988\n",
      "weighted avg       0.64      0.65      0.64      8988\n",
      "\n",
      "EPOCH  40 : train loss 0.524, val loss 1.167, val accuracy 0.618, and val rmse 0.944\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.82      0.76      2247\n",
      "           1       0.65      0.94      0.76      2247\n",
      "           2       0.42      0.40      0.41      2247\n",
      "           3       0.69      0.31      0.43      2247\n",
      "\n",
      "    accuracy                           0.62      8988\n",
      "   macro avg       0.62      0.62      0.59      8988\n",
      "weighted avg       0.62      0.62      0.59      8988\n",
      "\n",
      "EPOCH  45 : train loss 0.485, val loss 0.953, val accuracy 0.651, and val rmse 0.810\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.76      0.80      2247\n",
      "           1       0.71      0.87      0.78      2247\n",
      "           2       0.43      0.49      0.46      2247\n",
      "           3       0.65      0.49      0.56      2247\n",
      "\n",
      "    accuracy                           0.65      8988\n",
      "   macro avg       0.66      0.65      0.65      8988\n",
      "weighted avg       0.66      0.65      0.65      8988\n",
      "\n",
      "EPOCH  50 : train loss 0.453, val loss 0.990, val accuracy 0.644, and val rmse 0.797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.75      0.80      2247\n",
      "           1       0.71      0.86      0.78      2247\n",
      "           2       0.42      0.52      0.46      2247\n",
      "           3       0.64      0.45      0.53      2247\n",
      "\n",
      "    accuracy                           0.64      8988\n",
      "   macro avg       0.66      0.64      0.64      8988\n",
      "weighted avg       0.66      0.64      0.64      8988\n",
      "\n",
      "EPOCH  55 : train loss 0.430, val loss 1.046, val accuracy 0.647, and val rmse 0.807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.78      0.81      2247\n",
      "           1       0.68      0.91      0.78      2247\n",
      "           2       0.43      0.46      0.44      2247\n",
      "           3       0.65      0.45      0.53      2247\n",
      "\n",
      "    accuracy                           0.65      8988\n",
      "   macro avg       0.65      0.65      0.64      8988\n",
      "weighted avg       0.65      0.65      0.64      8988\n",
      "\n",
      "EPOCH  60 : train loss 0.416, val loss 1.120, val accuracy 0.645, and val rmse 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82      2247\n",
      "           1       0.72      0.89      0.80      2247\n",
      "           2       0.42      0.53      0.47      2247\n",
      "           3       0.66      0.36      0.47      2247\n",
      "\n",
      "    accuracy                           0.65      8988\n",
      "   macro avg       0.66      0.65      0.64      8988\n",
      "weighted avg       0.66      0.65      0.64      8988\n",
      "\n",
      "EPOCH  65 : train loss 0.380, val loss 1.147, val accuracy 0.644, and val rmse 0.794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      2247\n",
      "           1       0.74      0.81      0.78      2247\n",
      "           2       0.42      0.57      0.48      2247\n",
      "           3       0.64      0.39      0.49      2247\n",
      "\n",
      "    accuracy                           0.64      8988\n",
      "   macro avg       0.66      0.64      0.64      8988\n",
      "weighted avg       0.66      0.64      0.64      8988\n",
      "\n",
      "EPOCH  70 : train loss 0.374, val loss 1.195, val accuracy 0.631, and val rmse 0.787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.70      0.79      2247\n",
      "           1       0.69      0.86      0.76      2247\n",
      "           2       0.42      0.56      0.48      2247\n",
      "           3       0.65      0.40      0.50      2247\n",
      "\n",
      "    accuracy                           0.63      8988\n",
      "   macro avg       0.66      0.63      0.63      8988\n",
      "weighted avg       0.66      0.63      0.63      8988\n",
      "\n",
      "EPOCH  75 : train loss 0.345, val loss 1.256, val accuracy 0.630, and val rmse 0.785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.75      0.80      2247\n",
      "           1       0.71      0.87      0.78      2247\n",
      "           2       0.41      0.58      0.48      2247\n",
      "           3       0.65      0.33      0.43      2247\n",
      "\n",
      "    accuracy                           0.63      8988\n",
      "   macro avg       0.66      0.63      0.62      8988\n",
      "weighted avg       0.66      0.63      0.62      8988\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  80 : train loss 0.335, val loss 1.367, val accuracy 0.622, and val rmse 0.788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.72      0.79      2247\n",
      "           1       0.66      0.91      0.76      2247\n",
      "           2       0.41      0.55      0.47      2247\n",
      "           3       0.68      0.30      0.41      2247\n",
      "\n",
      "    accuracy                           0.62      8988\n",
      "   macro avg       0.66      0.62      0.61      8988\n",
      "weighted avg       0.66      0.62      0.61      8988\n",
      "\n",
      "EPOCH  85 : train loss 0.319, val loss 1.395, val accuracy 0.613, and val rmse 0.790\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.66      0.76      2247\n",
      "           1       0.67      0.87      0.76      2247\n",
      "           2       0.40      0.61      0.49      2247\n",
      "           3       0.67      0.32      0.43      2247\n",
      "\n",
      "    accuracy                           0.61      8988\n",
      "   macro avg       0.66      0.61      0.61      8988\n",
      "weighted avg       0.66      0.61      0.61      8988\n",
      "\n",
      "EPOCH  90 : train loss 0.305, val loss 1.506, val accuracy 0.619, and val rmse 0.792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.76      0.80      2247\n",
      "           1       0.67      0.88      0.76      2247\n",
      "           2       0.41      0.58      0.48      2247\n",
      "           3       0.69      0.26      0.38      2247\n",
      "\n",
      "    accuracy                           0.62      8988\n",
      "   macro avg       0.66      0.62      0.60      8988\n",
      "weighted avg       0.66      0.62      0.60      8988\n",
      "\n",
      "EPOCH  95 : train loss 0.293, val loss 1.404, val accuracy 0.618, and val rmse 0.782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.69      0.79      2247\n",
      "           1       0.73      0.79      0.76      2247\n",
      "           2       0.40      0.67      0.50      2247\n",
      "           3       0.67      0.32      0.43      2247\n",
      "\n",
      "    accuracy                           0.62      8988\n",
      "   macro avg       0.68      0.62      0.62      8988\n",
      "weighted avg       0.68      0.62      0.62      8988\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## BiLSTM (content + title) (num_layers=2), hidden_dim=50 GloVe embeddings emb_size=100, no stop words (train + test), N=450, (batch_size=500) w/ random synonym replacement (on content + title) alpha=0.5 (80/20 split), 9000 points/class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0 : train loss 1.231, val loss 1.157, val accuracy 0.490, and val rmse 1.272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.76      0.61      2247\n",
      "           1       0.61      0.38      0.47      2247\n",
      "           2       0.38      0.10      0.15      2247\n",
      "           3       0.44      0.73      0.55      2247\n",
      "\n",
      "    accuracy                           0.49      8988\n",
      "   macro avg       0.49      0.49      0.45      8988\n",
      "weighted avg       0.49      0.49      0.45      8988\n",
      "\n",
      "EPOCH  5 : train loss 0.901, val loss 1.079, val accuracy 0.531, and val rmse 1.147\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.58      0.64      2247\n",
      "           1       0.70      0.53      0.60      2247\n",
      "           2       0.33      0.22      0.27      2247\n",
      "           3       0.46      0.79      0.58      2247\n",
      "\n",
      "    accuracy                           0.53      8988\n",
      "   macro avg       0.55      0.53      0.52      8988\n",
      "weighted avg       0.55      0.53      0.52      8988\n",
      "\n",
      "EPOCH  10 : train loss 0.868, val loss 1.018, val accuracy 0.565, and val rmse 1.106\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.84      0.69      2247\n",
      "           1       0.68      0.61      0.64      2247\n",
      "           2       0.38      0.15      0.21      2247\n",
      "           3       0.52      0.66      0.58      2247\n",
      "\n",
      "    accuracy                           0.57      8988\n",
      "   macro avg       0.54      0.57      0.53      8988\n",
      "weighted avg       0.54      0.57      0.53      8988\n",
      "\n",
      "EPOCH  15 : train loss 0.703, val loss 0.885, val accuracy 0.622, and val rmse 0.927\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76      2247\n",
      "           1       0.66      0.89      0.76      2247\n",
      "           2       0.40      0.28      0.33      2247\n",
      "           3       0.59      0.56      0.57      2247\n",
      "\n",
      "    accuracy                           0.62      8988\n",
      "   macro avg       0.60      0.62      0.60      8988\n",
      "weighted avg       0.60      0.62      0.60      8988\n",
      "\n",
      "EPOCH  20 : train loss 0.635, val loss 1.081, val accuracy 0.598, and val rmse 0.997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.84      0.75      2247\n",
      "           1       0.64      0.86      0.73      2247\n",
      "           2       0.40      0.30      0.34      2247\n",
      "           3       0.60      0.39      0.47      2247\n",
      "\n",
      "    accuracy                           0.60      8988\n",
      "   macro avg       0.58      0.60      0.57      8988\n",
      "weighted avg       0.58      0.60      0.57      8988\n",
      "\n",
      "EPOCH  25 : train loss 0.530, val loss 0.962, val accuracy 0.634, and val rmse 0.844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.79      2247\n",
      "           1       0.74      0.80      0.77      2247\n",
      "           2       0.41      0.44      0.42      2247\n",
      "           3       0.59      0.54      0.56      2247\n",
      "\n",
      "    accuracy                           0.63      8988\n",
      "   macro avg       0.64      0.63      0.64      8988\n",
      "weighted avg       0.64      0.63      0.64      8988\n",
      "\n",
      "EPOCH  30 : train loss 0.468, val loss 1.025, val accuracy 0.641, and val rmse 0.801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.76      0.81      2247\n",
      "           1       0.71      0.85      0.77      2247\n",
      "           2       0.42      0.49      0.45      2247\n",
      "           3       0.62      0.47      0.53      2247\n",
      "\n",
      "    accuracy                           0.64      8988\n",
      "   macro avg       0.65      0.64      0.64      8988\n",
      "weighted avg       0.65      0.64      0.64      8988\n",
      "\n",
      "EPOCH  35 : train loss 0.428, val loss 1.079, val accuracy 0.643, and val rmse 0.799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.78      0.82      2247\n",
      "           1       0.71      0.89      0.79      2247\n",
      "           2       0.41      0.48      0.44      2247\n",
      "           3       0.62      0.42      0.50      2247\n",
      "\n",
      "    accuracy                           0.64      8988\n",
      "   macro avg       0.65      0.64      0.64      8988\n",
      "weighted avg       0.65      0.64      0.64      8988\n",
      "\n",
      "EPOCH  40 : train loss 0.379, val loss 1.250, val accuracy 0.603, and val rmse 0.824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.66      0.76      2247\n",
      "           1       0.70      0.84      0.76      2247\n",
      "           2       0.39      0.59      0.47      2247\n",
      "           3       0.60      0.33      0.42      2247\n",
      "\n",
      "    accuracy                           0.60      8988\n",
      "   macro avg       0.65      0.60      0.60      8988\n",
      "weighted avg       0.65      0.60      0.60      8988\n",
      "\n",
      "EPOCH  45 : train loss 0.346, val loss 1.323, val accuracy 0.636, and val rmse 0.777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82      2247\n",
      "           1       0.70      0.89      0.78      2247\n",
      "           2       0.42      0.56      0.48      2247\n",
      "           3       0.66      0.31      0.42      2247\n",
      "\n",
      "    accuracy                           0.64      8988\n",
      "   macro avg       0.66      0.64      0.63      8988\n",
      "weighted avg       0.66      0.64      0.63      8988\n",
      "\n",
      "EPOCH  50 : train loss 0.323, val loss 1.515, val accuracy 0.625, and val rmse 0.781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.73      0.80      2247\n",
      "           1       0.74      0.85      0.79      2247\n",
      "           2       0.40      0.66      0.50      2247\n",
      "           3       0.68      0.25      0.37      2247\n",
      "\n",
      "    accuracy                           0.63      8988\n",
      "   macro avg       0.68      0.63      0.62      8988\n",
      "weighted avg       0.68      0.63      0.62      8988\n",
      "\n",
      "EPOCH  55 : train loss 0.298, val loss 1.406, val accuracy 0.631, and val rmse 0.785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.78      0.81      2247\n",
      "           1       0.71      0.83      0.76      2247\n",
      "           2       0.42      0.58      0.48      2247\n",
      "           3       0.65      0.33      0.44      2247\n",
      "\n",
      "    accuracy                           0.63      8988\n",
      "   macro avg       0.66      0.63      0.63      8988\n",
      "weighted avg       0.66      0.63      0.63      8988\n",
      "\n",
      "EPOCH  60 : train loss 0.284, val loss 1.477, val accuracy 0.637, and val rmse 0.771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      2247\n",
      "           1       0.75      0.82      0.78      2247\n",
      "           2       0.42      0.62      0.50      2247\n",
      "           3       0.65      0.29      0.40      2247\n",
      "\n",
      "    accuracy                           0.64      8988\n",
      "   macro avg       0.66      0.64      0.63      8988\n",
      "weighted avg       0.66      0.64      0.63      8988\n",
      "\n",
      "EPOCH  65 : train loss 0.275, val loss 1.511, val accuracy 0.628, and val rmse 0.778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.74      0.81      2247\n",
      "           1       0.74      0.83      0.78      2247\n",
      "           2       0.41      0.64      0.50      2247\n",
      "           3       0.62      0.31      0.41      2247\n",
      "\n",
      "    accuracy                           0.63      8988\n",
      "   macro avg       0.67      0.63      0.63      8988\n",
      "weighted avg       0.67      0.63      0.63      8988\n",
      "\n",
      "EPOCH  70 : train loss 0.255, val loss 1.575, val accuracy 0.620, and val rmse 0.783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.70      0.79      2247\n",
      "           1       0.73      0.82      0.77      2247\n",
      "           2       0.40      0.65      0.50      2247\n",
      "           3       0.64      0.32      0.42      2247\n",
      "\n",
      "    accuracy                           0.62      8988\n",
      "   macro avg       0.67      0.62      0.62      8988\n",
      "weighted avg       0.67      0.62      0.62      8988\n",
      "\n",
      "EPOCH  75 : train loss 0.241, val loss 1.608, val accuracy 0.629, and val rmse 0.780\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.75      0.81      2247\n",
      "           1       0.76      0.81      0.78      2247\n",
      "           2       0.41      0.66      0.50      2247\n",
      "           3       0.64      0.29      0.40      2247\n",
      "\n",
      "    accuracy                           0.63      8988\n",
      "   macro avg       0.67      0.63      0.63      8988\n",
      "weighted avg       0.67      0.63      0.63      8988\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  80 : train loss 0.230, val loss 1.668, val accuracy 0.613, and val rmse 0.785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.69      0.78      2247\n",
      "           1       0.73      0.81      0.76      2247\n",
      "           2       0.40      0.67      0.50      2247\n",
      "           3       0.63      0.29      0.40      2247\n",
      "\n",
      "    accuracy                           0.61      8988\n",
      "   macro avg       0.67      0.61      0.61      8988\n",
      "weighted avg       0.67      0.61      0.61      8988\n",
      "\n",
      "EPOCH  85 : train loss 0.220, val loss 1.702, val accuracy 0.632, and val rmse 0.779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.82      2247\n",
      "           1       0.72      0.85      0.78      2247\n",
      "           2       0.42      0.62      0.50      2247\n",
      "           3       0.66      0.26      0.37      2247\n",
      "\n",
      "    accuracy                           0.63      8988\n",
      "   macro avg       0.66      0.63      0.62      8988\n",
      "weighted avg       0.66      0.63      0.62      8988\n",
      "\n",
      "EPOCH  90 : train loss 0.219, val loss 1.825, val accuracy 0.612, and val rmse 0.782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.73      0.80      2247\n",
      "           1       0.77      0.73      0.75      2247\n",
      "           2       0.40      0.73      0.51      2247\n",
      "           3       0.65      0.26      0.37      2247\n",
      "\n",
      "    accuracy                           0.61      8988\n",
      "   macro avg       0.68      0.61      0.61      8988\n",
      "weighted avg       0.68      0.61      0.61      8988\n",
      "\n",
      "EPOCH  95 : train loss 0.199, val loss 1.663, val accuracy 0.631, and val rmse 0.775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.78      0.82      2247\n",
      "           1       0.77      0.76      0.77      2247\n",
      "           2       0.41      0.66      0.51      2247\n",
      "           3       0.64      0.33      0.43      2247\n",
      "\n",
      "    accuracy                           0.63      8988\n",
      "   macro avg       0.67      0.63      0.63      8988\n",
      "weighted avg       0.67      0.63      0.63      8988\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## BiLSTM (content + title) (num_layers=2), hidden_dim=50 GloVe embeddings emb_size=100, no stop words (train + test), N=450, (batch_size=500) w/ random synonym replacement/insertion (on content + title) alpha=0.5 (80/20 split), 14000 points/class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0 : train loss 1.187, val loss 1.051, val accuracy 0.550, and val rmse 1.093\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.74      0.66      3317\n",
      "           1       0.58      0.59      0.59      3317\n",
      "           2       0.39      0.23      0.29      3317\n",
      "           3       0.55      0.65      0.60      3317\n",
      "\n",
      "    accuracy                           0.55     13268\n",
      "   macro avg       0.53      0.55      0.53     13268\n",
      "weighted avg       0.53      0.55      0.53     13268\n",
      "\n",
      "EPOCH  5 : train loss 0.997, val loss 1.019, val accuracy 0.563, and val rmse 1.054\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.63      0.67      3317\n",
      "           1       0.56      0.82      0.66      3317\n",
      "           2       0.36      0.16      0.22      3317\n",
      "           3       0.53      0.65      0.58      3317\n",
      "\n",
      "    accuracy                           0.56     13268\n",
      "   macro avg       0.54      0.56      0.53     13268\n",
      "weighted avg       0.54      0.56      0.53     13268\n",
      "\n",
      "EPOCH  10 : train loss 0.721, val loss 0.869, val accuracy 0.627, and val rmse 0.884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      3317\n",
      "           1       0.65      0.91      0.76      3317\n",
      "           2       0.40      0.31      0.35      3317\n",
      "           3       0.61      0.57      0.59      3317\n",
      "\n",
      "    accuracy                           0.63     13268\n",
      "   macro avg       0.62      0.63      0.61     13268\n",
      "weighted avg       0.62      0.63      0.61     13268\n",
      "\n",
      "EPOCH  15 : train loss 0.583, val loss 0.812, val accuracy 0.665, and val rmse 0.846\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.79      3317\n",
      "           1       0.72      0.88      0.79      3317\n",
      "           2       0.45      0.38      0.41      3317\n",
      "           3       0.64      0.63      0.63      3317\n",
      "\n",
      "    accuracy                           0.67     13268\n",
      "   macro avg       0.66      0.67      0.66     13268\n",
      "weighted avg       0.66      0.67      0.66     13268\n",
      "\n",
      "EPOCH  20 : train loss 0.488, val loss 0.940, val accuracy 0.659, and val rmse 0.817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.75      0.80      3317\n",
      "           1       0.71      0.89      0.79      3317\n",
      "           2       0.44      0.47      0.46      3317\n",
      "           3       0.66      0.52      0.58      3317\n",
      "\n",
      "    accuracy                           0.66     13268\n",
      "   macro avg       0.66      0.66      0.66     13268\n",
      "weighted avg       0.66      0.66      0.66     13268\n",
      "\n",
      "EPOCH  25 : train loss 0.422, val loss 0.994, val accuracy 0.655, and val rmse 0.809\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81      3317\n",
      "           1       0.72      0.90      0.80      3317\n",
      "           2       0.43      0.49      0.46      3317\n",
      "           3       0.65      0.44      0.53      3317\n",
      "\n",
      "    accuracy                           0.65     13268\n",
      "   macro avg       0.66      0.65      0.65     13268\n",
      "weighted avg       0.66      0.65      0.65     13268\n",
      "\n",
      "EPOCH  30 : train loss 0.370, val loss 1.120, val accuracy 0.652, and val rmse 0.785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.75      0.81      3317\n",
      "           1       0.71      0.92      0.80      3317\n",
      "           2       0.43      0.52      0.47      3317\n",
      "           3       0.66      0.42      0.51      3317\n",
      "\n",
      "    accuracy                           0.65     13268\n",
      "   macro avg       0.67      0.65      0.65     13268\n",
      "weighted avg       0.67      0.65      0.65     13268\n",
      "\n",
      "EPOCH  35 : train loss 0.335, val loss 1.206, val accuracy 0.642, and val rmse 0.790\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.76      0.81      3317\n",
      "           1       0.78      0.80      0.79      3317\n",
      "           2       0.42      0.64      0.51      3317\n",
      "           3       0.65      0.37      0.47      3317\n",
      "\n",
      "    accuracy                           0.64     13268\n",
      "   macro avg       0.68      0.64      0.64     13268\n",
      "weighted avg       0.68      0.64      0.64     13268\n",
      "\n",
      "EPOCH  40 : train loss 0.311, val loss 1.464, val accuracy 0.623, and val rmse 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.69      0.78      3317\n",
      "           1       0.71      0.88      0.79      3317\n",
      "           2       0.41      0.65      0.50      3317\n",
      "           3       0.68      0.27      0.39      3317\n",
      "\n",
      "    accuracy                           0.62     13268\n",
      "   macro avg       0.67      0.62      0.61     13268\n",
      "weighted avg       0.67      0.62      0.61     13268\n",
      "\n",
      "EPOCH  45 : train loss 0.290, val loss 1.339, val accuracy 0.633, and val rmse 0.800\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.67      0.77      3317\n",
      "           1       0.72      0.89      0.80      3317\n",
      "           2       0.41      0.58      0.48      3317\n",
      "           3       0.64      0.39      0.49      3317\n",
      "\n",
      "    accuracy                           0.63     13268\n",
      "   macro avg       0.67      0.63      0.63     13268\n",
      "weighted avg       0.67      0.63      0.63     13268\n",
      "\n",
      "EPOCH  50 : train loss 0.279, val loss 1.361, val accuracy 0.646, and val rmse 0.790\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.73      0.80      3317\n",
      "           1       0.78      0.85      0.81      3317\n",
      "           2       0.42      0.62      0.50      3317\n",
      "           3       0.64      0.38      0.48      3317\n",
      "\n",
      "    accuracy                           0.65     13268\n",
      "   macro avg       0.68      0.65      0.65     13268\n",
      "weighted avg       0.68      0.65      0.65     13268\n",
      "\n",
      "EPOCH  55 : train loss 0.263, val loss 1.397, val accuracy 0.640, and val rmse 0.779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.82      3317\n",
      "           1       0.72      0.87      0.79      3317\n",
      "           2       0.42      0.55      0.47      3317\n",
      "           3       0.63      0.34      0.45      3317\n",
      "\n",
      "    accuracy                           0.64     13268\n",
      "   macro avg       0.65      0.64      0.63     13268\n",
      "weighted avg       0.65      0.64      0.63     13268\n",
      "\n",
      "EPOCH  60 : train loss 0.247, val loss 1.535, val accuracy 0.643, and val rmse 0.774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.77      0.82      3317\n",
      "           1       0.77      0.85      0.81      3317\n",
      "           2       0.42      0.67      0.52      3317\n",
      "           3       0.66      0.28      0.39      3317\n",
      "\n",
      "    accuracy                           0.64     13268\n",
      "   macro avg       0.68      0.64      0.63     13268\n",
      "weighted avg       0.68      0.64      0.63     13268\n",
      "\n",
      "EPOCH  65 : train loss 0.233, val loss 1.590, val accuracy 0.650, and val rmse 0.751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84      3317\n",
      "           1       0.77      0.85      0.81      3317\n",
      "           2       0.42      0.65      0.51      3317\n",
      "           3       0.66      0.29      0.41      3317\n",
      "\n",
      "    accuracy                           0.65     13268\n",
      "   macro avg       0.68      0.65      0.64     13268\n",
      "weighted avg       0.68      0.65      0.64     13268\n",
      "\n",
      "EPOCH  70 : train loss 0.223, val loss 1.672, val accuracy 0.637, and val rmse 0.768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.78      0.82      3317\n",
      "           1       0.74      0.87      0.80      3317\n",
      "           2       0.42      0.63      0.50      3317\n",
      "           3       0.64      0.28      0.39      3317\n",
      "\n",
      "    accuracy                           0.64     13268\n",
      "   macro avg       0.67      0.64      0.63     13268\n",
      "weighted avg       0.67      0.64      0.63     13268\n",
      "\n",
      "EPOCH  75 : train loss 0.214, val loss 1.864, val accuracy 0.629, and val rmse 0.776\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.74      0.81      3317\n",
      "           1       0.76      0.84      0.80      3317\n",
      "           2       0.41      0.72      0.52      3317\n",
      "           3       0.69      0.22      0.33      3317\n",
      "\n",
      "    accuracy                           0.63     13268\n",
      "   macro avg       0.69      0.63      0.62     13268\n",
      "weighted avg       0.69      0.63      0.62     13268\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  80 : train loss 0.206, val loss 1.617, val accuracy 0.645, and val rmse 0.767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83      3317\n",
      "           1       0.77      0.83      0.80      3317\n",
      "           2       0.42      0.64      0.51      3317\n",
      "           3       0.65      0.31      0.42      3317\n",
      "\n",
      "    accuracy                           0.64     13268\n",
      "   macro avg       0.67      0.64      0.64     13268\n",
      "weighted avg       0.67      0.64      0.64     13268\n",
      "\n",
      "EPOCH  85 : train loss 0.193, val loss 1.831, val accuracy 0.636, and val rmse 0.768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.77      0.83      3317\n",
      "           1       0.77      0.84      0.81      3317\n",
      "           2       0.41      0.70      0.52      3317\n",
      "           3       0.65      0.24      0.35      3317\n",
      "\n",
      "    accuracy                           0.64     13268\n",
      "   macro avg       0.68      0.64      0.63     13268\n",
      "weighted avg       0.68      0.64      0.63     13268\n",
      "\n",
      "EPOCH  90 : train loss 0.192, val loss 1.726, val accuracy 0.635, and val rmse 0.776\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.77      0.82      3317\n",
      "           1       0.75      0.83      0.78      3317\n",
      "           2       0.42      0.65      0.51      3317\n",
      "           3       0.63      0.30      0.41      3317\n",
      "\n",
      "    accuracy                           0.64     13268\n",
      "   macro avg       0.67      0.64      0.63     13268\n",
      "weighted avg       0.67      0.64      0.63     13268\n",
      "\n",
      "EPOCH  95 : train loss 0.179, val loss 1.949, val accuracy 0.642, and val rmse 0.765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84      3317\n",
      "           1       0.77      0.85      0.81      3317\n",
      "           2       0.42      0.68      0.52      3317\n",
      "           3       0.66      0.22      0.33      3317\n",
      "\n",
      "    accuracy                           0.64     13268\n",
      "   macro avg       0.68      0.64      0.63     13268\n",
      "weighted avg       0.68      0.64      0.63     13268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM (content + title) (num_layers=2), hidden_dim=50 GloVe embeddings emb_size=100, no stop words (train + test), N=150, (batch_size=500) w/ random synonym replacement/insertion (on content + title) alpha=0.5 (80/20 split), 14000 points/class, Join hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0 : train loss 1.191, val loss 1.105, val accuracy 0.513, and val rmse 1.110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.65      3317\n",
      "           1       0.51      0.72      0.60      3317\n",
      "           2       0.34      0.25      0.29      3317\n",
      "           3       0.50      0.44      0.47      3317\n",
      "\n",
      "    accuracy                           0.51     13268\n",
      "   macro avg       0.50      0.51      0.50     13268\n",
      "weighted avg       0.50      0.51      0.50     13268\n",
      "\n",
      "EPOCH  5 : train loss 0.805, val loss 0.909, val accuracy 0.608, and val rmse 0.957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.62      0.70      3317\n",
      "           1       0.64      0.89      0.74      3317\n",
      "           2       0.39      0.23      0.29      3317\n",
      "           3       0.56      0.69      0.62      3317\n",
      "\n",
      "    accuracy                           0.61     13268\n",
      "   macro avg       0.60      0.61      0.59     13268\n",
      "weighted avg       0.60      0.61      0.59     13268\n",
      "\n",
      "EPOCH  10 : train loss 0.612, val loss 0.847, val accuracy 0.646, and val rmse 0.855\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.70      0.76      3317\n",
      "           1       0.69      0.92      0.79      3317\n",
      "           2       0.42      0.37      0.40      3317\n",
      "           3       0.63      0.60      0.61      3317\n",
      "\n",
      "    accuracy                           0.65     13268\n",
      "   macro avg       0.65      0.65      0.64     13268\n",
      "weighted avg       0.65      0.65      0.64     13268\n",
      "\n",
      "EPOCH  15 : train loss 0.479, val loss 1.080, val accuracy 0.619, and val rmse 0.848\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.64      0.74      3317\n",
      "           1       0.69      0.89      0.77      3317\n",
      "           2       0.40      0.50      0.44      3317\n",
      "           3       0.63      0.45      0.52      3317\n",
      "\n",
      "    accuracy                           0.62     13268\n",
      "   macro avg       0.64      0.62      0.62     13268\n",
      "weighted avg       0.64      0.62      0.62     13268\n",
      "\n",
      "EPOCH  20 : train loss 0.414, val loss 1.118, val accuracy 0.636, and val rmse 0.828\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.71      0.78      3317\n",
      "           1       0.70      0.90      0.79      3317\n",
      "           2       0.41      0.50      0.45      3317\n",
      "           3       0.63      0.43      0.51      3317\n",
      "\n",
      "    accuracy                           0.64     13268\n",
      "   macro avg       0.65      0.64      0.63     13268\n",
      "weighted avg       0.65      0.64      0.63     13268\n",
      "\n",
      "EPOCH  25 : train loss 0.359, val loss 1.349, val accuracy 0.613, and val rmse 0.829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.64      0.75      3317\n",
      "           1       0.70      0.89      0.78      3317\n",
      "           2       0.40      0.60      0.48      3317\n",
      "           3       0.64      0.32      0.43      3317\n",
      "\n",
      "    accuracy                           0.61     13268\n",
      "   macro avg       0.66      0.61      0.61     13268\n",
      "weighted avg       0.66      0.61      0.61     13268\n",
      "\n",
      "EPOCH  30 : train loss 0.318, val loss 1.395, val accuracy 0.624, and val rmse 0.813\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.74      0.79      3317\n",
      "           1       0.68      0.91      0.78      3317\n",
      "           2       0.41      0.56      0.48      3317\n",
      "           3       0.65      0.29      0.40      3317\n",
      "\n",
      "    accuracy                           0.62     13268\n",
      "   macro avg       0.65      0.62      0.61     13268\n",
      "weighted avg       0.65      0.62      0.61     13268\n",
      "\n",
      "EPOCH  35 : train loss 0.291, val loss 1.545, val accuracy 0.619, and val rmse 0.831\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.73      0.78      3317\n",
      "           1       0.67      0.91      0.77      3317\n",
      "           2       0.41      0.58      0.48      3317\n",
      "           3       0.67      0.26      0.37      3317\n",
      "\n",
      "    accuracy                           0.62     13268\n",
      "   macro avg       0.65      0.62      0.60     13268\n",
      "weighted avg       0.65      0.62      0.60     13268\n",
      "\n",
      "EPOCH  40 : train loss 0.277, val loss 1.585, val accuracy 0.619, and val rmse 0.812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.72      0.78      3317\n",
      "           1       0.69      0.89      0.78      3317\n",
      "           2       0.41      0.62      0.49      3317\n",
      "           3       0.66      0.25      0.36      3317\n",
      "\n",
      "    accuracy                           0.62     13268\n",
      "   macro avg       0.66      0.62      0.60     13268\n",
      "weighted avg       0.66      0.62      0.60     13268\n",
      "\n",
      "EPOCH  45 : train loss 0.254, val loss 1.742, val accuracy 0.624, and val rmse 0.835\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      3317\n",
      "           1       0.72      0.91      0.80      3317\n",
      "           2       0.41      0.58      0.48      3317\n",
      "           3       0.66      0.19      0.29      3317\n",
      "\n",
      "    accuracy                           0.62     13268\n",
      "   macro avg       0.64      0.62      0.60     13268\n",
      "weighted avg       0.64      0.62      0.60     13268\n",
      "\n",
      "EPOCH  50 : train loss 0.240, val loss 1.781, val accuracy 0.613, and val rmse 0.810\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.68      0.77      3317\n",
      "           1       0.71      0.88      0.78      3317\n",
      "           2       0.40      0.66      0.50      3317\n",
      "           3       0.65      0.23      0.34      3317\n",
      "\n",
      "    accuracy                           0.61     13268\n",
      "   macro avg       0.66      0.61      0.60     13268\n",
      "weighted avg       0.66      0.61      0.60     13268\n",
      "\n",
      "EPOCH  55 : train loss 0.224, val loss 1.765, val accuracy 0.620, and val rmse 0.809\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.71      0.79      3317\n",
      "           1       0.75      0.84      0.80      3317\n",
      "           2       0.40      0.68      0.51      3317\n",
      "           3       0.64      0.24      0.35      3317\n",
      "\n",
      "    accuracy                           0.62     13268\n",
      "   macro avg       0.67      0.62      0.61     13268\n",
      "weighted avg       0.67      0.62      0.61     13268\n",
      "\n",
      "EPOCH  60 : train loss 0.215, val loss 1.891, val accuracy 0.615, and val rmse 0.817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.71      0.78      3317\n",
      "           1       0.74      0.84      0.79      3317\n",
      "           2       0.41      0.70      0.52      3317\n",
      "           3       0.67      0.21      0.32      3317\n",
      "\n",
      "    accuracy                           0.62     13268\n",
      "   macro avg       0.67      0.62      0.60     13268\n",
      "weighted avg       0.67      0.62      0.60     13268\n",
      "\n",
      "EPOCH  65 : train loss 0.204, val loss 1.856, val accuracy 0.614, and val rmse 0.811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.71      0.78      3317\n",
      "           1       0.73      0.84      0.78      3317\n",
      "           2       0.40      0.69      0.51      3317\n",
      "           3       0.66      0.22      0.33      3317\n",
      "\n",
      "    accuracy                           0.61     13268\n",
      "   macro avg       0.67      0.61      0.60     13268\n",
      "weighted avg       0.67      0.61      0.60     13268\n",
      "\n",
      "EPOCH  70 : train loss 0.192, val loss 1.876, val accuracy 0.622, and val rmse 0.803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.77      0.80      3317\n",
      "           1       0.75      0.83      0.79      3317\n",
      "           2       0.41      0.67      0.51      3317\n",
      "           3       0.65      0.21      0.32      3317\n",
      "\n",
      "    accuracy                           0.62     13268\n",
      "   macro avg       0.66      0.62      0.60     13268\n",
      "weighted avg       0.66      0.62      0.60     13268\n",
      "\n",
      "EPOCH  75 : train loss 0.184, val loss 1.998, val accuracy 0.600, and val rmse 0.819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.64      0.75      3317\n",
      "           1       0.73      0.80      0.76      3317\n",
      "           2       0.39      0.72      0.51      3317\n",
      "           3       0.66      0.24      0.35      3317\n",
      "\n",
      "    accuracy                           0.60     13268\n",
      "   macro avg       0.67      0.60      0.59     13268\n",
      "weighted avg       0.67      0.60      0.59     13268\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  80 : train loss 0.175, val loss 2.013, val accuracy 0.602, and val rmse 0.808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.68      0.77      3317\n",
      "           1       0.75      0.77      0.76      3317\n",
      "           2       0.39      0.73      0.51      3317\n",
      "           3       0.65      0.23      0.34      3317\n",
      "\n",
      "    accuracy                           0.60     13268\n",
      "   macro avg       0.67      0.60      0.60     13268\n",
      "weighted avg       0.67      0.60      0.60     13268\n",
      "\n",
      "EPOCH  85 : train loss 0.166, val loss 1.951, val accuracy 0.618, and val rmse 0.810\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.71      0.78      3317\n",
      "           1       0.73      0.84      0.78      3317\n",
      "           2       0.41      0.66      0.50      3317\n",
      "           3       0.63      0.26      0.37      3317\n",
      "\n",
      "    accuracy                           0.62     13268\n",
      "   macro avg       0.66      0.62      0.61     13268\n",
      "weighted avg       0.66      0.62      0.61     13268\n",
      "\n",
      "EPOCH  90 : train loss 0.163, val loss 1.966, val accuracy 0.613, and val rmse 0.819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.68      0.77      3317\n",
      "           1       0.72      0.85      0.78      3317\n",
      "           2       0.41      0.67      0.50      3317\n",
      "           3       0.63      0.26      0.37      3317\n",
      "\n",
      "    accuracy                           0.61     13268\n",
      "   macro avg       0.66      0.61      0.60     13268\n",
      "weighted avg       0.66      0.61      0.60     13268\n",
      "\n",
      "EPOCH  95 : train loss 0.156, val loss 2.162, val accuracy 0.606, and val rmse 0.820\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.68      0.77      3317\n",
      "           1       0.72      0.84      0.77      3317\n",
      "           2       0.40      0.69      0.51      3317\n",
      "           3       0.63      0.22      0.33      3317\n",
      "\n",
      "    accuracy                           0.61     13268\n",
      "   macro avg       0.66      0.61      0.59     13268\n",
      "weighted avg       0.66      0.61      0.59     13268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM (content + title) (num_layers=2), hidden_dim=50 GloVe embeddings emb_size=100, no stop words (train + test), N=450, (batch_size=500) w/ random synonym replacement/insertion (on content + title) alpha=0.5 (80/20 split), 14000 points/class, Join hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0 : train loss 1.221, val loss 1.146, val accuracy 0.481, and val rmse 1.131\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.42      0.53      3317\n",
      "           1       0.51      0.57      0.54      3317\n",
      "           2       0.33      0.27      0.30      3317\n",
      "           3       0.44      0.67      0.53      3317\n",
      "\n",
      "    accuracy                           0.48     13268\n",
      "   macro avg       0.51      0.48      0.48     13268\n",
      "weighted avg       0.51      0.48      0.48     13268\n",
      "\n",
      "EPOCH  5 : train loss 0.914, val loss 0.961, val accuracy 0.581, and val rmse 1.022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.65      0.70      3317\n",
      "           1       0.58      0.88      0.70      3317\n",
      "           2       0.37      0.18      0.24      3317\n",
      "           3       0.54      0.61      0.57      3317\n",
      "\n",
      "    accuracy                           0.58     13268\n",
      "   macro avg       0.56      0.58      0.55     13268\n",
      "weighted avg       0.56      0.58      0.55     13268\n",
      "\n",
      "EPOCH  10 : train loss 1.028, val loss 0.991, val accuracy 0.584, and val rmse 1.053\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71      3317\n",
      "           1       0.57      0.86      0.69      3317\n",
      "           2       0.39      0.12      0.18      3317\n",
      "           3       0.55      0.64      0.59      3317\n",
      "\n",
      "    accuracy                           0.58     13268\n",
      "   macro avg       0.55      0.58      0.54     13268\n",
      "weighted avg       0.55      0.58      0.54     13268\n",
      "\n",
      "EPOCH  15 : train loss 0.715, val loss 0.819, val accuracy 0.635, and val rmse 0.892\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.78      3317\n",
      "           1       0.69      0.88      0.77      3317\n",
      "           2       0.40      0.31      0.35      3317\n",
      "           3       0.61      0.56      0.59      3317\n",
      "\n",
      "    accuracy                           0.64     13268\n",
      "   macro avg       0.62      0.64      0.62     13268\n",
      "weighted avg       0.62      0.64      0.62     13268\n",
      "\n",
      "EPOCH  20 : train loss 0.601, val loss 0.870, val accuracy 0.638, and val rmse 0.870\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.78      3317\n",
      "           1       0.67      0.93      0.78      3317\n",
      "           2       0.42      0.38      0.40      3317\n",
      "           3       0.66      0.45      0.53      3317\n",
      "\n",
      "    accuracy                           0.64     13268\n",
      "   macro avg       0.63      0.64      0.62     13268\n",
      "weighted avg       0.63      0.64      0.62     13268\n",
      "\n",
      "EPOCH  25 : train loss 0.542, val loss 0.972, val accuracy 0.621, and val rmse 0.894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77      3317\n",
      "           1       0.65      0.94      0.77      3317\n",
      "           2       0.41      0.42      0.41      3317\n",
      "           3       0.69      0.34      0.45      3317\n",
      "\n",
      "    accuracy                           0.62     13268\n",
      "   macro avg       0.63      0.62      0.60     13268\n",
      "weighted avg       0.63      0.62      0.60     13268\n",
      "\n",
      "EPOCH  30 : train loss 0.463, val loss 1.012, val accuracy 0.638, and val rmse 0.817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.76      0.80      3317\n",
      "           1       0.70      0.91      0.79      3317\n",
      "           2       0.41      0.54      0.47      3317\n",
      "           3       0.68      0.34      0.45      3317\n",
      "\n",
      "    accuracy                           0.64     13268\n",
      "   macro avg       0.66      0.64      0.63     13268\n",
      "weighted avg       0.66      0.64      0.63     13268\n",
      "\n",
      "EPOCH  35 : train loss 0.418, val loss 0.975, val accuracy 0.645, and val rmse 0.801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.75      0.81      3317\n",
      "           1       0.76      0.85      0.80      3317\n",
      "           2       0.41      0.57      0.48      3317\n",
      "           3       0.63      0.42      0.50      3317\n",
      "\n",
      "    accuracy                           0.65     13268\n",
      "   macro avg       0.67      0.65      0.65     13268\n",
      "weighted avg       0.67      0.65      0.65     13268\n",
      "\n",
      "EPOCH  40 : train loss 0.382, val loss 1.093, val accuracy 0.648, and val rmse 0.818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      3317\n",
      "           1       0.74      0.89      0.81      3317\n",
      "           2       0.42      0.53      0.47      3317\n",
      "           3       0.65      0.35      0.46      3317\n",
      "\n",
      "    accuracy                           0.65     13268\n",
      "   macro avg       0.66      0.65      0.64     13268\n",
      "weighted avg       0.66      0.65      0.64     13268\n",
      "\n",
      "EPOCH  45 : train loss 0.353, val loss 1.306, val accuracy 0.627, and val rmse 0.793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.74      0.80      3317\n",
      "           1       0.70      0.90      0.78      3317\n",
      "           2       0.41      0.63      0.50      3317\n",
      "           3       0.69      0.24      0.36      3317\n",
      "\n",
      "    accuracy                           0.63     13268\n",
      "   macro avg       0.67      0.63      0.61     13268\n",
      "weighted avg       0.67      0.63      0.61     13268\n",
      "\n",
      "EPOCH  50 : train loss 0.327, val loss 1.202, val accuracy 0.639, and val rmse 0.776\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.70      0.80      3317\n",
      "           1       0.75      0.86      0.80      3317\n",
      "           2       0.41      0.63      0.50      3317\n",
      "           3       0.65      0.36      0.47      3317\n",
      "\n",
      "    accuracy                           0.64     13268\n",
      "   macro avg       0.69      0.64      0.64     13268\n",
      "weighted avg       0.69      0.64      0.64     13268\n",
      "\n",
      "EPOCH  55 : train loss 0.315, val loss 1.191, val accuracy 0.638, and val rmse 0.787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.72      0.80      3317\n",
      "           1       0.79      0.79      0.79      3317\n",
      "           2       0.41      0.64      0.50      3317\n",
      "           3       0.64      0.40      0.50      3317\n",
      "\n",
      "    accuracy                           0.64     13268\n",
      "   macro avg       0.69      0.64      0.65     13268\n",
      "weighted avg       0.69      0.64      0.65     13268\n",
      "\n",
      "EPOCH  60 : train loss 0.290, val loss 1.418, val accuracy 0.622, and val rmse 0.791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.69      0.79      3317\n",
      "           1       0.78      0.80      0.79      3317\n",
      "           2       0.40      0.71      0.51      3317\n",
      "           3       0.66      0.28      0.40      3317\n",
      "\n",
      "    accuracy                           0.62     13268\n",
      "   macro avg       0.69      0.62      0.62     13268\n",
      "weighted avg       0.69      0.62      0.62     13268\n",
      "\n",
      "EPOCH  65 : train loss 0.276, val loss 1.338, val accuracy 0.645, and val rmse 0.765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.75      0.82      3317\n",
      "           1       0.76      0.84      0.80      3317\n",
      "           2       0.42      0.64      0.50      3317\n",
      "           3       0.65      0.35      0.46      3317\n",
      "\n",
      "    accuracy                           0.64     13268\n",
      "   macro avg       0.68      0.64      0.65     13268\n",
      "weighted avg       0.68      0.64      0.65     13268\n",
      "\n",
      "EPOCH  70 : train loss 0.270, val loss 1.467, val accuracy 0.645, and val rmse 0.761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.75      0.82      3317\n",
      "           1       0.76      0.88      0.81      3317\n",
      "           2       0.42      0.67      0.52      3317\n",
      "           3       0.68      0.29      0.40      3317\n",
      "\n",
      "    accuracy                           0.64     13268\n",
      "   macro avg       0.69      0.64      0.64     13268\n",
      "weighted avg       0.69      0.64      0.64     13268\n",
      "\n",
      "EPOCH  75 : train loss 0.246, val loss 1.459, val accuracy 0.644, and val rmse 0.767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.77      0.83      3317\n",
      "           1       0.76      0.87      0.81      3317\n",
      "           2       0.42      0.64      0.50      3317\n",
      "           3       0.65      0.30      0.41      3317\n",
      "\n",
      "    accuracy                           0.64     13268\n",
      "   macro avg       0.68      0.64      0.64     13268\n",
      "weighted avg       0.68      0.64      0.64     13268\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  80 : train loss 0.237, val loss 1.451, val accuracy 0.652, and val rmse 0.760\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.83      3317\n",
      "           1       0.78      0.83      0.80      3317\n",
      "           2       0.43      0.64      0.51      3317\n",
      "           3       0.67      0.33      0.44      3317\n",
      "\n",
      "    accuracy                           0.65     13268\n",
      "   macro avg       0.68      0.65      0.65     13268\n",
      "weighted avg       0.68      0.65      0.65     13268\n",
      "\n",
      "EPOCH  85 : train loss 0.233, val loss 1.510, val accuracy 0.641, and val rmse 0.770\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.74      0.81      3317\n",
      "           1       0.77      0.85      0.81      3317\n",
      "           2       0.42      0.67      0.51      3317\n",
      "           3       0.67      0.30      0.41      3317\n",
      "\n",
      "    accuracy                           0.64     13268\n",
      "   macro avg       0.69      0.64      0.64     13268\n",
      "weighted avg       0.69      0.64      0.64     13268\n",
      "\n",
      "EPOCH  90 : train loss 0.229, val loss 1.634, val accuracy 0.628, and val rmse 0.783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.69      0.79      3317\n",
      "           1       0.75      0.87      0.80      3317\n",
      "           2       0.40      0.65      0.50      3317\n",
      "           3       0.64      0.31      0.41      3317\n",
      "\n",
      "    accuracy                           0.63     13268\n",
      "   macro avg       0.68      0.63      0.63     13268\n",
      "weighted avg       0.68      0.63      0.63     13268\n",
      "\n",
      "EPOCH  95 : train loss 0.205, val loss 1.733, val accuracy 0.630, and val rmse 0.775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.73      0.81      3317\n",
      "           1       0.73      0.86      0.79      3317\n",
      "           2       0.41      0.66      0.51      3317\n",
      "           3       0.67      0.27      0.39      3317\n",
      "\n",
      "    accuracy                           0.63     13268\n",
      "   macro avg       0.68      0.63      0.62     13268\n",
      "weighted avg       0.68      0.63      0.62     13268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

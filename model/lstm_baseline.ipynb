{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import spacy\n",
    "import torch\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "NODES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating mean/median\n",
      "mean:  3395.3801836343455\n",
      "median:  1400.0\n",
      "39644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../uci_data/OnlineNewsPopularity_extended.csv\")\n",
    "print(\"calculating mean/median\")\n",
    "mean =  df[\"shares\"].mean()\n",
    "median = df[\"shares\"].median()\n",
    "print(\"mean: \", mean)\n",
    "print(\"median: \", median)\n",
    "[print(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['shares'] < median, 'shares'] = 0\n",
    "df.loc[df['shares'] >= median, 'shares'] = 1\n",
    "df = df.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['content'].fillna('')\n",
    "df['content_length'] = df['content'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>...</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>label_by_mean</th>\n",
       "      <th>label_by_median</th>\n",
       "      <th>content_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazons Streaming Video Library Now a Little E...</td>\n",
       "      <td>Having trouble finding something to watch on A...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>APs Twitter to Begin Displaying Sponsored Tweets</td>\n",
       "      <td>The Associated Press is the latest news organi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Apples App Store Passes 40 Billion Downloads</td>\n",
       "      <td>It looks like 2012 was a pretty good year for ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>This Astronaut Is Rooting for Notre Dame Tonight</td>\n",
       "      <td>When it comes to college football NASA astrona...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>731.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0</td>\n",
       "      <td>New UVerse Apps Simplify Sharing Photos and Vi...</td>\n",
       "      <td>LAS VEGAS — Sharing photos and videos on your ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timedelta  n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "0      731.0            12.0             219.0         0.663594   \n",
       "1      731.0             9.0             255.0         0.604743   \n",
       "2      731.0             9.0             211.0         0.575130   \n",
       "3      731.0             9.0             531.0         0.503788   \n",
       "4      731.0            13.0            1072.0         0.415646   \n",
       "\n",
       "   n_non_stop_words  n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  \\\n",
       "0               1.0                  0.815385        4.0             2.0   \n",
       "1               1.0                  0.791946        3.0             1.0   \n",
       "2               1.0                  0.663866        3.0             1.0   \n",
       "3               1.0                  0.665635        9.0             0.0   \n",
       "4               1.0                  0.540890       19.0            19.0   \n",
       "\n",
       "   num_imgs  num_videos  ...  title_subjectivity  title_sentiment_polarity  \\\n",
       "0       1.0         0.0  ...            0.500000                 -0.187500   \n",
       "1       1.0         0.0  ...            0.000000                  0.000000   \n",
       "2       1.0         0.0  ...            0.000000                  0.000000   \n",
       "3       1.0         0.0  ...            0.000000                  0.000000   \n",
       "4      20.0         0.0  ...            0.454545                  0.136364   \n",
       "\n",
       "   abs_title_subjectivity  abs_title_sentiment_polarity  shares  \\\n",
       "0                0.000000                      0.187500       0   \n",
       "1                0.500000                      0.000000       0   \n",
       "2                0.500000                      0.000000       1   \n",
       "3                0.500000                      0.000000       0   \n",
       "4                0.045455                      0.136364       0   \n",
       "\n",
       "                                               title  \\\n",
       "0  Amazons Streaming Video Library Now a Little E...   \n",
       "1   APs Twitter to Begin Displaying Sponsored Tweets   \n",
       "2       Apples App Store Passes 40 Billion Downloads   \n",
       "3   This Astronaut Is Rooting for Notre Dame Tonight   \n",
       "4  New UVerse Apps Simplify Sharing Photos and Vi...   \n",
       "\n",
       "                                             content  label_by_mean  \\\n",
       "0  Having trouble finding something to watch on A...              1   \n",
       "1  The Associated Press is the latest news organi...              1   \n",
       "2  It looks like 2012 was a pretty good year for ...              1   \n",
       "3  When it comes to college football NASA astrona...              1   \n",
       "4  LAS VEGAS — Sharing photos and videos on your ...              1   \n",
       "\n",
       "   label_by_median  content_length  \n",
       "0                1             210  \n",
       "1                1             250  \n",
       "2                0             197  \n",
       "3                1             478  \n",
       "4                1             289  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404.07882655635154"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean content length\n",
    "\n",
    "np.mean(df['content_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization\n",
    "tok = spacy.load('en')\n",
    "def tokenize(text):\n",
    "    text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)\n",
    "    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]')\n",
    "    nopunct = regex.sub(\" \", text.lower())\n",
    "    return [token.text for token in tok.tokenizer(nopunct)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count number of occurences of each word\n",
    "counts = Counter()\n",
    "for index, row in df.iterrows():\n",
    "    counts.update(tokenize(row['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words before: 202157\n",
      "num_words after: 102822\n"
     ]
    }
   ],
   "source": [
    "#deleting infrequnet words\n",
    "print(\"num_words before:\", len(counts.keys()))\n",
    "for word in list(counts):\n",
    "    if counts[word] < 2:\n",
    "        del counts[word]\n",
    "print(\"num_words after:\",len(counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating vocab\n",
    "vocab2index = {\"\":0, \"UNK\":1}\n",
    "words = [\"\",\"UNK\"]\n",
    "for word in counts:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(text, vocab2index, N=450):\n",
    "    tokenized = tokenize(text)\n",
    "    encoded = np.zeros(N,dtype=int)\n",
    "    enc1 = np.array([vocab2index.get(word,vocab2index[\"UNK\"]) for word in tokenized])\n",
    "    length = min(N, len(enc1))\n",
    "    encoded[:length] = enc1[:length]\n",
    "    return encoded, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>...</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>label_by_mean</th>\n",
       "      <th>label_by_median</th>\n",
       "      <th>content_length</th>\n",
       "      <th>encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazons Streaming Video Library Now a Little E...</td>\n",
       "      <td>Having trouble finding something to watch on A...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>210</td>\n",
       "      <td>[[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>APs Twitter to Begin Displaying Sponsored Tweets</td>\n",
       "      <td>The Associated Press is the latest news organi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>[[12, 145, 146, 98, 12, 99, 147, 85, 6, 148, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Apples App Store Passes 40 Billion Downloads</td>\n",
       "      <td>It looks like 2012 was a pretty good year for ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>[[81, 263, 264, 265, 139, 100, 78, 237, 140, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>This Astronaut Is Rooting for Notre Dame Tonight</td>\n",
       "      <td>When it comes to college football NASA astrona...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>478</td>\n",
       "      <td>[[336, 81, 337, 6, 338, 339, 340, 341, 342, 34...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>731.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0</td>\n",
       "      <td>New UVerse Apps Simplify Sharing Photos and Vi...</td>\n",
       "      <td>LAS VEGAS — Sharing photos and videos on your ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>[[171, 172, 122, 525, 519, 25, 66, 8, 526, 26,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timedelta  n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "0      731.0            12.0             219.0         0.663594   \n",
       "1      731.0             9.0             255.0         0.604743   \n",
       "2      731.0             9.0             211.0         0.575130   \n",
       "3      731.0             9.0             531.0         0.503788   \n",
       "4      731.0            13.0            1072.0         0.415646   \n",
       "\n",
       "   n_non_stop_words  n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  \\\n",
       "0               1.0                  0.815385        4.0             2.0   \n",
       "1               1.0                  0.791946        3.0             1.0   \n",
       "2               1.0                  0.663866        3.0             1.0   \n",
       "3               1.0                  0.665635        9.0             0.0   \n",
       "4               1.0                  0.540890       19.0            19.0   \n",
       "\n",
       "   num_imgs  num_videos  ...  title_sentiment_polarity  \\\n",
       "0       1.0         0.0  ...                 -0.187500   \n",
       "1       1.0         0.0  ...                  0.000000   \n",
       "2       1.0         0.0  ...                  0.000000   \n",
       "3       1.0         0.0  ...                  0.000000   \n",
       "4      20.0         0.0  ...                  0.136364   \n",
       "\n",
       "   abs_title_subjectivity  abs_title_sentiment_polarity  shares  \\\n",
       "0                0.000000                      0.187500       0   \n",
       "1                0.500000                      0.000000       0   \n",
       "2                0.500000                      0.000000       1   \n",
       "3                0.500000                      0.000000       0   \n",
       "4                0.045455                      0.136364       0   \n",
       "\n",
       "                                               title  \\\n",
       "0  Amazons Streaming Video Library Now a Little E...   \n",
       "1   APs Twitter to Begin Displaying Sponsored Tweets   \n",
       "2       Apples App Store Passes 40 Billion Downloads   \n",
       "3   This Astronaut Is Rooting for Notre Dame Tonight   \n",
       "4  New UVerse Apps Simplify Sharing Photos and Vi...   \n",
       "\n",
       "                                             content  label_by_mean  \\\n",
       "0  Having trouble finding something to watch on A...              1   \n",
       "1  The Associated Press is the latest news organi...              1   \n",
       "2  It looks like 2012 was a pretty good year for ...              1   \n",
       "3  When it comes to college football NASA astrona...              1   \n",
       "4  LAS VEGAS — Sharing photos and videos on your ...              1   \n",
       "\n",
       "   label_by_median  content_length  \\\n",
       "0                1             210   \n",
       "1                1             250   \n",
       "2                0             197   \n",
       "3                1             478   \n",
       "4                1             289   \n",
       "\n",
       "                                             encoded  \n",
       "0  [[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ...  \n",
       "1  [[12, 145, 146, 98, 12, 99, 147, 85, 6, 148, 9...  \n",
       "2  [[81, 263, 264, 265, 139, 100, 78, 237, 140, 6...  \n",
       "3  [[336, 81, 337, 6, 338, 339, 340, 341, 342, 34...  \n",
       "4  [[171, 172, 122, 525, 519, 25, 66, 8, 526, 26,...  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['encoded'] = df['content'].apply(lambda x: np.array(encode_sentence(x,vocab2index)))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a91d68cd08>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'shares', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = df.iloc[:, 0:-1]\n",
    "#y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.680365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378636</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.913725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286915</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.393365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.495833</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.404896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.682836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411127</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39639</th>\n",
       "      <td>11.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>0.529052</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.684783</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.523121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333791</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.260000</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39640</th>\n",
       "      <td>12.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>0.696296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.885057</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>4.405488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374825</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.211111</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39641</th>\n",
       "      <td>10.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>0.516355</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.644128</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.076923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307273</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.356439</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39642</th>\n",
       "      <td>6.0</td>\n",
       "      <td>682.0</td>\n",
       "      <td>0.539493</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.692661</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.975073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236851</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.205246</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.012500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39643</th>\n",
       "      <td>10.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.471338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247338</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39644 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        n_tokens_title   n_tokens_content   n_unique_tokens  \\\n",
       "0                 12.0              219.0          0.663594   \n",
       "1                  9.0              255.0          0.604743   \n",
       "2                  9.0              211.0          0.575130   \n",
       "3                  9.0              531.0          0.503788   \n",
       "4                 13.0             1072.0          0.415646   \n",
       "...                ...                ...               ...   \n",
       "39639             11.0              346.0          0.529052   \n",
       "39640             12.0              328.0          0.696296   \n",
       "39641             10.0              442.0          0.516355   \n",
       "39642              6.0              682.0          0.539493   \n",
       "39643             10.0              157.0          0.701987   \n",
       "\n",
       "        n_non_stop_words   n_non_stop_unique_tokens   num_hrefs  \\\n",
       "0                    1.0                   0.815385         4.0   \n",
       "1                    1.0                   0.791946         3.0   \n",
       "2                    1.0                   0.663866         3.0   \n",
       "3                    1.0                   0.665635         9.0   \n",
       "4                    1.0                   0.540890        19.0   \n",
       "...                  ...                        ...         ...   \n",
       "39639                1.0                   0.684783         9.0   \n",
       "39640                1.0                   0.885057         9.0   \n",
       "39641                1.0                   0.644128        24.0   \n",
       "39642                1.0                   0.692661        10.0   \n",
       "39643                1.0                   0.846154         1.0   \n",
       "\n",
       "        num_self_hrefs   num_imgs   num_videos   average_token_length  ...  \\\n",
       "0                  2.0        1.0          0.0               4.680365  ...   \n",
       "1                  1.0        1.0          0.0               4.913725  ...   \n",
       "2                  1.0        1.0          0.0               4.393365  ...   \n",
       "3                  0.0        1.0          0.0               4.404896  ...   \n",
       "4                 19.0       20.0          0.0               4.682836  ...   \n",
       "...                ...        ...          ...                    ...  ...   \n",
       "39639              7.0        1.0          1.0               4.523121  ...   \n",
       "39640              7.0        3.0         48.0               4.405488  ...   \n",
       "39641              1.0       12.0          1.0               5.076923  ...   \n",
       "39642              1.0        1.0          0.0               4.975073  ...   \n",
       "39643              1.0        0.0          2.0               4.471338  ...   \n",
       "\n",
       "        avg_positive_polarity   min_positive_polarity   max_positive_polarity  \\\n",
       "0                    0.378636                0.100000                    0.70   \n",
       "1                    0.286915                0.033333                    0.70   \n",
       "2                    0.495833                0.100000                    1.00   \n",
       "3                    0.385965                0.136364                    0.80   \n",
       "4                    0.411127                0.033333                    1.00   \n",
       "...                       ...                     ...                     ...   \n",
       "39639                0.333791                0.100000                    0.75   \n",
       "39640                0.374825                0.136364                    0.70   \n",
       "39641                0.307273                0.136364                    0.50   \n",
       "39642                0.236851                0.062500                    0.50   \n",
       "39643                0.247338                0.100000                    0.50   \n",
       "\n",
       "        avg_negative_polarity   min_negative_polarity   max_negative_polarity  \\\n",
       "0                   -0.350000                  -0.600               -0.200000   \n",
       "1                   -0.118750                  -0.125               -0.100000   \n",
       "2                   -0.466667                  -0.800               -0.133333   \n",
       "3                   -0.369697                  -0.600               -0.166667   \n",
       "4                   -0.220192                  -0.500               -0.050000   \n",
       "...                       ...                     ...                     ...   \n",
       "39639               -0.260000                  -0.500               -0.125000   \n",
       "39640               -0.211111                  -0.400               -0.100000   \n",
       "39641               -0.356439                  -0.800               -0.166667   \n",
       "39642               -0.205246                  -0.500               -0.012500   \n",
       "39643               -0.200000                  -0.200               -0.200000   \n",
       "\n",
       "        title_subjectivity   title_sentiment_polarity  \\\n",
       "0                 0.500000                  -0.187500   \n",
       "1                 0.000000                   0.000000   \n",
       "2                 0.000000                   0.000000   \n",
       "3                 0.000000                   0.000000   \n",
       "4                 0.454545                   0.136364   \n",
       "...                    ...                        ...   \n",
       "39639             0.100000                   0.000000   \n",
       "39640             0.300000                   1.000000   \n",
       "39641             0.454545                   0.136364   \n",
       "39642             0.000000                   0.000000   \n",
       "39643             0.333333                   0.250000   \n",
       "\n",
       "        abs_title_subjectivity   abs_title_sentiment_polarity  \n",
       "0                     0.000000                       0.187500  \n",
       "1                     0.500000                       0.000000  \n",
       "2                     0.500000                       0.000000  \n",
       "3                     0.500000                       0.000000  \n",
       "4                     0.045455                       0.136364  \n",
       "...                        ...                            ...  \n",
       "39639                 0.400000                       0.000000  \n",
       "39640                 0.200000                       1.000000  \n",
       "39641                 0.045455                       0.136364  \n",
       "39642                 0.500000                       0.000000  \n",
       "39643                 0.166667                       0.250000  \n",
       "\n",
       "[39644 rows x 58 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        1\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "39639    1\n",
       "39640    1\n",
       "39641    1\n",
       "39642    0\n",
       "39643    0\n",
       "Name:  shares, Length: 39644, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(df['encoded'])\n",
    "y = list(df['shares'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "            self.X = X\n",
    "            self.y = Y\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.X[idx][0].astype(np.int32)), self.y[idx], self.X[idx][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = NewsDataset(X_train, y_train)\n",
    "valid_ds = NewsDataset(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=LEARNING_RATE)\n",
    "    for i in range(EPOCHS):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, y, l in train_dl:\n",
    "            x = x.long()\n",
    "            y = y.long()\n",
    "            y_pred = model(x, l)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.cross_entropy(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item() *y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        val_loss, val_acc, val_rmse = validation_metrics(model, val_dl)\n",
    "        if i%5 == 1:\n",
    "            print(\"train loss %.3f, val loss %.3f, val accuracy %.3f, and val rmse %.3f\" % (sum_loss/total, val_loss, val_acc, val_rmse))\n",
    "def validation_metrics (model, valid_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    sum_rmse = 0.0\n",
    "    for x, y, l in valid_dl:\n",
    "        x = x.long()\n",
    "        y = y.long()\n",
    "        y_hat = model(x, l)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        pred = torch.max(y_hat, 1)[1]\n",
    "        correct += (pred == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "        sum_rmse += np.sqrt(mean_squared_error(pred, y.unsqueeze(-1)))*y.shape[0]\n",
    "    return sum_loss/total, correct/total, sum_rmse/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(words)\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dl = DataLoader(valid_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_fixed_len(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 2)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x, l):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        lstm_out, (ht, ct) = self.lstm(x)\n",
    "        return self.linear(ht[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_fixed_len(\n",
       "  (embeddings): Embedding(102824, 50, padding_idx=0)\n",
       "  (lstm): LSTM(50, 50, batch_first=True)\n",
       "  (linear): Linear(in_features=50, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fixed = LSTM_fixed_len(vocab_size, 50, 50)\n",
    "model_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.691, val loss 0.690, val accuracy 0.540, and val rmse 0.678\n",
      "train loss 0.690, val loss 0.690, val accuracy 0.538, and val rmse 0.680\n",
      "train loss 0.687, val loss 0.691, val accuracy 0.537, and val rmse 0.680\n",
      "train loss 0.683, val loss 0.693, val accuracy 0.536, and val rmse 0.681\n",
      "train loss 0.674, val loss 0.699, val accuracy 0.535, and val rmse 0.682\n",
      "train loss 0.662, val loss 0.710, val accuracy 0.534, and val rmse 0.683\n",
      "train loss 0.645, val loss 0.725, val accuracy 0.533, and val rmse 0.683\n",
      "train loss 0.625, val loss 0.751, val accuracy 0.533, and val rmse 0.683\n",
      "train loss 0.608, val loss 0.770, val accuracy 0.531, and val rmse 0.685\n",
      "train loss 0.594, val loss 0.793, val accuracy 0.532, and val rmse 0.684\n",
      "train loss 0.580, val loss 0.816, val accuracy 0.532, and val rmse 0.684\n",
      "train loss 0.565, val loss 0.851, val accuracy 0.532, and val rmse 0.684\n",
      "train loss 0.553, val loss 0.875, val accuracy 0.530, and val rmse 0.685\n",
      "train loss 0.543, val loss 0.906, val accuracy 0.527, and val rmse 0.687\n",
      "train loss 0.535, val loss 0.906, val accuracy 0.530, and val rmse 0.686\n",
      "train loss 0.525, val loss 0.952, val accuracy 0.530, and val rmse 0.686\n",
      "train loss 0.520, val loss 0.995, val accuracy 0.530, and val rmse 0.686\n",
      "train loss 0.513, val loss 0.989, val accuracy 0.527, and val rmse 0.688\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-ed654d0dd9f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_fixed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-140-06931d53b64d>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0msum_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(model_fixed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data  \n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "train_data = trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "## test data    \n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "test_data = testData(torch.FloatTensor(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        # Number of input features is 58.\n",
    "        self.layer_1 = nn.Linear(58, NODES) \n",
    "        self.layer_2 = nn.Linear(NODES, NODES)\n",
    "        self.layer_3 = nn.Linear(NODES, NODES)\n",
    "        self.layer_4= nn.Linear(NODES, NODES)\n",
    "        self.layer_out = nn.Linear(NODES, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(NODES)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(NODES)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(NODES)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(NODES)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(self.layer_4(x))\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binaryClassification(\n",
      "  (layer_1): Linear(in_features=58, out_features=1000, bias=True)\n",
      "  (layer_2): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "  (layer_3): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "  (layer_4): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "  (layer_out): Linear(in_features=1000, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = binaryClassification()\n",
    "model.to(device)\n",
    "print(model)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.66039 | Acc: 63.279\n",
      "Epoch 002: | Loss: 0.61167 | Acc: 66.606\n",
      "Epoch 003: | Loss: 0.60290 | Acc: 67.587\n",
      "Epoch 004: | Loss: 0.59184 | Acc: 68.067\n",
      "Epoch 005: | Loss: 0.58322 | Acc: 68.913\n",
      "Epoch 006: | Loss: 0.57233 | Acc: 69.635\n",
      "Epoch 007: | Loss: 0.55725 | Acc: 70.962\n",
      "Epoch 008: | Loss: 0.54488 | Acc: 71.625\n",
      "Epoch 009: | Loss: 0.52243 | Acc: 73.356\n",
      "Epoch 010: | Loss: 0.50960 | Acc: 74.135\n",
      "Epoch 011: | Loss: 0.48391 | Acc: 75.981\n",
      "Epoch 012: | Loss: 0.45588 | Acc: 77.769\n",
      "Epoch 013: | Loss: 0.42766 | Acc: 79.279\n",
      "Epoch 014: | Loss: 0.39070 | Acc: 81.548\n",
      "Epoch 015: | Loss: 0.35392 | Acc: 83.558\n",
      "Epoch 016: | Loss: 0.30813 | Acc: 86.106\n",
      "Epoch 017: | Loss: 0.27973 | Acc: 87.606\n",
      "Epoch 018: | Loss: 0.25027 | Acc: 89.058\n",
      "Epoch 019: | Loss: 0.21046 | Acc: 91.000\n",
      "Epoch 020: | Loss: 0.19261 | Acc: 91.904\n",
      "Epoch 021: | Loss: 0.16147 | Acc: 93.337\n",
      "Epoch 022: | Loss: 0.14403 | Acc: 94.144\n",
      "Epoch 023: | Loss: 0.12276 | Acc: 94.885\n",
      "Epoch 024: | Loss: 0.11840 | Acc: 95.212\n",
      "Epoch 025: | Loss: 0.10100 | Acc: 95.856\n",
      "Epoch 026: | Loss: 0.09544 | Acc: 96.231\n",
      "Epoch 027: | Loss: 0.08783 | Acc: 96.385\n",
      "Epoch 028: | Loss: 0.09066 | Acc: 96.202\n",
      "Epoch 029: | Loss: 0.07740 | Acc: 96.798\n",
      "Epoch 030: | Loss: 0.06258 | Acc: 97.394\n",
      "Epoch 031: | Loss: 0.06646 | Acc: 97.365\n",
      "Epoch 032: | Loss: 0.06432 | Acc: 97.250\n",
      "Epoch 033: | Loss: 0.07351 | Acc: 96.923\n",
      "Epoch 034: | Loss: 0.06468 | Acc: 97.269\n",
      "Epoch 035: | Loss: 0.05587 | Acc: 97.625\n",
      "Epoch 036: | Loss: 0.05126 | Acc: 97.798\n",
      "Epoch 037: | Loss: 0.04988 | Acc: 97.913\n",
      "Epoch 038: | Loss: 0.05695 | Acc: 97.740\n",
      "Epoch 039: | Loss: 0.04998 | Acc: 97.798\n",
      "Epoch 040: | Loss: 0.04820 | Acc: 97.952\n",
      "Epoch 041: | Loss: 0.04593 | Acc: 98.000\n",
      "Epoch 042: | Loss: 0.05891 | Acc: 97.712\n",
      "Epoch 043: | Loss: 0.05130 | Acc: 97.885\n",
      "Epoch 044: | Loss: 0.04399 | Acc: 98.240\n",
      "Epoch 045: | Loss: 0.03871 | Acc: 98.375\n",
      "Epoch 046: | Loss: 0.03870 | Acc: 98.394\n",
      "Epoch 047: | Loss: 0.04378 | Acc: 98.356\n",
      "Epoch 048: | Loss: 0.04137 | Acc: 98.346\n",
      "Epoch 049: | Loss: 0.03805 | Acc: 98.413\n",
      "Epoch 050: | Loss: 0.04107 | Acc: 98.308\n",
      "Epoch 051: | Loss: 0.04672 | Acc: 98.163\n",
      "Epoch 052: | Loss: 0.04314 | Acc: 98.365\n",
      "Epoch 053: | Loss: 0.03789 | Acc: 98.471\n",
      "Epoch 054: | Loss: 0.03304 | Acc: 98.808\n",
      "Epoch 055: | Loss: 0.02700 | Acc: 98.952\n",
      "Epoch 056: | Loss: 0.03220 | Acc: 98.817\n",
      "Epoch 057: | Loss: 0.03600 | Acc: 98.567\n",
      "Epoch 058: | Loss: 0.03631 | Acc: 98.702\n",
      "Epoch 059: | Loss: 0.04268 | Acc: 98.356\n",
      "Epoch 060: | Loss: 0.03698 | Acc: 98.625\n",
      "Epoch 061: | Loss: 0.02671 | Acc: 99.000\n",
      "Epoch 062: | Loss: 0.03359 | Acc: 98.721\n",
      "Epoch 063: | Loss: 0.03572 | Acc: 98.606\n",
      "Epoch 064: | Loss: 0.03102 | Acc: 98.827\n",
      "Epoch 065: | Loss: 0.03060 | Acc: 98.913\n",
      "Epoch 066: | Loss: 0.03248 | Acc: 98.702\n",
      "Epoch 067: | Loss: 0.03501 | Acc: 98.740\n",
      "Epoch 068: | Loss: 0.03040 | Acc: 98.865\n",
      "Epoch 069: | Loss: 0.03364 | Acc: 98.663\n",
      "Epoch 070: | Loss: 0.03044 | Acc: 98.942\n",
      "Epoch 071: | Loss: 0.02646 | Acc: 99.067\n",
      "Epoch 072: | Loss: 0.02784 | Acc: 98.952\n",
      "Epoch 073: | Loss: 0.02897 | Acc: 98.981\n",
      "Epoch 074: | Loss: 0.03196 | Acc: 98.904\n",
      "Epoch 075: | Loss: 0.02609 | Acc: 99.125\n",
      "Epoch 076: | Loss: 0.02193 | Acc: 99.192\n",
      "Epoch 077: | Loss: 0.02080 | Acc: 99.250\n",
      "Epoch 078: | Loss: 0.02884 | Acc: 99.010\n",
      "Epoch 079: | Loss: 0.02493 | Acc: 99.144\n",
      "Epoch 080: | Loss: 0.02885 | Acc: 99.048\n",
      "Epoch 081: | Loss: 0.02772 | Acc: 98.913\n",
      "Epoch 082: | Loss: 0.02393 | Acc: 99.231\n",
      "Epoch 083: | Loss: 0.02227 | Acc: 99.144\n",
      "Epoch 084: | Loss: 0.02424 | Acc: 99.212\n",
      "Epoch 085: | Loss: 0.02750 | Acc: 99.019\n",
      "Epoch 086: | Loss: 0.02573 | Acc: 99.154\n",
      "Epoch 087: | Loss: 0.01999 | Acc: 99.375\n",
      "Epoch 088: | Loss: 0.02029 | Acc: 99.365\n",
      "Epoch 089: | Loss: 0.02204 | Acc: 99.298\n",
      "Epoch 090: | Loss: 0.02454 | Acc: 99.173\n",
      "Epoch 091: | Loss: 0.02333 | Acc: 99.240\n",
      "Epoch 092: | Loss: 0.01763 | Acc: 99.413\n",
      "Epoch 093: | Loss: 0.01653 | Acc: 99.548\n",
      "Epoch 094: | Loss: 0.01981 | Acc: 99.327\n",
      "Epoch 095: | Loss: 0.02016 | Acc: 99.375\n",
      "Epoch 096: | Loss: 0.01906 | Acc: 99.423\n",
      "Epoch 097: | Loss: 0.02288 | Acc: 99.202\n",
      "Epoch 098: | Loss: 0.02834 | Acc: 99.048\n",
      "Epoch 099: | Loss: 0.02507 | Acc: 99.154\n",
      "Epoch 100: | Loss: 0.01597 | Acc: 99.481\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3468, 2539],\n",
       "       [2594, 4482]], dtype=int64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.58      0.57      6007\n",
      "           1       0.64      0.63      0.64      7076\n",
      "\n",
      "    accuracy                           0.61     13083\n",
      "   macro avg       0.61      0.61      0.61     13083\n",
      "weighted avg       0.61      0.61      0.61     13083\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
